{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Sentiment Analysis Web App\n",
    "## Using PyTorch and SageMaker\n",
    "\n",
    "_Deep Learning Nanodegree Program | Deployment_\n",
    "\n",
    "---\n",
    "\n",
    "Now that we have a basic understanding of how SageMaker works we will try to use it to construct a complete project from end to end. Our goal will be to have a simple web page which a user can use to enter a movie review. The web page will then send the review off to our deployed model which will predict the sentiment of the entered review.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this notebook. You will not need to modify the included code beyond what is requested. Sections that begin with '**TODO**' in the header indicate that you need to complete or implement some portion within them. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a `# TODO: ...` comment. Please be sure to read the instructions carefully!\n",
    "\n",
    "In addition to implementing code, there will be questions for you to answer which relate to the task and your implementation. Each section where you will answer a question is preceded by a '**Question:**' header. Carefully read each question and provide your answer below the '**Answer:**' header by editing the Markdown cell.\n",
    "\n",
    "> **Note**: Code and Markdown cells can be executed using the **Shift+Enter** keyboard shortcut. In addition, a cell can be edited by typically clicking it (double-click for Markdown cells) or by pressing **Enter** while it is highlighted.\n",
    "\n",
    "## General Outline\n",
    "\n",
    "Recall the general outline for SageMaker projects using a notebook instance.\n",
    "\n",
    "1. Download or otherwise retrieve the data.\n",
    "2. Process / Prepare the data.\n",
    "3. Upload the processed data to S3.\n",
    "4. Train a chosen model.\n",
    "5. Test the trained model (typically using a batch transform job).\n",
    "6. Deploy the trained model.\n",
    "7. Use the deployed model.\n",
    "\n",
    "For this project, you will be following the steps in the general outline with some modifications. \n",
    "\n",
    "First, you will not be testing the model in its own step. You will still be testing the model, however, you will do it by deploying your model and then using the deployed model by sending the test data to it. One of the reasons for doing this is so that you can make sure that your deployed model is working correctly before moving forward.\n",
    "\n",
    "In addition, you will deploy and use your trained model a second time. In the second iteration you will customize the way that your trained model is deployed by including some of your own code. In addition, your newly deployed model will be used in the sentiment analysis web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Downloading the data\n",
    "\n",
    "As in the XGBoost in SageMaker notebook, we will be using the [IMDb dataset](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "> Maas, Andrew L., et al. [Learning Word Vectors for Sentiment Analysis](http://ai.stanford.edu/~amaas/data/sentiment/). In _Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies_. Association for Computational Linguistics, 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../data’: File exists\n",
      "--2020-04-08 22:15:50--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘../data/aclImdb_v1.tar.gz’\n",
      "\n",
      "../data/aclImdb_v1. 100%[===================>]  80.23M  23.1MB/s    in 4.2s    \n",
      "\n",
      "2020-04-08 22:15:55 (19.0 MB/s) - ‘../data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%mkdir ../data\n",
    "!wget -O ../data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -zxf ../data/aclImdb_v1.tar.gz -C ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing and Processing the data\n",
    "\n",
    "Also, as in the XGBoost notebook, we will be doing some initial data processing. The first few steps are the same as in the XGBoost example. To begin with, we will read in each of the reviews and combine them into a single input structure. Then, we will split the dataset into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def read_imdb_data(data_dir='../data/aclImdb'):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "        \n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "            \n",
    "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "            \n",
    "            for f in files:\n",
    "                with open(f) as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "                    \n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "                \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "data, labels = read_imdb_data()\n",
    "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
    "            len(data['train']['pos']), len(data['train']['neg']),\n",
    "            len(data['test']['pos']), len(data['test']['neg'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've read the raw training and testing data from the downloaded dataset, we will combine the positive and negative reviews and shuffle the resulting records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_imdb_data(data, labels):\n",
    "    \"\"\"Prepare training and test sets from IMDb movie reviews.\"\"\"\n",
    "    \n",
    "    #Combine positive and negative reviews and labels\n",
    "    data_train = data['train']['pos'] + data['train']['neg']\n",
    "    data_test = data['test']['pos'] + data['test']['neg']\n",
    "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
    "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
    "    \n",
    "    #Shuffle reviews and corresponding labels within training and test sets\n",
    "    data_train, labels_train = shuffle(data_train, labels_train)\n",
    "    data_test, labels_test = shuffle(data_test, labels_test)\n",
    "    \n",
    "    # Return a unified training data, test data, training labels, test labets\n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews (combined): train = 25000, test = 25000\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
    "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_X), len(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training and testing sets unified and prepared, we should do a quick check and see an example of the data our model will be trained on. This is generally a good idea as it allows you to see how each of the further processing steps affects the reviews and it also ensures that the data has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Kaabee\" depicts the hardship of a woman in pre and during WWII, raising her kids alone after her husband imprisoned for \"thought crime\". This movie was directed by Yamada Youji, and as expected the atmosphere of this movie is really wonderful. Although the historical correctness of some scenes, most notably the beach scene, is a suspect.<br /><br />The acting in this movie is absolutely incredible. I am baffled at how they managed to gather this all-star cast for a 2008 film. Yoshinaga Sayuri, possibly the most decorated still-active actress in Japan, will undoubtedly win more individual awards for her performance in this film. Shoufukutei Tsurube in a supporting role was really nice as well. It was Asano Tadanobu though, who delivered the most impressive performance, perfectly portraying the wittiness of his character and the difficult situation he was in.<br /><br />Films with pre-war setting is not my thing, but thanks to wonderful directing and acting, I was totally absorbed by the story. Also, it wasn't a far-left nonsense like \"Yuunagi no Machi, Sakura no Kuni\", and examines the controversial and sensitive issue of government oppression and brainwashing that occurred in that period in Japan. Excellent film, highly recommended for all viewers.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_X[100])\n",
    "print(train_y[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in processing the reviews is to make sure that any html tags that appear should be removed. In addition we wish to tokenize our input, that way words such as *entertained* and *entertaining* are considered the same with regard to sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `review_to_words` method defined above uses `BeautifulSoup` to remove any html tags that appear and uses the `nltk` package to tokenize the reviews. As a check to ensure we know how everything is working, try applying `review_to_words` to one of the reviews in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slither',\n",
       " 'horror',\n",
       " 'comedi',\n",
       " 'realli',\n",
       " 'enough',\n",
       " 'horror',\n",
       " 'comedi',\n",
       " 'qualifi',\n",
       " 'one',\n",
       " 'one',\n",
       " 'scene',\n",
       " 'except',\n",
       " 'good',\n",
       " 'number',\n",
       " 'zinger',\n",
       " 'work',\n",
       " 'real',\n",
       " 'scare',\n",
       " 'enough',\n",
       " 'humor',\n",
       " 'maintain',\n",
       " 'movi',\n",
       " 'addit',\n",
       " 'script',\n",
       " 'focu',\n",
       " 'hero',\n",
       " 'heroin',\n",
       " 'goe',\n",
       " 'kilter',\n",
       " 'sever',\n",
       " 'place',\n",
       " 'major',\n",
       " 'fail',\n",
       " 'film',\n",
       " 'introduc',\n",
       " 'leav',\n",
       " 'hero',\n",
       " 'fillion',\n",
       " 'follow',\n",
       " 'grant',\n",
       " 'grant',\n",
       " 'michael',\n",
       " 'rooker',\n",
       " 'first',\n",
       " 'introduc',\n",
       " 'becom',\n",
       " 'monster',\n",
       " 'whole',\n",
       " 'part',\n",
       " 'film',\n",
       " 'drag',\n",
       " 'michael',\n",
       " 'rooker',\n",
       " 'charact',\n",
       " 'interest',\n",
       " 'us',\n",
       " 'person',\n",
       " 'watch',\n",
       " 'goe',\n",
       " 'seri',\n",
       " 'motion',\n",
       " 'act',\n",
       " 'monster',\n",
       " 'interest',\n",
       " 'might',\n",
       " 'interest',\n",
       " 'grant',\n",
       " 'portrait',\n",
       " 'man',\n",
       " 'turn',\n",
       " 'monster',\n",
       " 'rather',\n",
       " 'horror',\n",
       " 'comedi',\n",
       " 'alien',\n",
       " 'invas',\n",
       " 'movi',\n",
       " 'final',\n",
       " 'analysi',\n",
       " 'movi',\n",
       " 'problem',\n",
       " 'script',\n",
       " 'import',\n",
       " 'audienc',\n",
       " 'monster',\n",
       " 'act',\n",
       " 'propag',\n",
       " 'purpos',\n",
       " 'horror',\n",
       " 'comedi',\n",
       " 'get',\n",
       " 'hero',\n",
       " 'back',\n",
       " 'corner',\n",
       " 'shotgun',\n",
       " 'throw',\n",
       " 'bug',\n",
       " 'crack',\n",
       " 'wise',\n",
       " 'everi',\n",
       " 'time',\n",
       " 'someth',\n",
       " 'frighten',\n",
       " 'disgust',\n",
       " 'happen',\n",
       " 'instead',\n",
       " 'get',\n",
       " 'explor',\n",
       " 'alien',\n",
       " 'habit',\n",
       " 'tactic',\n",
       " 'make',\n",
       " 'part',\n",
       " 'movi',\n",
       " 'drag',\n",
       " 'ostens',\n",
       " 'heroin',\n",
       " 'elizabeth',\n",
       " 'bank',\n",
       " 'starla',\n",
       " 'grant',\n",
       " 'central',\n",
       " 'part',\n",
       " 'nonetheless',\n",
       " 'felt',\n",
       " 'movi',\n",
       " 'left',\n",
       " 'narr',\n",
       " 'track',\n",
       " 'unless',\n",
       " 'plan',\n",
       " 'follow',\n",
       " 'grant',\n",
       " 'grant',\n",
       " 'way',\n",
       " 'end',\n",
       " 'fillion',\n",
       " 'poss',\n",
       " 'final',\n",
       " 'confront',\n",
       " 'alien',\n",
       " 'movi',\n",
       " 'begin',\n",
       " 'cook',\n",
       " 'problem',\n",
       " 'script',\n",
       " 'point',\n",
       " 'audienc',\n",
       " 'know',\n",
       " 'charact',\n",
       " 'know',\n",
       " 'grant',\n",
       " 'suffer',\n",
       " 'diseas',\n",
       " 'act',\n",
       " 'accordingli',\n",
       " 'shotgun',\n",
       " 'instead',\n",
       " 'continu',\n",
       " 'parley',\n",
       " 'face',\n",
       " 'increas',\n",
       " 'evid',\n",
       " 'someth',\n",
       " 'let',\n",
       " 'us',\n",
       " 'get',\n",
       " 'hospit',\n",
       " 'go',\n",
       " 'help',\n",
       " 'although',\n",
       " 'reaction',\n",
       " 'might',\n",
       " 'human',\n",
       " 'real',\n",
       " 'charact',\n",
       " 'action',\n",
       " 'movi',\n",
       " 'simpli',\n",
       " 'done',\n",
       " 'movi',\n",
       " 'promis',\n",
       " 'deliv',\n",
       " 'action',\n",
       " 'lack',\n",
       " 'action',\n",
       " 'scene',\n",
       " 'movi',\n",
       " 'idea',\n",
       " 'great',\n",
       " 'fail',\n",
       " 'spoiler',\n",
       " 'ahead',\n",
       " 'first',\n",
       " 'confront',\n",
       " 'burst',\n",
       " 'alien',\n",
       " 'larval',\n",
       " 'sack',\n",
       " 'minor',\n",
       " 'charact',\n",
       " 'perhap',\n",
       " 'best',\n",
       " 'scene',\n",
       " 'movi',\n",
       " 'script',\n",
       " 'betray',\n",
       " 'movi',\n",
       " 'point',\n",
       " 'one',\n",
       " 'charact',\n",
       " 'almost',\n",
       " 'taken',\n",
       " 'alien',\n",
       " 'develop',\n",
       " 'insight',\n",
       " 'alien',\n",
       " 'writer',\n",
       " 'director',\n",
       " 'gunn',\n",
       " 'choos',\n",
       " 'charact',\n",
       " 'complet',\n",
       " 'new',\n",
       " 'charact',\n",
       " 'rather',\n",
       " 'one',\n",
       " 'alreadi',\n",
       " 'develop',\n",
       " 'minor',\n",
       " 'charact',\n",
       " 'need',\n",
       " 'introduc',\n",
       " 'complet',\n",
       " 'new',\n",
       " 'charact',\n",
       " 'hour',\n",
       " 'movi',\n",
       " 'becom',\n",
       " 'central',\n",
       " 'plot',\n",
       " 'time',\n",
       " 'charact',\n",
       " 'attack',\n",
       " 'know',\n",
       " 'hardli',\n",
       " 'anyth',\n",
       " 'could',\n",
       " 'care',\n",
       " 'less',\n",
       " 'even',\n",
       " 'though',\n",
       " 'winsom',\n",
       " 'teenag',\n",
       " 'girl',\n",
       " 'bath',\n",
       " 'gunn',\n",
       " 'decid',\n",
       " 'use',\n",
       " 'charact',\n",
       " 'use',\n",
       " 'one',\n",
       " 'establish',\n",
       " 'minor',\n",
       " 'charact',\n",
       " 'could',\n",
       " 'complet',\n",
       " 'avoid',\n",
       " 'introduc',\n",
       " 'famili',\n",
       " 'save',\n",
       " 'time',\n",
       " 'money',\n",
       " 'furthermor',\n",
       " 'hero',\n",
       " 'heroin',\n",
       " 'would',\n",
       " 'fill',\n",
       " 'alien',\n",
       " 'plan',\n",
       " 'without',\n",
       " 'addit',\n",
       " 'charact',\n",
       " 'could',\n",
       " 'gotten',\n",
       " 'around',\n",
       " 'blow',\n",
       " 'away',\n",
       " 'alien',\n",
       " 'sooner',\n",
       " 'vigor',\n",
       " 'last',\n",
       " 'critic',\n",
       " 'base',\n",
       " 'movi',\n",
       " 'look',\n",
       " 'gunn',\n",
       " 'primarili',\n",
       " 'writer',\n",
       " 'mayb',\n",
       " 'budgetari',\n",
       " 'constraint',\n",
       " 'movi',\n",
       " 'look',\n",
       " 'ugli',\n",
       " 'uninterest',\n",
       " 'action',\n",
       " 'take',\n",
       " 'place',\n",
       " 'night',\n",
       " 'wood',\n",
       " 'field',\n",
       " 'screen',\n",
       " 'simpli',\n",
       " 'look',\n",
       " 'drab',\n",
       " 'set',\n",
       " 'wheelsi',\n",
       " 'fiction',\n",
       " 'town',\n",
       " 'action',\n",
       " 'take',\n",
       " 'place',\n",
       " 'look',\n",
       " 'cheap',\n",
       " 'whole',\n",
       " 'movi',\n",
       " 'look',\n",
       " 'cheap',\n",
       " 'box',\n",
       " 'offic',\n",
       " 'mojo',\n",
       " 'state',\n",
       " 'film',\n",
       " 'budget',\n",
       " '15',\n",
       " 'million',\n",
       " 'newspap',\n",
       " 'say',\n",
       " '29',\n",
       " 'million',\n",
       " 'consid',\n",
       " 'use',\n",
       " 'name',\n",
       " 'talent',\n",
       " 'would',\n",
       " 'say',\n",
       " 'money',\n",
       " 'show',\n",
       " 'screen',\n",
       " 'monster',\n",
       " 'repuls',\n",
       " 'rare',\n",
       " 'look',\n",
       " 'deadli',\n",
       " 'last',\n",
       " 'critic',\n",
       " 'primarili',\n",
       " 'base',\n",
       " 'realiti',\n",
       " 'charact',\n",
       " 'action',\n",
       " 'time',\n",
       " 'fillion',\n",
       " 'co',\n",
       " 'begun',\n",
       " 'hunt',\n",
       " 'grant',\n",
       " 'alien',\n",
       " 'one',\n",
       " 'woman',\n",
       " 'disappear',\n",
       " 'grant',\n",
       " 'known',\n",
       " 'mutil',\n",
       " 'anim',\n",
       " 'point',\n",
       " 'expect',\n",
       " 'fbi',\n",
       " 'least',\n",
       " 'state',\n",
       " 'polic',\n",
       " 'show',\n",
       " 'take',\n",
       " 'hick',\n",
       " 'sheriff',\n",
       " 'woman',\n",
       " 'disappear',\n",
       " 'like',\n",
       " 'murder',\n",
       " 'local',\n",
       " 'act',\n",
       " 'psychot',\n",
       " 'time',\n",
       " 'call',\n",
       " 'author',\n",
       " 'basic',\n",
       " 'hope',\n",
       " 'would',\n",
       " 'happen',\n",
       " 'want',\n",
       " 'charact',\n",
       " 'would',\n",
       " 'show',\n",
       " 'act',\n",
       " 'although',\n",
       " 'movi',\n",
       " 'ostens',\n",
       " 'horror',\n",
       " 'comedi',\n",
       " 'movi',\n",
       " 'bear',\n",
       " 'resembl',\n",
       " 'dreamcatch',\n",
       " 'term',\n",
       " 'monstrou',\n",
       " 'invas',\n",
       " 'type',\n",
       " 'monster',\n",
       " 'intent',\n",
       " 'wherea',\n",
       " 'dreamcatch',\n",
       " 'much',\n",
       " 'bigger',\n",
       " 'problem',\n",
       " 'stori',\n",
       " 'especi',\n",
       " 'entir',\n",
       " 'morgan',\n",
       " 'freeman',\n",
       " 'subplot',\n",
       " 'particularli',\n",
       " 'end',\n",
       " 'mani',\n",
       " 'way',\n",
       " 'stronger',\n",
       " 'primarili',\n",
       " 'main',\n",
       " 'charact',\n",
       " 'stronger',\n",
       " 'importantli',\n",
       " 'look',\n",
       " 'beauti',\n",
       " 'although',\n",
       " 'may',\n",
       " 'anathema',\n",
       " 'prefer',\n",
       " 'movi',\n",
       " 'weaker',\n",
       " 'gener',\n",
       " 'plot',\n",
       " 'structur',\n",
       " 'spine',\n",
       " 'product',\n",
       " 'valu',\n",
       " 'show',\n",
       " 'uninterest',\n",
       " 'found',\n",
       " 'look',\n",
       " 'slither']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Apply review_to_words to a review (train_X[100] or any other review)\n",
    "review_to_words(train_X[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Above we mentioned that `review_to_words` method removes html formatting and allows us to tokenize the words found in a review, for example, converting *entertained* and *entertaining* into *entertain* so that they are treated as though they are the same word. What else, if anything, does this method do to the input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method below applies the `review_to_words` method to each of the reviews in the training and testing datasets. In addition it caches the results. This is because performing this processing step can take a long time. This way if you are unable to complete the notebook in the current session, you can come back without needing to process the data a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cache_dir = os.path.join(\"../cache\", \"sentiment_analysis\")  # where to store cache files\n",
    "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "\n",
    "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
    "                    cache_dir=cache_dir, cache_file=\"preprocessed_data_full.pkl\"):\n",
    "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
    "\n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "    \n",
    "    # If cache is missing, then do the heavy lifting\n",
    "    if cache_data is None:\n",
    "        # Preprocess training and test data to obtain words for each review\n",
    "        #words_train = list(map(review_to_words, data_train))\n",
    "        #words_test = list(map(review_to_words, data_test))\n",
    "        words_train = [review_to_words(review) for review in data_train]\n",
    "        words_test = [review_to_words(review) for review in data_test]\n",
    "        \n",
    "        # Write to cache file for future runs\n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
    "                              labels_train=labels_train, labels_test=labels_test)\n",
    "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "    else:\n",
    "        # Unpack data loaded from cache file\n",
    "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
    "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
    "    \n",
    "    return words_train, words_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read preprocessed data from cache file: preprocessed_data_full.pkl\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "#n=100\n",
    "#train_X, test_X, train_y, test_y = preprocess_data(train_X[:n], test_X[:n], train_y[:n], test_y[:n])\n",
    "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data\n",
    "\n",
    "In the XGBoost notebook we transformed the data from its word representation to a bag-of-words feature representation. For the model we are going to construct in this notebook we will construct a feature representation which is very similar. To start, we will represent each word as an integer. Of course, some of the words that appear in the reviews occur very infrequently and so likely don't contain much information for the purposes of sentiment analysis. The way we will deal with this problem is that we will fix the size of our working vocabulary and we will only include the words that appear most frequently. We will then combine all of the infrequent words into a single category and, in our case, we will label it as `1`.\n",
    "\n",
    "Since we will be using a recurrent neural network, it will be convenient if the length of each review is the same. To do this, we will fix a size for our reviews and then pad short reviews with the category 'no word' (which we will label `0`) and truncate long reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Create a word dictionary\n",
    "\n",
    "To begin with, we need to construct a way to map words that appear in the reviews to integers. Here we fix the size of our vocabulary (including the 'no word' and 'infrequent' categories) to be `5000` but you may wish to change this to see how it affects the model.\n",
    "\n",
    "> **TODO:** Complete the implementation for the `build_dict()` method below. Note that even though the vocab_size is set to `5000`, we only want to construct a mapping for the most frequently appearing `4998` words. This is because we want to reserve the special labels `0` for 'no word' and `1` for 'infrequent word'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.42.1)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "#Monitor the for loop like this [review_to_words(review) for review in tqdm(data_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "word_dict = None\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    \n",
    "    \"\"\"vectorizer = CountVectorizer(max_features=vocabulary_size)\n",
    "    features_train = vectorizer.fit_transform(words_train).toarray()\n",
    "\n",
    "        # Apply the same vectorizer to transform the test documents (ignore unknown words)\n",
    "        \n",
    "        \n",
    "        # NOTE: Remember to convert the features using .toarray() for a compact representation\n",
    "        \n",
    "        # Write to cache file for future runs (store vocabulary as well)\n",
    "    vocabulary = vectorizer.vocabulary_\"\"\"\n",
    "    \n",
    "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
    "    \n",
    "    # TODO: Determine how often each word appears in `data`. Note that `data` is a list of sentences and that a\n",
    "    #       sentence is a list of words.\n",
    "    #print(set(tuple(x) for x in data))\n",
    "    #flat_list = [item for sublist in data for item in sublist]\n",
    "    #print(len(flat_list),len(set(flat_list)))\n",
    "    print(\"flatten the list\")\n",
    "    flat_list = [item for sublist in tqdm(data) for item in sublist]\n",
    "    \"\"\"itr=0\n",
    "    for sublist in data:\n",
    "        for item in sublist:\n",
    "            unique_data.append(item)\n",
    "        itr+=1\n",
    "        print(\"sentence # \",itr)\"\"\"\n",
    "    print(\"len flat_list: \",len(flat_list))\n",
    "    unique_data = list(set(flat_list))\n",
    "    print(\"len set unique data: \",len(unique_data))#[x for x in set(data)] #tuple(x) for x in data)]\n",
    "    #word_count = {} # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    print(\"word frequancies: \")\n",
    "    wordfreq = [flat_list.count(p) for p in tqdm(unique_data)]\n",
    "    print(\"max word freq:\", max(wordfreq))\n",
    "    word_count = {}\n",
    "    #for p in tqdm(unique_data:\n",
    "        #word_count.append()\n",
    "    #print(unique_data,wordfreq)\n",
    "    print(\"zip pairs of words with frequencies\")\n",
    "    word_count = dict(zip(unique_data,wordfreq))\n",
    "    #unique_data,wordfreq = None\n",
    "    # TODO: Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
    "    #       sorted_words[-1] is the least frequently appearing word.\n",
    "    sorted_words = []\n",
    "    listofTuples = sorted(word_count.items() , reverse=True, key=lambda x: x[1])\n",
    "    # Iterate over the sorted sequence\n",
    "    for elem in listofTuples :\n",
    "        print(elem[0] , \" ::\" , elem[1] )\n",
    "    #itr=0\n",
    "    sorted_words = [elem[0] for elem in listofTuples]#[(word_count[key], key) for key in tqdm(word_count)]\n",
    "    print(\"word counts with keys\")\n",
    "    #for key in tqdm(word_count):\n",
    "        #sorted_words.append((word_count[key], key))\n",
    "        #print(itr)\n",
    "        #itr+=1\n",
    "    #sorted_words = aux\n",
    "    #sorted_words.sort()\n",
    "    #sorted_words.reverse()\n",
    "    print(sorted_words)\n",
    "    #sorted_words = aux\n",
    "    print(\"dict: \")\n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "    for idx, word in tqdm(enumerate(sorted_words[:vocab_size - 2])): # The -2 is so that we save room for the 'no word'\n",
    "        word_dict[word] = idx + 2       \n",
    "        #print(idx)# 'infrequent' labels\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 5393/25000 [00:00<00:00, 26655.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten the list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 25987.54it/s]\n",
      "  0%|          | 1/5000 [00:00<27:39,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len flat_list:  12500000\n",
      "len set unique data:  5000\n",
      "word frequancies: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [27:56<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max word freq: 9484769\n",
      "zip pairs of words with frequencies\n",
      "0  :: 9484769\n",
      "1  :: 320980\n",
      "2  :: 51612\n",
      "3  :: 48025\n",
      "4  :: 27652\n",
      "5  :: 22741\n",
      "6  :: 16150\n",
      "7  :: 15321\n",
      "8  :: 15166\n",
      "9  :: 14145\n",
      "10  :: 14103\n",
      "11  :: 14067\n",
      "12  :: 13915\n",
      "13  :: 13144\n",
      "14  :: 12877\n",
      "15  :: 12392\n",
      "16  :: 11716\n",
      "17  :: 11003\n",
      "18  :: 10538\n",
      "19  :: 10020\n",
      "20  :: 9851\n",
      "21  :: 9733\n",
      "22  :: 9598\n",
      "23  :: 9356\n",
      "24  :: 9326\n",
      "25  :: 9279\n",
      "26  :: 9144\n",
      "27  :: 9127\n",
      "28  :: 9042\n",
      "29  :: 9013\n",
      "30  :: 8895\n",
      "31  :: 8805\n",
      "32  :: 8787\n",
      "33  :: 8720\n",
      "34  :: 8345\n",
      "35  :: 8187\n",
      "36  :: 7893\n",
      "37  :: 7494\n",
      "38  :: 7432\n",
      "39  :: 7211\n",
      "40  :: 7080\n",
      "41  :: 6956\n",
      "42  :: 6882\n",
      "43  :: 6869\n",
      "44  :: 6851\n",
      "45  :: 6731\n",
      "47  :: 6665\n",
      "46  :: 6658\n",
      "48  :: 6631\n",
      "50  :: 6624\n",
      "49  :: 6620\n",
      "51  :: 6466\n",
      "52  :: 6417\n",
      "53  :: 6401\n",
      "54  :: 6340\n",
      "55  :: 6018\n",
      "56  :: 5985\n",
      "57  :: 5769\n",
      "58  :: 5720\n",
      "59  :: 5644\n",
      "60  :: 5522\n",
      "61  :: 5432\n",
      "62  :: 5280\n",
      "63  :: 5237\n",
      "64  :: 5115\n",
      "67  :: 5110\n",
      "65  :: 5108\n",
      "66  :: 5102\n",
      "68  :: 5051\n",
      "69  :: 4885\n",
      "70  :: 4765\n",
      "71  :: 4725\n",
      "72  :: 4573\n",
      "73  :: 4565\n",
      "74  :: 4552\n",
      "75  :: 4465\n",
      "76  :: 4438\n",
      "77  :: 4339\n",
      "78  :: 4332\n",
      "79  :: 4314\n",
      "80  :: 4297\n",
      "81  :: 4296\n",
      "84  :: 4284\n",
      "82  :: 4283\n",
      "83  :: 4238\n",
      "85  :: 4232\n",
      "86  :: 4226\n",
      "87  :: 4158\n",
      "88  :: 4102\n",
      "89  :: 4056\n",
      "90  :: 4029\n",
      "91  :: 4004\n",
      "93  :: 3966\n",
      "92  :: 3964\n",
      "94  :: 3902\n",
      "95  :: 3864\n",
      "96  :: 3825\n",
      "98  :: 3789\n",
      "97  :: 3775\n",
      "99  :: 3769\n",
      "100  :: 3740\n",
      "101  :: 3733\n",
      "102  :: 3699\n",
      "104  :: 3683\n",
      "103  :: 3676\n",
      "105  :: 3676\n",
      "106  :: 3665\n",
      "107  :: 3657\n",
      "108  :: 3626\n",
      "109  :: 3617\n",
      "110  :: 3607\n",
      "111  :: 3570\n",
      "112  :: 3569\n",
      "113  :: 3547\n",
      "115  :: 3531\n",
      "114  :: 3529\n",
      "116  :: 3461\n",
      "118  :: 3446\n",
      "117  :: 3441\n",
      "119  :: 3439\n",
      "120  :: 3411\n",
      "121  :: 3375\n",
      "122  :: 3356\n",
      "123  :: 3347\n",
      "124  :: 3340\n",
      "125  :: 3340\n",
      "126  :: 3279\n",
      "127  :: 3266\n",
      "128  :: 3263\n",
      "129  :: 3256\n",
      "130  :: 3244\n",
      "131  :: 3232\n",
      "132  :: 3226\n",
      "133  :: 3209\n",
      "134  :: 3200\n",
      "135  :: 3176\n",
      "136  :: 3146\n",
      "138  :: 3143\n",
      "137  :: 3133\n",
      "139  :: 3128\n",
      "140  :: 3119\n",
      "141  :: 3103\n",
      "142  :: 3087\n",
      "143  :: 3084\n",
      "144  :: 3067\n",
      "145  :: 3041\n",
      "146  :: 3032\n",
      "147  :: 3005\n",
      "149  :: 3000\n",
      "148  :: 2997\n",
      "150  :: 2990\n",
      "151  :: 2967\n",
      "152  :: 2958\n",
      "153  :: 2941\n",
      "154  :: 2922\n",
      "155  :: 2920\n",
      "157  :: 2914\n",
      "156  :: 2907\n",
      "158  :: 2901\n",
      "159  :: 2892\n",
      "160  :: 2871\n",
      "161  :: 2867\n",
      "162  :: 2827\n",
      "163  :: 2820\n",
      "164  :: 2815\n",
      "165  :: 2810\n",
      "166  :: 2793\n",
      "168  :: 2785\n",
      "167  :: 2784\n",
      "169  :: 2774\n",
      "170  :: 2770\n",
      "171  :: 2748\n",
      "172  :: 2743\n",
      "174  :: 2728\n",
      "173  :: 2726\n",
      "175  :: 2718\n",
      "176  :: 2690\n",
      "177  :: 2679\n",
      "178  :: 2674\n",
      "179  :: 2670\n",
      "180  :: 2628\n",
      "181  :: 2625\n",
      "182  :: 2624\n",
      "183  :: 2612\n",
      "184  :: 2601\n",
      "185  :: 2557\n",
      "186  :: 2546\n",
      "187  :: 2536\n",
      "188  :: 2531\n",
      "189  :: 2515\n",
      "190  :: 2512\n",
      "191  :: 2508\n",
      "192  :: 2469\n",
      "193  :: 2458\n",
      "194  :: 2437\n",
      "195  :: 2422\n",
      "196  :: 2410\n",
      "198  :: 2406\n",
      "197  :: 2403\n",
      "199  :: 2386\n",
      "200  :: 2366\n",
      "201  :: 2357\n",
      "202  :: 2348\n",
      "204  :: 2333\n",
      "203  :: 2329\n",
      "205  :: 2323\n",
      "206  :: 2323\n",
      "207  :: 2316\n",
      "208  :: 2304\n",
      "209  :: 2300\n",
      "211  :: 2289\n",
      "210  :: 2287\n",
      "212  :: 2287\n",
      "213  :: 2287\n",
      "215  :: 2286\n",
      "216  :: 2281\n",
      "214  :: 2280\n",
      "217  :: 2274\n",
      "218  :: 2272\n",
      "219  :: 2261\n",
      "221  :: 2252\n",
      "220  :: 2250\n",
      "222  :: 2242\n",
      "223  :: 2242\n",
      "224  :: 2227\n",
      "225  :: 2224\n",
      "226  :: 2222\n",
      "227  :: 2218\n",
      "229  :: 2209\n",
      "228  :: 2205\n",
      "230  :: 2195\n",
      "231  :: 2194\n",
      "232  :: 2193\n",
      "235  :: 2182\n",
      "234  :: 2180\n",
      "233  :: 2177\n",
      "236  :: 2176\n",
      "237  :: 2174\n",
      "238  :: 2164\n",
      "239  :: 2157\n",
      "241  :: 2152\n",
      "240  :: 2151\n",
      "242  :: 2147\n",
      "243  :: 2139\n",
      "244  :: 2123\n",
      "246  :: 2119\n",
      "247  :: 2119\n",
      "245  :: 2115\n",
      "248  :: 2100\n",
      "250  :: 2098\n",
      "249  :: 2094\n",
      "251  :: 2093\n",
      "252  :: 2086\n",
      "254  :: 2064\n",
      "253  :: 2062\n",
      "255  :: 2050\n",
      "256  :: 2040\n",
      "257  :: 2027\n",
      "260  :: 2020\n",
      "259  :: 2019\n",
      "258  :: 2015\n",
      "261  :: 2014\n",
      "262  :: 2002\n",
      "263  :: 2000\n",
      "264  :: 1998\n",
      "265  :: 1998\n",
      "266  :: 1987\n",
      "268  :: 1976\n",
      "267  :: 1975\n",
      "269  :: 1957\n",
      "270  :: 1957\n",
      "272  :: 1954\n",
      "271  :: 1946\n",
      "274  :: 1944\n",
      "275  :: 1942\n",
      "273  :: 1932\n",
      "276  :: 1928\n",
      "277  :: 1923\n",
      "278  :: 1920\n",
      "279  :: 1916\n",
      "280  :: 1913\n",
      "281  :: 1913\n",
      "282  :: 1912\n",
      "284  :: 1906\n",
      "283  :: 1903\n",
      "285  :: 1898\n",
      "287  :: 1898\n",
      "286  :: 1896\n",
      "288  :: 1894\n",
      "289  :: 1891\n",
      "292  :: 1885\n",
      "290  :: 1883\n",
      "291  :: 1877\n",
      "293  :: 1874\n",
      "294  :: 1866\n",
      "296  :: 1866\n",
      "298  :: 1863\n",
      "295  :: 1862\n",
      "297  :: 1859\n",
      "299  :: 1859\n",
      "300  :: 1847\n",
      "301  :: 1847\n",
      "302  :: 1844\n",
      "304  :: 1843\n",
      "303  :: 1837\n",
      "306  :: 1815\n",
      "307  :: 1813\n",
      "308  :: 1811\n",
      "305  :: 1809\n",
      "309  :: 1787\n",
      "311  :: 1784\n",
      "310  :: 1782\n",
      "312  :: 1776\n",
      "314  :: 1772\n",
      "313  :: 1769\n",
      "315  :: 1751\n",
      "316  :: 1736\n",
      "317  :: 1736\n",
      "318  :: 1729\n",
      "320  :: 1726\n",
      "321  :: 1724\n",
      "322  :: 1724\n",
      "319  :: 1722\n",
      "324  :: 1713\n",
      "323  :: 1709\n",
      "325  :: 1702\n",
      "326  :: 1695\n",
      "327  :: 1693\n",
      "329  :: 1683\n",
      "330  :: 1683\n",
      "328  :: 1680\n",
      "331  :: 1677\n",
      "332  :: 1670\n",
      "333  :: 1670\n",
      "334  :: 1663\n",
      "335  :: 1659\n",
      "336  :: 1655\n",
      "338  :: 1648\n",
      "340  :: 1648\n",
      "337  :: 1645\n",
      "339  :: 1643\n",
      "341  :: 1642\n",
      "342  :: 1627\n",
      "343  :: 1610\n",
      "345  :: 1607\n",
      "344  :: 1599\n",
      "346  :: 1599\n",
      "347  :: 1595\n",
      "350  :: 1593\n",
      "349  :: 1592\n",
      "348  :: 1591\n",
      "351  :: 1588\n",
      "352  :: 1587\n",
      "353  :: 1580\n",
      "354  :: 1571\n",
      "355  :: 1562\n",
      "356  :: 1558\n",
      "357  :: 1557\n",
      "358  :: 1550\n",
      "362  :: 1550\n",
      "363  :: 1550\n",
      "360  :: 1547\n",
      "359  :: 1546\n",
      "361  :: 1545\n",
      "365  :: 1544\n",
      "366  :: 1544\n",
      "367  :: 1541\n",
      "364  :: 1540\n",
      "368  :: 1537\n",
      "369  :: 1536\n",
      "370  :: 1529\n",
      "372  :: 1527\n",
      "371  :: 1521\n",
      "374  :: 1518\n",
      "373  :: 1515\n",
      "375  :: 1513\n",
      "376  :: 1510\n",
      "377  :: 1504\n",
      "378  :: 1503\n",
      "379  :: 1503\n",
      "380  :: 1500\n",
      "381  :: 1494\n",
      "382  :: 1488\n",
      "383  :: 1483\n",
      "384  :: 1476\n",
      "385  :: 1470\n",
      "386  :: 1470\n",
      "387  :: 1464\n",
      "389  :: 1459\n",
      "388  :: 1456\n",
      "391  :: 1456\n",
      "390  :: 1455\n",
      "392  :: 1453\n",
      "393  :: 1449\n",
      "394  :: 1429\n",
      "395  :: 1418\n",
      "396  :: 1417\n",
      "397  :: 1413\n",
      "398  :: 1410\n",
      "399  :: 1405\n",
      "400  :: 1400\n",
      "401  :: 1399\n",
      "402  :: 1387\n",
      "404  :: 1375\n",
      "403  :: 1372\n",
      "406  :: 1368\n",
      "405  :: 1367\n",
      "408  :: 1366\n",
      "407  :: 1365\n",
      "410  :: 1364\n",
      "411  :: 1360\n",
      "409  :: 1359\n",
      "413  :: 1355\n",
      "412  :: 1353\n",
      "414  :: 1340\n",
      "418  :: 1326\n",
      "416  :: 1324\n",
      "419  :: 1323\n",
      "415  :: 1322\n",
      "417  :: 1322\n",
      "421  :: 1322\n",
      "420  :: 1321\n",
      "422  :: 1318\n",
      "423  :: 1307\n",
      "425  :: 1304\n",
      "424  :: 1303\n",
      "426  :: 1300\n",
      "427  :: 1288\n",
      "429  :: 1288\n",
      "430  :: 1287\n",
      "428  :: 1284\n",
      "431  :: 1282\n",
      "432  :: 1279\n",
      "435  :: 1278\n",
      "434  :: 1276\n",
      "433  :: 1273\n",
      "436  :: 1267\n",
      "437  :: 1266\n",
      "438  :: 1262\n",
      "440  :: 1259\n",
      "441  :: 1257\n",
      "439  :: 1254\n",
      "442  :: 1254\n",
      "443  :: 1254\n",
      "444  :: 1248\n",
      "445  :: 1246\n",
      "446  :: 1234\n",
      "447  :: 1233\n",
      "448  :: 1226\n",
      "450  :: 1224\n",
      "449  :: 1223\n",
      "451  :: 1213\n",
      "452  :: 1211\n",
      "453  :: 1209\n",
      "455  :: 1204\n",
      "454  :: 1203\n",
      "456  :: 1200\n",
      "458  :: 1197\n",
      "457  :: 1196\n",
      "459  :: 1195\n",
      "460  :: 1190\n",
      "461  :: 1188\n",
      "462  :: 1186\n",
      "464  :: 1180\n",
      "463  :: 1178\n",
      "465  :: 1178\n",
      "466  :: 1177\n",
      "467  :: 1175\n",
      "468  :: 1171\n",
      "469  :: 1169\n",
      "470  :: 1164\n",
      "472  :: 1157\n",
      "473  :: 1156\n",
      "474  :: 1154\n",
      "471  :: 1153\n",
      "475  :: 1147\n",
      "478  :: 1147\n",
      "476  :: 1144\n",
      "479  :: 1144\n",
      "477  :: 1142\n",
      "480  :: 1142\n",
      "482  :: 1127\n",
      "481  :: 1125\n",
      "483  :: 1121\n",
      "484  :: 1114\n",
      "486  :: 1113\n",
      "487  :: 1110\n",
      "485  :: 1108\n",
      "488  :: 1106\n",
      "489  :: 1104\n",
      "490  :: 1101\n",
      "491  :: 1100\n",
      "492  :: 1097\n",
      "496  :: 1095\n",
      "497  :: 1094\n",
      "494  :: 1093\n",
      "493  :: 1092\n",
      "495  :: 1092\n",
      "498  :: 1090\n",
      "500  :: 1089\n",
      "499  :: 1087\n",
      "501  :: 1086\n",
      "502  :: 1079\n",
      "503  :: 1078\n",
      "505  :: 1074\n",
      "506  :: 1072\n",
      "504  :: 1065\n",
      "507  :: 1065\n",
      "509  :: 1063\n",
      "508  :: 1062\n",
      "510  :: 1062\n",
      "511  :: 1059\n",
      "512  :: 1058\n",
      "513  :: 1057\n",
      "517  :: 1055\n",
      "516  :: 1054\n",
      "515  :: 1053\n",
      "519  :: 1053\n",
      "520  :: 1052\n",
      "521  :: 1051\n",
      "518  :: 1050\n",
      "522  :: 1050\n",
      "523  :: 1049\n",
      "526  :: 1049\n",
      "525  :: 1048\n",
      "529  :: 1046\n",
      "524  :: 1044\n",
      "528  :: 1044\n",
      "532  :: 1042\n",
      "527  :: 1040\n",
      "530  :: 1039\n",
      "531  :: 1038\n",
      "533  :: 1037\n",
      "535  :: 1033\n",
      "536  :: 1033\n",
      "534  :: 1031\n",
      "537  :: 1028\n",
      "538  :: 1028\n",
      "514  :: 1027\n",
      "542  :: 1025\n",
      "539  :: 1024\n",
      "541  :: 1024\n",
      "543  :: 1022\n",
      "540  :: 1021\n",
      "544  :: 1021\n",
      "546  :: 1017\n",
      "545  :: 1012\n",
      "547  :: 1012\n",
      "548  :: 1010\n",
      "549  :: 1007\n",
      "552  :: 1005\n",
      "550  :: 1004\n",
      "553  :: 1004\n",
      "554  :: 1002\n",
      "551  :: 1000\n",
      "555  :: 1000\n",
      "556  :: 998\n",
      "558  :: 998\n",
      "560  :: 995\n",
      "563  :: 993\n",
      "559  :: 992\n",
      "565  :: 991\n",
      "561  :: 990\n",
      "562  :: 990\n",
      "564  :: 989\n",
      "557  :: 988\n",
      "566  :: 988\n",
      "567  :: 985\n",
      "568  :: 983\n",
      "569  :: 983\n",
      "570  :: 981\n",
      "571  :: 977\n",
      "572  :: 976\n",
      "573  :: 972\n",
      "574  :: 972\n",
      "575  :: 969\n",
      "577  :: 967\n",
      "576  :: 966\n",
      "579  :: 964\n",
      "578  :: 963\n",
      "580  :: 963\n",
      "583  :: 963\n",
      "581  :: 962\n",
      "582  :: 962\n",
      "585  :: 955\n",
      "584  :: 954\n",
      "587  :: 953\n",
      "586  :: 951\n",
      "588  :: 945\n",
      "592  :: 940\n",
      "590  :: 939\n",
      "594  :: 939\n",
      "593  :: 938\n",
      "589  :: 937\n",
      "591  :: 937\n",
      "597  :: 937\n",
      "596  :: 935\n",
      "599  :: 935\n",
      "602  :: 934\n",
      "595  :: 933\n",
      "601  :: 932\n",
      "603  :: 932\n",
      "598  :: 931\n",
      "604  :: 931\n",
      "605  :: 929\n",
      "606  :: 927\n",
      "607  :: 925\n",
      "600  :: 922\n",
      "608  :: 921\n",
      "610  :: 920\n",
      "612  :: 920\n",
      "614  :: 920\n",
      "609  :: 919\n",
      "611  :: 919\n",
      "615  :: 917\n",
      "613  :: 916\n",
      "618  :: 914\n",
      "619  :: 912\n",
      "617  :: 911\n",
      "616  :: 909\n",
      "621  :: 908\n",
      "623  :: 908\n",
      "620  :: 906\n",
      "622  :: 904\n",
      "625  :: 903\n",
      "627  :: 900\n",
      "628  :: 900\n",
      "630  :: 899\n",
      "631  :: 898\n",
      "624  :: 897\n",
      "626  :: 897\n",
      "637  :: 896\n",
      "633  :: 895\n",
      "638  :: 893\n",
      "629  :: 892\n",
      "635  :: 892\n",
      "632  :: 890\n",
      "634  :: 888\n",
      "639  :: 888\n",
      "640  :: 888\n",
      "636  :: 884\n",
      "642  :: 884\n",
      "641  :: 883\n",
      "644  :: 882\n",
      "643  :: 879\n",
      "645  :: 879\n",
      "646  :: 878\n",
      "647  :: 877\n",
      "648  :: 869\n",
      "649  :: 869\n",
      "650  :: 868\n",
      "651  :: 864\n",
      "653  :: 864\n",
      "652  :: 863\n",
      "654  :: 858\n",
      "655  :: 857\n",
      "656  :: 856\n",
      "658  :: 855\n",
      "657  :: 852\n",
      "659  :: 851\n",
      "663  :: 851\n",
      "661  :: 848\n",
      "662  :: 848\n",
      "665  :: 848\n",
      "664  :: 847\n",
      "660  :: 845\n",
      "667  :: 843\n",
      "666  :: 842\n",
      "668  :: 840\n",
      "669  :: 840\n",
      "670  :: 840\n",
      "671  :: 836\n",
      "672  :: 836\n",
      "673  :: 835\n",
      "674  :: 832\n",
      "675  :: 831\n",
      "677  :: 825\n",
      "678  :: 825\n",
      "676  :: 824\n",
      "679  :: 823\n",
      "680  :: 822\n",
      "682  :: 822\n",
      "681  :: 820\n",
      "683  :: 816\n",
      "684  :: 816\n",
      "685  :: 816\n",
      "689  :: 813\n",
      "686  :: 812\n",
      "688  :: 811\n",
      "690  :: 811\n",
      "687  :: 809\n",
      "692  :: 808\n",
      "694  :: 808\n",
      "693  :: 806\n",
      "695  :: 806\n",
      "697  :: 802\n",
      "696  :: 801\n",
      "700  :: 798\n",
      "701  :: 798\n",
      "703  :: 798\n",
      "699  :: 797\n",
      "698  :: 796\n",
      "704  :: 796\n",
      "702  :: 792\n",
      "707  :: 792\n",
      "691  :: 790\n",
      "705  :: 790\n",
      "708  :: 789\n",
      "706  :: 787\n",
      "709  :: 787\n",
      "712  :: 785\n",
      "710  :: 783\n",
      "717  :: 781\n",
      "715  :: 780\n",
      "713  :: 779\n",
      "716  :: 779\n",
      "711  :: 777\n",
      "714  :: 777\n",
      "719  :: 777\n",
      "720  :: 777\n",
      "718  :: 775\n",
      "722  :: 775\n",
      "721  :: 774\n",
      "724  :: 771\n",
      "726  :: 771\n",
      "725  :: 770\n",
      "728  :: 770\n",
      "723  :: 769\n",
      "729  :: 769\n",
      "730  :: 769\n",
      "731  :: 769\n",
      "727  :: 766\n",
      "733  :: 766\n",
      "732  :: 764\n",
      "734  :: 764\n",
      "735  :: 763\n",
      "737  :: 758\n",
      "739  :: 758\n",
      "736  :: 756\n",
      "738  :: 756\n",
      "740  :: 753\n",
      "743  :: 753\n",
      "744  :: 752\n",
      "741  :: 751\n",
      "748  :: 750\n",
      "747  :: 749\n",
      "749  :: 749\n",
      "742  :: 748\n",
      "745  :: 748\n",
      "750  :: 748\n",
      "746  :: 747\n",
      "751  :: 747\n",
      "752  :: 746\n",
      "754  :: 745\n",
      "753  :: 744\n",
      "759  :: 741\n",
      "756  :: 740\n",
      "757  :: 740\n",
      "758  :: 738\n",
      "762  :: 738\n",
      "760  :: 737\n",
      "761  :: 737\n",
      "764  :: 737\n",
      "763  :: 736\n",
      "755  :: 734\n",
      "765  :: 734\n",
      "766  :: 732\n",
      "767  :: 732\n",
      "768  :: 732\n",
      "769  :: 729\n",
      "770  :: 728\n",
      "771  :: 728\n",
      "773  :: 727\n",
      "775  :: 726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772  :: 725\n",
      "774  :: 724\n",
      "776  :: 724\n",
      "777  :: 722\n",
      "778  :: 722\n",
      "779  :: 722\n",
      "780  :: 719\n",
      "781  :: 718\n",
      "782  :: 716\n",
      "783  :: 714\n",
      "784  :: 713\n",
      "787  :: 712\n",
      "786  :: 710\n",
      "790  :: 710\n",
      "785  :: 709\n",
      "788  :: 709\n",
      "792  :: 709\n",
      "789  :: 708\n",
      "791  :: 708\n",
      "793  :: 708\n",
      "794  :: 706\n",
      "796  :: 706\n",
      "795  :: 704\n",
      "797  :: 702\n",
      "799  :: 701\n",
      "800  :: 701\n",
      "804  :: 701\n",
      "805  :: 701\n",
      "806  :: 701\n",
      "798  :: 700\n",
      "801  :: 700\n",
      "802  :: 700\n",
      "807  :: 699\n",
      "803  :: 698\n",
      "809  :: 698\n",
      "808  :: 697\n",
      "812  :: 697\n",
      "811  :: 696\n",
      "814  :: 695\n",
      "810  :: 694\n",
      "813  :: 692\n",
      "815  :: 691\n",
      "816  :: 691\n",
      "819  :: 688\n",
      "817  :: 686\n",
      "818  :: 686\n",
      "820  :: 685\n",
      "822  :: 685\n",
      "823  :: 684\n",
      "821  :: 683\n",
      "824  :: 682\n",
      "825  :: 680\n",
      "827  :: 676\n",
      "828  :: 676\n",
      "829  :: 674\n",
      "826  :: 673\n",
      "831  :: 672\n",
      "832  :: 672\n",
      "830  :: 671\n",
      "833  :: 670\n",
      "834  :: 669\n",
      "835  :: 665\n",
      "836  :: 665\n",
      "838  :: 664\n",
      "839  :: 664\n",
      "842  :: 662\n",
      "845  :: 662\n",
      "837  :: 660\n",
      "847  :: 660\n",
      "844  :: 659\n",
      "841  :: 658\n",
      "846  :: 658\n",
      "843  :: 657\n",
      "840  :: 656\n",
      "850  :: 656\n",
      "851  :: 656\n",
      "852  :: 656\n",
      "848  :: 655\n",
      "853  :: 655\n",
      "854  :: 654\n",
      "857  :: 654\n",
      "849  :: 653\n",
      "858  :: 653\n",
      "855  :: 652\n",
      "856  :: 651\n",
      "861  :: 648\n",
      "859  :: 647\n",
      "860  :: 647\n",
      "862  :: 647\n",
      "863  :: 643\n",
      "864  :: 642\n",
      "865  :: 641\n",
      "866  :: 640\n",
      "867  :: 638\n",
      "868  :: 638\n",
      "869  :: 636\n",
      "871  :: 634\n",
      "873  :: 634\n",
      "872  :: 633\n",
      "874  :: 633\n",
      "870  :: 632\n",
      "875  :: 629\n",
      "876  :: 629\n",
      "878  :: 628\n",
      "879  :: 627\n",
      "880  :: 627\n",
      "877  :: 624\n",
      "883  :: 624\n",
      "884  :: 624\n",
      "881  :: 623\n",
      "882  :: 623\n",
      "888  :: 621\n",
      "889  :: 620\n",
      "885  :: 619\n",
      "886  :: 619\n",
      "887  :: 619\n",
      "892  :: 619\n",
      "890  :: 618\n",
      "894  :: 617\n",
      "891  :: 616\n",
      "893  :: 615\n",
      "895  :: 614\n",
      "897  :: 614\n",
      "896  :: 613\n",
      "898  :: 613\n",
      "900  :: 610\n",
      "903  :: 608\n",
      "904  :: 608\n",
      "902  :: 607\n",
      "899  :: 606\n",
      "905  :: 605\n",
      "901  :: 603\n",
      "906  :: 603\n",
      "907  :: 603\n",
      "909  :: 603\n",
      "910  :: 602\n",
      "908  :: 601\n",
      "911  :: 601\n",
      "912  :: 599\n",
      "913  :: 599\n",
      "915  :: 598\n",
      "914  :: 597\n",
      "917  :: 596\n",
      "918  :: 596\n",
      "916  :: 595\n",
      "919  :: 595\n",
      "921  :: 595\n",
      "922  :: 594\n",
      "920  :: 593\n",
      "924  :: 593\n",
      "923  :: 591\n",
      "926  :: 589\n",
      "925  :: 588\n",
      "929  :: 587\n",
      "928  :: 586\n",
      "927  :: 584\n",
      "931  :: 584\n",
      "932  :: 584\n",
      "933  :: 581\n",
      "935  :: 580\n",
      "934  :: 579\n",
      "936  :: 579\n",
      "938  :: 577\n",
      "940  :: 577\n",
      "941  :: 577\n",
      "942  :: 576\n",
      "943  :: 575\n",
      "937  :: 574\n",
      "939  :: 574\n",
      "945  :: 574\n",
      "930  :: 573\n",
      "947  :: 573\n",
      "948  :: 573\n",
      "950  :: 573\n",
      "946  :: 572\n",
      "949  :: 572\n",
      "953  :: 572\n",
      "944  :: 571\n",
      "951  :: 571\n",
      "952  :: 571\n",
      "956  :: 570\n",
      "955  :: 569\n",
      "958  :: 568\n",
      "954  :: 567\n",
      "957  :: 566\n",
      "960  :: 566\n",
      "959  :: 565\n",
      "962  :: 565\n",
      "961  :: 564\n",
      "963  :: 564\n",
      "964  :: 563\n",
      "965  :: 563\n",
      "966  :: 563\n",
      "968  :: 561\n",
      "971  :: 561\n",
      "972  :: 560\n",
      "967  :: 559\n",
      "969  :: 559\n",
      "970  :: 558\n",
      "973  :: 558\n",
      "974  :: 557\n",
      "978  :: 555\n",
      "979  :: 555\n",
      "975  :: 554\n",
      "976  :: 554\n",
      "977  :: 554\n",
      "982  :: 553\n",
      "981  :: 552\n",
      "980  :: 551\n",
      "986  :: 550\n",
      "983  :: 549\n",
      "984  :: 549\n",
      "987  :: 549\n",
      "989  :: 548\n",
      "990  :: 548\n",
      "985  :: 547\n",
      "988  :: 546\n",
      "992  :: 546\n",
      "991  :: 543\n",
      "994  :: 542\n",
      "998  :: 542\n",
      "995  :: 541\n",
      "1002  :: 541\n",
      "996  :: 540\n",
      "997  :: 540\n",
      "1001  :: 540\n",
      "999  :: 539\n",
      "1000  :: 539\n",
      "1003  :: 539\n",
      "1004  :: 538\n",
      "1006  :: 538\n",
      "993  :: 537\n",
      "1007  :: 537\n",
      "1008  :: 537\n",
      "1010  :: 537\n",
      "1011  :: 536\n",
      "1005  :: 535\n",
      "1009  :: 534\n",
      "1013  :: 534\n",
      "1015  :: 534\n",
      "1016  :: 534\n",
      "1012  :: 533\n",
      "1014  :: 533\n",
      "1017  :: 530\n",
      "1020  :: 530\n",
      "1018  :: 529\n",
      "1021  :: 527\n",
      "1022  :: 527\n",
      "1023  :: 527\n",
      "1024  :: 525\n",
      "1019  :: 523\n",
      "1027  :: 523\n",
      "1028  :: 523\n",
      "1029  :: 521\n",
      "1026  :: 518\n",
      "1030  :: 517\n",
      "1031  :: 517\n",
      "1032  :: 517\n",
      "1034  :: 515\n",
      "1036  :: 515\n",
      "1038  :: 514\n",
      "1039  :: 514\n",
      "1035  :: 513\n",
      "1037  :: 513\n",
      "1040  :: 512\n",
      "1041  :: 511\n",
      "1042  :: 510\n",
      "1045  :: 510\n",
      "1025  :: 509\n",
      "1033  :: 509\n",
      "1043  :: 509\n",
      "1047  :: 509\n",
      "1044  :: 508\n",
      "1046  :: 508\n",
      "1048  :: 508\n",
      "1050  :: 507\n",
      "1052  :: 506\n",
      "1049  :: 505\n",
      "1053  :: 503\n",
      "1054  :: 503\n",
      "1055  :: 503\n",
      "1057  :: 503\n",
      "1059  :: 503\n",
      "1058  :: 502\n",
      "1062  :: 502\n",
      "1056  :: 501\n",
      "1065  :: 501\n",
      "1063  :: 500\n",
      "1051  :: 499\n",
      "1061  :: 499\n",
      "1066  :: 499\n",
      "1067  :: 499\n",
      "1060  :: 498\n",
      "1064  :: 498\n",
      "1068  :: 498\n",
      "1073  :: 496\n",
      "1070  :: 495\n",
      "1072  :: 495\n",
      "1075  :: 495\n",
      "1069  :: 494\n",
      "1071  :: 493\n",
      "1076  :: 493\n",
      "1078  :: 491\n",
      "1080  :: 491\n",
      "1074  :: 490\n",
      "1079  :: 490\n",
      "1077  :: 489\n",
      "1081  :: 489\n",
      "1083  :: 489\n",
      "1084  :: 489\n",
      "1085  :: 489\n",
      "1086  :: 488\n",
      "1087  :: 488\n",
      "1082  :: 487\n",
      "1088  :: 485\n",
      "1089  :: 485\n",
      "1090  :: 485\n",
      "1092  :: 485\n",
      "1093  :: 485\n",
      "1091  :: 484\n",
      "1094  :: 482\n",
      "1099  :: 482\n",
      "1095  :: 481\n",
      "1097  :: 481\n",
      "1101  :: 481\n",
      "1102  :: 481\n",
      "1096  :: 480\n",
      "1103  :: 480\n",
      "1098  :: 479\n",
      "1100  :: 478\n",
      "1106  :: 478\n",
      "1104  :: 477\n",
      "1107  :: 477\n",
      "1112  :: 477\n",
      "1110  :: 476\n",
      "1111  :: 476\n",
      "1113  :: 476\n",
      "1109  :: 475\n",
      "1115  :: 475\n",
      "1108  :: 473\n",
      "1114  :: 473\n",
      "1116  :: 473\n",
      "1118  :: 473\n",
      "1117  :: 472\n",
      "1119  :: 472\n",
      "1121  :: 471\n",
      "1105  :: 470\n",
      "1120  :: 470\n",
      "1122  :: 470\n",
      "1123  :: 470\n",
      "1125  :: 468\n",
      "1126  :: 468\n",
      "1124  :: 467\n",
      "1127  :: 466\n",
      "1128  :: 466\n",
      "1130  :: 466\n",
      "1131  :: 465\n",
      "1132  :: 465\n",
      "1133  :: 464\n",
      "1140  :: 464\n",
      "1129  :: 463\n",
      "1136  :: 463\n",
      "1141  :: 463\n",
      "1142  :: 463\n",
      "1134  :: 462\n",
      "1138  :: 462\n",
      "1143  :: 462\n",
      "1144  :: 462\n",
      "1137  :: 461\n",
      "1139  :: 461\n",
      "1145  :: 461\n",
      "1147  :: 461\n",
      "1148  :: 460\n",
      "1149  :: 459\n",
      "1150  :: 459\n",
      "1151  :: 458\n",
      "1154  :: 458\n",
      "1155  :: 458\n",
      "1146  :: 457\n",
      "1152  :: 457\n",
      "1157  :: 457\n",
      "1158  :: 457\n",
      "1153  :: 456\n",
      "1159  :: 456\n",
      "1135  :: 455\n",
      "1161  :: 455\n",
      "1156  :: 454\n",
      "1163  :: 454\n",
      "1162  :: 453\n",
      "1164  :: 453\n",
      "1165  :: 453\n",
      "1167  :: 453\n",
      "1160  :: 452\n",
      "1168  :: 452\n",
      "1169  :: 452\n",
      "1170  :: 450\n",
      "1171  :: 450\n",
      "1166  :: 449\n",
      "1172  :: 449\n",
      "1173  :: 449\n",
      "1176  :: 449\n",
      "1177  :: 449\n",
      "1175  :: 448\n",
      "1179  :: 448\n",
      "1178  :: 447\n",
      "1181  :: 447\n",
      "1180  :: 446\n",
      "1182  :: 446\n",
      "1186  :: 446\n",
      "1174  :: 445\n",
      "1184  :: 445\n",
      "1185  :: 445\n",
      "1189  :: 445\n",
      "1188  :: 444\n",
      "1187  :: 443\n",
      "1191  :: 443\n",
      "1192  :: 442\n",
      "1190  :: 441\n",
      "1183  :: 440\n",
      "1194  :: 440\n",
      "1196  :: 437\n",
      "1197  :: 437\n",
      "1199  :: 437\n",
      "1201  :: 437\n",
      "1195  :: 436\n",
      "1198  :: 435\n",
      "1193  :: 434\n",
      "1204  :: 434\n",
      "1205  :: 434\n",
      "1200  :: 433\n",
      "1202  :: 433\n",
      "1209  :: 433\n",
      "1208  :: 432\n",
      "1207  :: 430\n",
      "1210  :: 430\n",
      "1203  :: 429\n",
      "1211  :: 429\n",
      "1213  :: 429\n",
      "1217  :: 428\n",
      "1218  :: 428\n",
      "1206  :: 427\n",
      "1212  :: 427\n",
      "1214  :: 427\n",
      "1215  :: 426\n",
      "1216  :: 426\n",
      "1220  :: 426\n",
      "1219  :: 425\n",
      "1223  :: 425\n",
      "1225  :: 425\n",
      "1221  :: 424\n",
      "1222  :: 424\n",
      "1224  :: 424\n",
      "1226  :: 424\n",
      "1228  :: 424\n",
      "1231  :: 424\n",
      "1229  :: 423\n",
      "1233  :: 423\n",
      "1227  :: 422\n",
      "1230  :: 422\n",
      "1234  :: 422\n",
      "1232  :: 421\n",
      "1236  :: 421\n",
      "1235  :: 420\n",
      "1237  :: 420\n",
      "1241  :: 420\n",
      "1238  :: 419\n",
      "1239  :: 419\n",
      "1240  :: 419\n",
      "1242  :: 419\n",
      "1243  :: 418\n",
      "1244  :: 418\n",
      "1245  :: 418\n",
      "1247  :: 418\n",
      "1246  :: 417\n",
      "1250  :: 417\n",
      "1252  :: 417\n",
      "1249  :: 416\n",
      "1248  :: 415\n",
      "1251  :: 415\n",
      "1253  :: 415\n",
      "1254  :: 415\n",
      "1259  :: 414\n",
      "1257  :: 413\n",
      "1258  :: 413\n",
      "1262  :: 413\n",
      "1255  :: 411\n",
      "1256  :: 411\n",
      "1260  :: 411\n",
      "1263  :: 411\n",
      "1264  :: 411\n",
      "1265  :: 410\n",
      "1261  :: 409\n",
      "1268  :: 409\n",
      "1270  :: 409\n",
      "1267  :: 408\n",
      "1271  :: 408\n",
      "1272  :: 408\n",
      "1266  :: 407\n",
      "1273  :: 407\n",
      "1274  :: 407\n",
      "1269  :: 406\n",
      "1277  :: 406\n",
      "1279  :: 406\n",
      "1278  :: 405\n",
      "1275  :: 404\n",
      "1276  :: 404\n",
      "1280  :: 404\n",
      "1281  :: 404\n",
      "1285  :: 403\n",
      "1286  :: 403\n",
      "1282  :: 402\n",
      "1283  :: 402\n",
      "1284  :: 402\n",
      "1287  :: 402\n",
      "1288  :: 401\n",
      "1291  :: 400\n",
      "1289  :: 399\n",
      "1290  :: 399\n",
      "1292  :: 399\n",
      "1297  :: 398\n",
      "1293  :: 397\n",
      "1294  :: 397\n",
      "1298  :: 397\n",
      "1299  :: 397\n",
      "1296  :: 396\n",
      "1301  :: 396\n",
      "1300  :: 395\n",
      "1302  :: 394\n",
      "1304  :: 394\n",
      "1303  :: 393\n",
      "1305  :: 393\n",
      "1307  :: 393\n",
      "1309  :: 393\n",
      "1311  :: 392\n",
      "1306  :: 391\n",
      "1310  :: 391\n",
      "1312  :: 391\n",
      "1314  :: 391\n",
      "1315  :: 391\n",
      "1316  :: 391\n",
      "1308  :: 390\n",
      "1317  :: 390\n",
      "1318  :: 390\n",
      "1313  :: 389\n",
      "1320  :: 389\n",
      "1321  :: 389\n",
      "1322  :: 389\n",
      "1324  :: 388\n",
      "1326  :: 388\n",
      "1319  :: 387\n",
      "1323  :: 387\n",
      "1325  :: 387\n",
      "1327  :: 387\n",
      "1328  :: 387\n",
      "1329  :: 386\n",
      "1332  :: 385\n",
      "1330  :: 384\n",
      "1331  :: 384\n",
      "1334  :: 384\n",
      "1333  :: 383\n",
      "1336  :: 383\n",
      "1335  :: 382\n",
      "1337  :: 382\n",
      "1338  :: 381\n",
      "1341  :: 381\n",
      "1342  :: 381\n",
      "1339  :: 380\n",
      "1340  :: 380\n",
      "1343  :: 380\n",
      "1346  :: 379\n",
      "1347  :: 379\n",
      "1348  :: 379\n",
      "1344  :: 378\n",
      "1345  :: 378\n",
      "1350  :: 378\n",
      "1349  :: 377\n",
      "1353  :: 376\n",
      "1355  :: 376\n",
      "1357  :: 376\n",
      "1351  :: 375\n",
      "1352  :: 375\n",
      "1356  :: 375\n",
      "1358  :: 375\n",
      "1354  :: 374\n",
      "1361  :: 374\n",
      "1295  :: 373\n",
      "1359  :: 373\n",
      "1362  :: 373\n",
      "1363  :: 373\n",
      "1364  :: 373\n",
      "1365  :: 372\n",
      "1367  :: 372\n",
      "1368  :: 372\n",
      "1360  :: 370\n",
      "1366  :: 370\n",
      "1374  :: 370\n",
      "1375  :: 370\n",
      "1369  :: 369\n",
      "1370  :: 369\n",
      "1372  :: 369\n",
      "1376  :: 369\n",
      "1378  :: 369\n",
      "1371  :: 368\n",
      "1377  :: 368\n",
      "1380  :: 368\n",
      "1381  :: 368\n",
      "1385  :: 368\n",
      "1379  :: 367\n",
      "1383  :: 367\n",
      "1384  :: 367\n",
      "1386  :: 367\n",
      "1387  :: 367\n",
      "1373  :: 366\n",
      "1382  :: 366\n",
      "1388  :: 366\n",
      "1389  :: 366\n",
      "1390  :: 365\n",
      "1395  :: 365\n",
      "1391  :: 364\n",
      "1392  :: 364\n",
      "1393  :: 364\n",
      "1396  :: 364\n",
      "1397  :: 363\n",
      "1399  :: 362\n",
      "1394  :: 361\n",
      "1400  :: 361\n",
      "1401  :: 360\n",
      "1404  :: 360\n",
      "1405  :: 360\n",
      "1398  :: 359\n",
      "1403  :: 359\n",
      "1406  :: 358\n",
      "1407  :: 358\n",
      "1408  :: 358\n",
      "1411  :: 358\n",
      "1409  :: 357\n",
      "1410  :: 357\n",
      "1412  :: 357\n",
      "1413  :: 357\n",
      "1415  :: 357\n",
      "1402  :: 356\n",
      "1417  :: 356\n",
      "1418  :: 355\n",
      "1420  :: 355\n",
      "1421  :: 355\n",
      "1423  :: 355\n",
      "1419  :: 354\n",
      "1422  :: 354\n",
      "1414  :: 353\n",
      "1428  :: 353\n",
      "1424  :: 352\n",
      "1425  :: 352\n",
      "1426  :: 352\n",
      "1431  :: 352\n",
      "1432  :: 352\n",
      "1427  :: 351\n",
      "1429  :: 351\n",
      "1430  :: 351\n",
      "1433  :: 351\n",
      "1435  :: 351\n",
      "1436  :: 350\n",
      "1437  :: 350\n",
      "1434  :: 349\n",
      "1440  :: 349\n",
      "1438  :: 348\n",
      "1442  :: 348\n",
      "1441  :: 347\n",
      "1443  :: 347\n",
      "1444  :: 347\n",
      "1447  :: 347\n",
      "1450  :: 347\n",
      "1445  :: 346\n",
      "1446  :: 346\n",
      "1448  :: 346\n",
      "1451  :: 346\n",
      "1452  :: 345\n",
      "1453  :: 345\n",
      "1455  :: 344\n",
      "1462  :: 344\n",
      "1439  :: 343\n",
      "1454  :: 343\n",
      "1456  :: 343\n",
      "1458  :: 343\n",
      "1459  :: 343\n",
      "1460  :: 343\n",
      "1461  :: 343\n",
      "1464  :: 343\n",
      "1457  :: 342\n",
      "1465  :: 342\n",
      "1467  :: 342\n",
      "1468  :: 342\n",
      "1449  :: 341\n",
      "1463  :: 341\n",
      "1469  :: 341\n",
      "1471  :: 341\n",
      "1472  :: 341\n",
      "1475  :: 341\n",
      "1466  :: 340\n",
      "1470  :: 340\n",
      "1474  :: 339\n",
      "1479  :: 339\n",
      "1416  :: 338\n",
      "1476  :: 338\n",
      "1480  :: 338\n",
      "1481  :: 338\n",
      "1483  :: 338\n",
      "1473  :: 337\n",
      "1477  :: 337\n",
      "1478  :: 337\n",
      "1482  :: 337\n",
      "1484  :: 337\n",
      "1485  :: 337\n",
      "1487  :: 336\n",
      "1488  :: 336\n",
      "1489  :: 335\n",
      "1490  :: 335\n",
      "1486  :: 334\n",
      "1492  :: 334\n",
      "1491  :: 333\n",
      "1495  :: 332\n",
      "1493  :: 331\n",
      "1494  :: 331\n",
      "1497  :: 331\n",
      "1499  :: 331\n",
      "1496  :: 330\n",
      "1498  :: 330\n",
      "1500  :: 330\n",
      "1501  :: 330\n",
      "1504  :: 330\n",
      "1505  :: 330\n",
      "1502  :: 329\n",
      "1503  :: 329\n",
      "1506  :: 329\n",
      "1507  :: 329\n",
      "1508  :: 328\n",
      "1512  :: 328\n",
      "1510  :: 327\n",
      "1511  :: 327\n",
      "1514  :: 327\n",
      "1516  :: 327\n",
      "1517  :: 327\n",
      "1509  :: 326\n",
      "1519  :: 326\n",
      "1515  :: 325\n",
      "1518  :: 325\n",
      "1521  :: 325\n",
      "1513  :: 324\n",
      "1520  :: 324\n",
      "1526  :: 324\n",
      "1523  :: 323\n",
      "1524  :: 323\n",
      "1525  :: 323\n",
      "1522  :: 322\n",
      "1527  :: 322\n",
      "1528  :: 322\n",
      "1530  :: 322\n",
      "1531  :: 321\n",
      "1532  :: 321\n",
      "1529  :: 320\n",
      "1534  :: 320\n",
      "1536  :: 320\n",
      "1537  :: 320\n",
      "1538  :: 320\n",
      "1539  :: 319\n",
      "1541  :: 319\n",
      "1542  :: 319\n",
      "1535  :: 318\n",
      "1533  :: 317\n",
      "1540  :: 317\n",
      "1544  :: 317\n",
      "1545  :: 317\n",
      "1547  :: 317\n",
      "1548  :: 317\n",
      "1550  :: 316\n",
      "1551  :: 316\n",
      "1543  :: 315\n",
      "1549  :: 315\n",
      "1552  :: 315\n",
      "1553  :: 315\n",
      "1546  :: 314\n",
      "1555  :: 314\n",
      "1557  :: 314\n",
      "1558  :: 312\n",
      "1560  :: 312\n",
      "1561  :: 311\n",
      "1564  :: 311\n",
      "1565  :: 311\n",
      "1566  :: 311\n",
      "1567  :: 311\n",
      "1568  :: 311\n",
      "1554  :: 310\n",
      "1556  :: 310\n",
      "1559  :: 310\n",
      "1562  :: 310\n",
      "1570  :: 310\n",
      "1563  :: 309\n",
      "1571  :: 309\n",
      "1572  :: 309\n",
      "1573  :: 309\n",
      "1575  :: 309\n",
      "1569  :: 308\n",
      "1574  :: 308\n",
      "1577  :: 308\n",
      "1579  :: 308\n",
      "1578  :: 307\n",
      "1581  :: 307\n",
      "1585  :: 307\n",
      "1576  :: 306\n",
      "1580  :: 306\n",
      "1583  :: 306\n",
      "1590  :: 306\n",
      "1582  :: 305\n",
      "1584  :: 305\n",
      "1586  :: 305\n",
      "1587  :: 305\n",
      "1589  :: 305\n",
      "1592  :: 305\n",
      "1597  :: 305\n",
      "1588  :: 304\n",
      "1594  :: 304\n",
      "1596  :: 304\n",
      "1599  :: 304\n",
      "1601  :: 304\n",
      "1591  :: 303\n",
      "1593  :: 303\n",
      "1595  :: 303\n",
      "1598  :: 303\n",
      "1600  :: 303\n",
      "1602  :: 303\n",
      "1603  :: 302\n",
      "1604  :: 302\n",
      "1606  :: 302\n",
      "1608  :: 302\n",
      "1610  :: 302\n",
      "1613  :: 302\n",
      "1614  :: 302\n",
      "1605  :: 301\n",
      "1607  :: 301\n",
      "1609  :: 301\n",
      "1611  :: 301\n",
      "1612  :: 301\n",
      "1615  :: 301\n",
      "1616  :: 301\n",
      "1618  :: 301\n",
      "1619  :: 300\n",
      "1620  :: 300\n",
      "1622  :: 300\n",
      "1617  :: 299\n",
      "1621  :: 299\n",
      "1624  :: 299\n",
      "1625  :: 299\n",
      "1626  :: 298\n",
      "1627  :: 297\n",
      "1632  :: 297\n",
      "1635  :: 297\n",
      "1623  :: 296\n",
      "1631  :: 296\n",
      "1634  :: 296\n",
      "1636  :: 296\n",
      "1637  :: 296\n",
      "1640  :: 296\n",
      "1628  :: 295\n",
      "1629  :: 295\n",
      "1639  :: 295\n",
      "1641  :: 295\n",
      "1642  :: 295\n",
      "1630  :: 294\n",
      "1633  :: 294\n",
      "1643  :: 293\n",
      "1644  :: 293\n",
      "1646  :: 293\n",
      "1647  :: 293\n",
      "1650  :: 293\n",
      "1653  :: 293\n",
      "1654  :: 293\n",
      "1645  :: 292\n",
      "1648  :: 292\n",
      "1649  :: 292\n",
      "1651  :: 292\n",
      "1655  :: 292\n",
      "1656  :: 292\n",
      "1657  :: 292\n",
      "1652  :: 291\n",
      "1659  :: 291\n",
      "1662  :: 291\n",
      "1660  :: 290\n",
      "1661  :: 290\n",
      "1665  :: 290\n",
      "1670  :: 290\n",
      "1638  :: 289\n",
      "1658  :: 289\n",
      "1666  :: 289\n",
      "1667  :: 289\n",
      "1668  :: 289\n",
      "1673  :: 289\n",
      "1674  :: 289\n",
      "1676  :: 289\n",
      "1663  :: 288\n",
      "1669  :: 288\n",
      "1672  :: 288\n",
      "1675  :: 288\n",
      "1678  :: 288\n",
      "1679  :: 288\n",
      "1680  :: 288\n",
      "1677  :: 287\n",
      "1681  :: 287\n",
      "1682  :: 287\n",
      "1683  :: 287\n",
      "1664  :: 286\n",
      "1671  :: 286\n",
      "1685  :: 286\n",
      "1690  :: 286\n",
      "1686  :: 285\n",
      "1687  :: 285\n",
      "1694  :: 285\n",
      "1684  :: 284\n",
      "1688  :: 284\n",
      "1691  :: 284\n",
      "1692  :: 284\n",
      "1693  :: 284\n",
      "1695  :: 284\n",
      "1696  :: 284\n",
      "1699  :: 284\n",
      "1689  :: 283\n",
      "1697  :: 283\n",
      "1698  :: 283\n",
      "1701  :: 283\n",
      "1702  :: 283\n",
      "1703  :: 283\n",
      "1705  :: 283\n",
      "1700  :: 282\n",
      "1704  :: 282\n",
      "1706  :: 282\n",
      "1709  :: 281\n",
      "1710  :: 281\n",
      "1711  :: 281\n",
      "1708  :: 280\n",
      "1712  :: 280\n",
      "1713  :: 279\n",
      "1715  :: 279\n",
      "1718  :: 279\n",
      "1719  :: 279\n",
      "1714  :: 278\n",
      "1716  :: 278\n",
      "1720  :: 278\n",
      "1721  :: 278\n",
      "1724  :: 278\n",
      "1725  :: 278\n",
      "1707  :: 277\n",
      "1722  :: 277\n",
      "1723  :: 277\n",
      "1728  :: 277\n",
      "1731  :: 277\n",
      "1726  :: 276\n",
      "1729  :: 276\n",
      "1734  :: 276\n",
      "1738  :: 276\n",
      "1739  :: 276\n",
      "1732  :: 275\n",
      "1737  :: 275\n",
      "1740  :: 275\n",
      "1741  :: 275\n",
      "1742  :: 275\n",
      "1744  :: 275\n",
      "1745  :: 275\n",
      "1746  :: 275\n",
      "1717  :: 274\n",
      "1730  :: 274\n",
      "1727  :: 273\n",
      "1733  :: 273\n",
      "1735  :: 273\n",
      "1743  :: 273\n",
      "1747  :: 273\n",
      "1748  :: 273\n",
      "1750  :: 273\n",
      "1751  :: 273\n",
      "1755  :: 273\n",
      "1749  :: 272\n",
      "1756  :: 272\n",
      "1757  :: 272\n",
      "1736  :: 271\n",
      "1753  :: 271\n",
      "1752  :: 270\n",
      "1758  :: 270\n",
      "1763  :: 270\n",
      "1760  :: 269\n",
      "1761  :: 269\n",
      "1762  :: 269\n",
      "1765  :: 269\n",
      "1767  :: 269\n",
      "1754  :: 268\n",
      "1766  :: 268\n",
      "1769  :: 268\n",
      "1770  :: 268\n",
      "1771  :: 268\n",
      "1774  :: 268\n",
      "1772  :: 267\n",
      "1773  :: 267\n",
      "1775  :: 267\n",
      "1778  :: 267\n",
      "1779  :: 267\n",
      "1777  :: 266\n",
      "1780  :: 266\n",
      "1781  :: 266\n",
      "1782  :: 266\n",
      "1784  :: 266\n",
      "1783  :: 265\n",
      "1785  :: 265\n",
      "1786  :: 265\n",
      "1787  :: 265\n",
      "1789  :: 265\n",
      "1792  :: 265\n",
      "1759  :: 264\n",
      "1764  :: 264\n",
      "1788  :: 264\n",
      "1795  :: 264\n",
      "1776  :: 263\n",
      "1791  :: 263\n",
      "1793  :: 263\n",
      "1794  :: 263\n",
      "1797  :: 263\n",
      "1799  :: 263\n",
      "1800  :: 263\n",
      "1801  :: 263\n",
      "1802  :: 263\n",
      "1803  :: 263\n",
      "1804  :: 263\n",
      "1790  :: 262\n",
      "1796  :: 262\n",
      "1798  :: 262\n",
      "1805  :: 262\n",
      "1806  :: 262\n",
      "1809  :: 262\n",
      "1810  :: 262\n",
      "1811  :: 262\n",
      "1807  :: 261\n",
      "1808  :: 261\n",
      "1815  :: 260\n",
      "1816  :: 260\n",
      "1819  :: 260\n",
      "1813  :: 259\n",
      "1814  :: 259\n",
      "1818  :: 259\n",
      "1820  :: 259\n",
      "1822  :: 259\n",
      "1817  :: 258\n",
      "1825  :: 258\n",
      "1827  :: 258\n",
      "1812  :: 257\n",
      "1821  :: 257\n",
      "1823  :: 257\n",
      "1824  :: 257\n",
      "1826  :: 257\n",
      "1828  :: 257\n",
      "1830  :: 257\n",
      "1829  :: 256\n",
      "1832  :: 256\n",
      "1835  :: 256\n",
      "1836  :: 256\n",
      "1838  :: 256\n",
      "1768  :: 255\n",
      "1833  :: 255\n",
      "1837  :: 255\n",
      "1839  :: 255\n",
      "1841  :: 255\n",
      "1842  :: 255\n",
      "1834  :: 254\n",
      "1840  :: 254\n",
      "1843  :: 254\n",
      "1844  :: 254\n",
      "1845  :: 254\n",
      "1847  :: 254\n",
      "1831  :: 253\n",
      "1849  :: 253\n",
      "1850  :: 252\n",
      "1853  :: 252\n",
      "1854  :: 252\n",
      "1855  :: 252\n",
      "1856  :: 252\n",
      "1857  :: 252\n",
      "1848  :: 251\n",
      "1851  :: 251\n",
      "1858  :: 251\n",
      "1860  :: 251\n",
      "1861  :: 251\n",
      "1846  :: 250\n",
      "1852  :: 250\n",
      "1862  :: 250\n",
      "1863  :: 250\n",
      "1864  :: 249\n",
      "1867  :: 249\n",
      "1868  :: 249\n",
      "1871  :: 249\n",
      "1872  :: 249\n",
      "1873  :: 249\n",
      "1874  :: 249\n",
      "1876  :: 249\n",
      "1877  :: 249\n",
      "1878  :: 249\n",
      "1879  :: 249\n",
      "1859  :: 248\n",
      "1865  :: 248\n",
      "1869  :: 248\n",
      "1880  :: 248\n",
      "1882  :: 248\n",
      "1886  :: 248\n",
      "1888  :: 248\n",
      "1889  :: 248\n",
      "1890  :: 248\n",
      "1866  :: 247\n",
      "1870  :: 247\n",
      "1881  :: 247\n",
      "1884  :: 247\n",
      "1885  :: 247\n",
      "1891  :: 247\n",
      "1892  :: 247\n",
      "1894  :: 247\n",
      "1896  :: 247\n",
      "1897  :: 247\n",
      "1875  :: 246\n",
      "1883  :: 246\n",
      "1887  :: 246\n",
      "1893  :: 246\n",
      "1899  :: 246\n",
      "1900  :: 246\n",
      "1901  :: 246\n",
      "1902  :: 246\n",
      "1903  :: 246\n",
      "1906  :: 246\n",
      "1907  :: 245\n",
      "1908  :: 245\n",
      "1909  :: 245\n",
      "1895  :: 244\n",
      "1898  :: 244\n",
      "1904  :: 244\n",
      "1905  :: 244\n",
      "1910  :: 244\n",
      "1911  :: 243\n",
      "1912  :: 243\n",
      "1913  :: 243\n",
      "1915  :: 243\n",
      "1917  :: 243\n",
      "1918  :: 243\n",
      "1920  :: 243\n",
      "1914  :: 242\n",
      "1919  :: 242\n",
      "1922  :: 242\n",
      "1924  :: 242\n",
      "1925  :: 242\n",
      "1926  :: 242\n",
      "1916  :: 241\n",
      "1921  :: 241\n",
      "1923  :: 241\n",
      "1931  :: 241\n",
      "1928  :: 240\n",
      "1929  :: 240\n",
      "1932  :: 240\n",
      "1927  :: 239\n",
      "1930  :: 239\n",
      "1933  :: 239\n",
      "1935  :: 239\n",
      "1936  :: 239\n",
      "1937  :: 239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940  :: 239\n",
      "1941  :: 239\n",
      "1938  :: 238\n",
      "1943  :: 238\n",
      "1944  :: 238\n",
      "1945  :: 238\n",
      "1939  :: 237\n",
      "1942  :: 237\n",
      "1949  :: 237\n",
      "1950  :: 237\n",
      "1951  :: 237\n",
      "1952  :: 237\n",
      "1946  :: 236\n",
      "1947  :: 236\n",
      "1948  :: 236\n",
      "1953  :: 236\n",
      "1957  :: 236\n",
      "1960  :: 236\n",
      "1961  :: 236\n",
      "1962  :: 236\n",
      "1955  :: 235\n",
      "1956  :: 235\n",
      "1958  :: 235\n",
      "1959  :: 235\n",
      "1965  :: 235\n",
      "1967  :: 235\n",
      "1970  :: 235\n",
      "1934  :: 234\n",
      "1954  :: 234\n",
      "1963  :: 234\n",
      "1964  :: 234\n",
      "1966  :: 234\n",
      "1968  :: 234\n",
      "1969  :: 234\n",
      "1971  :: 234\n",
      "1973  :: 234\n",
      "1972  :: 233\n",
      "1975  :: 233\n",
      "1976  :: 233\n",
      "1978  :: 233\n",
      "1974  :: 232\n",
      "1980  :: 232\n",
      "1982  :: 232\n",
      "1984  :: 232\n",
      "1985  :: 232\n",
      "1979  :: 231\n",
      "1981  :: 231\n",
      "1983  :: 231\n",
      "1986  :: 231\n",
      "1977  :: 230\n",
      "1989  :: 230\n",
      "1992  :: 230\n",
      "1994  :: 230\n",
      "1997  :: 230\n",
      "1998  :: 230\n",
      "1988  :: 229\n",
      "1993  :: 229\n",
      "1995  :: 229\n",
      "1999  :: 229\n",
      "2002  :: 229\n",
      "1987  :: 228\n",
      "1991  :: 228\n",
      "2000  :: 228\n",
      "2003  :: 228\n",
      "2004  :: 228\n",
      "1990  :: 227\n",
      "1996  :: 227\n",
      "2001  :: 227\n",
      "2005  :: 227\n",
      "2009  :: 227\n",
      "2011  :: 227\n",
      "2015  :: 227\n",
      "2017  :: 227\n",
      "2006  :: 226\n",
      "2008  :: 226\n",
      "2010  :: 226\n",
      "2012  :: 226\n",
      "2013  :: 226\n",
      "2014  :: 226\n",
      "2016  :: 226\n",
      "2019  :: 226\n",
      "2020  :: 226\n",
      "2021  :: 226\n",
      "2024  :: 226\n",
      "2018  :: 225\n",
      "2023  :: 225\n",
      "2025  :: 225\n",
      "2026  :: 225\n",
      "2022  :: 224\n",
      "2028  :: 224\n",
      "2029  :: 224\n",
      "2030  :: 224\n",
      "2031  :: 224\n",
      "2032  :: 223\n",
      "2033  :: 223\n",
      "2034  :: 223\n",
      "2027  :: 222\n",
      "2035  :: 222\n",
      "2036  :: 222\n",
      "2041  :: 222\n",
      "2042  :: 222\n",
      "2044  :: 222\n",
      "2045  :: 222\n",
      "2047  :: 222\n",
      "2048  :: 222\n",
      "2049  :: 222\n",
      "2037  :: 221\n",
      "2040  :: 221\n",
      "2043  :: 221\n",
      "2046  :: 221\n",
      "2050  :: 221\n",
      "2038  :: 220\n",
      "2054  :: 220\n",
      "2052  :: 219\n",
      "2055  :: 219\n",
      "2056  :: 219\n",
      "2057  :: 219\n",
      "2060  :: 219\n",
      "2061  :: 219\n",
      "2039  :: 218\n",
      "2051  :: 218\n",
      "2053  :: 218\n",
      "2059  :: 218\n",
      "2064  :: 218\n",
      "2065  :: 218\n",
      "2062  :: 217\n",
      "2063  :: 217\n",
      "2066  :: 217\n",
      "2067  :: 217\n",
      "2068  :: 217\n",
      "2071  :: 217\n",
      "2058  :: 216\n",
      "2069  :: 216\n",
      "2070  :: 216\n",
      "2072  :: 216\n",
      "2074  :: 216\n",
      "2075  :: 216\n",
      "2076  :: 216\n",
      "2078  :: 216\n",
      "2079  :: 216\n",
      "2081  :: 216\n",
      "2082  :: 216\n",
      "2073  :: 215\n",
      "2077  :: 215\n",
      "2083  :: 215\n",
      "2084  :: 215\n",
      "2085  :: 215\n",
      "2086  :: 215\n",
      "2088  :: 214\n",
      "2090  :: 214\n",
      "2092  :: 214\n",
      "2094  :: 214\n",
      "2080  :: 213\n",
      "2091  :: 213\n",
      "2095  :: 213\n",
      "2097  :: 213\n",
      "2099  :: 213\n",
      "2100  :: 213\n",
      "2101  :: 213\n",
      "2007  :: 212\n",
      "2087  :: 212\n",
      "2093  :: 212\n",
      "2096  :: 212\n",
      "2098  :: 212\n",
      "2102  :: 212\n",
      "2105  :: 212\n",
      "2106  :: 212\n",
      "2103  :: 211\n",
      "2104  :: 211\n",
      "2108  :: 211\n",
      "2109  :: 211\n",
      "2110  :: 211\n",
      "2112  :: 211\n",
      "2113  :: 211\n",
      "2114  :: 211\n",
      "2115  :: 211\n",
      "2107  :: 210\n",
      "2111  :: 210\n",
      "2117  :: 210\n",
      "2119  :: 210\n",
      "2120  :: 210\n",
      "2121  :: 210\n",
      "2122  :: 210\n",
      "2118  :: 209\n",
      "2123  :: 209\n",
      "2124  :: 209\n",
      "2125  :: 209\n",
      "2126  :: 209\n",
      "2116  :: 208\n",
      "2127  :: 208\n",
      "2128  :: 208\n",
      "2129  :: 208\n",
      "2130  :: 208\n",
      "2131  :: 208\n",
      "2132  :: 208\n",
      "2135  :: 208\n",
      "2136  :: 208\n",
      "2138  :: 208\n",
      "2139  :: 208\n",
      "2141  :: 208\n",
      "2133  :: 207\n",
      "2134  :: 207\n",
      "2142  :: 207\n",
      "2143  :: 207\n",
      "2147  :: 207\n",
      "2140  :: 206\n",
      "2144  :: 206\n",
      "2145  :: 206\n",
      "2146  :: 206\n",
      "2148  :: 206\n",
      "2149  :: 206\n",
      "2152  :: 206\n",
      "2153  :: 206\n",
      "2154  :: 206\n",
      "2137  :: 205\n",
      "2150  :: 205\n",
      "2151  :: 205\n",
      "2161  :: 205\n",
      "2155  :: 204\n",
      "2156  :: 204\n",
      "2160  :: 204\n",
      "2162  :: 204\n",
      "2163  :: 204\n",
      "2165  :: 204\n",
      "2166  :: 204\n",
      "2167  :: 204\n",
      "2168  :: 204\n",
      "2171  :: 204\n",
      "2157  :: 203\n",
      "2158  :: 203\n",
      "2159  :: 203\n",
      "2164  :: 203\n",
      "2169  :: 203\n",
      "2170  :: 203\n",
      "2173  :: 203\n",
      "2175  :: 203\n",
      "2176  :: 203\n",
      "2177  :: 202\n",
      "2178  :: 202\n",
      "2179  :: 202\n",
      "2180  :: 202\n",
      "2181  :: 202\n",
      "2183  :: 202\n",
      "2185  :: 201\n",
      "2186  :: 201\n",
      "2187  :: 201\n",
      "2188  :: 201\n",
      "2189  :: 201\n",
      "2190  :: 201\n",
      "2191  :: 201\n",
      "2192  :: 201\n",
      "2195  :: 201\n",
      "2172  :: 200\n",
      "2174  :: 200\n",
      "2182  :: 200\n",
      "2198  :: 200\n",
      "2200  :: 200\n",
      "2201  :: 200\n",
      "2202  :: 200\n",
      "2203  :: 200\n",
      "2204  :: 200\n",
      "2184  :: 199\n",
      "2193  :: 199\n",
      "2194  :: 199\n",
      "2196  :: 199\n",
      "2197  :: 199\n",
      "2207  :: 199\n",
      "2209  :: 199\n",
      "2210  :: 199\n",
      "2212  :: 199\n",
      "2213  :: 199\n",
      "2215  :: 199\n",
      "2216  :: 199\n",
      "2217  :: 199\n",
      "2218  :: 199\n",
      "2219  :: 199\n",
      "2089  :: 198\n",
      "2205  :: 198\n",
      "2214  :: 198\n",
      "2220  :: 198\n",
      "2221  :: 198\n",
      "2223  :: 198\n",
      "2224  :: 198\n",
      "2225  :: 198\n",
      "2199  :: 197\n",
      "2206  :: 197\n",
      "2208  :: 197\n",
      "2211  :: 197\n",
      "2227  :: 197\n",
      "2228  :: 197\n",
      "2230  :: 197\n",
      "2234  :: 197\n",
      "2235  :: 197\n",
      "2222  :: 196\n",
      "2226  :: 196\n",
      "2229  :: 196\n",
      "2231  :: 196\n",
      "2233  :: 196\n",
      "2236  :: 196\n",
      "2239  :: 196\n",
      "2242  :: 196\n",
      "2243  :: 196\n",
      "2237  :: 195\n",
      "2240  :: 195\n",
      "2241  :: 195\n",
      "2244  :: 195\n",
      "2247  :: 195\n",
      "2248  :: 195\n",
      "2249  :: 195\n",
      "2251  :: 195\n",
      "2253  :: 195\n",
      "2256  :: 195\n",
      "2257  :: 195\n",
      "2238  :: 194\n",
      "2245  :: 194\n",
      "2250  :: 194\n",
      "2252  :: 194\n",
      "2254  :: 194\n",
      "2255  :: 194\n",
      "2259  :: 194\n",
      "2260  :: 194\n",
      "2262  :: 194\n",
      "2263  :: 194\n",
      "2232  :: 193\n",
      "2246  :: 193\n",
      "2261  :: 193\n",
      "2265  :: 193\n",
      "2268  :: 193\n",
      "2269  :: 193\n",
      "2270  :: 193\n",
      "2271  :: 193\n",
      "2272  :: 193\n",
      "2273  :: 193\n",
      "2258  :: 192\n",
      "2264  :: 192\n",
      "2266  :: 192\n",
      "2267  :: 192\n",
      "2274  :: 192\n",
      "2275  :: 192\n",
      "2276  :: 192\n",
      "2279  :: 192\n",
      "2280  :: 192\n",
      "2281  :: 192\n",
      "2283  :: 192\n",
      "2284  :: 192\n",
      "2282  :: 191\n",
      "2285  :: 191\n",
      "2286  :: 191\n",
      "2287  :: 191\n",
      "2288  :: 191\n",
      "2292  :: 191\n",
      "2293  :: 191\n",
      "2277  :: 190\n",
      "2278  :: 190\n",
      "2290  :: 190\n",
      "2291  :: 190\n",
      "2294  :: 190\n",
      "2295  :: 190\n",
      "2296  :: 190\n",
      "2300  :: 190\n",
      "2301  :: 190\n",
      "2302  :: 190\n",
      "2303  :: 190\n",
      "2305  :: 190\n",
      "2307  :: 190\n",
      "2289  :: 189\n",
      "2299  :: 189\n",
      "2304  :: 189\n",
      "2306  :: 189\n",
      "2308  :: 189\n",
      "2309  :: 189\n",
      "2311  :: 189\n",
      "2298  :: 188\n",
      "2310  :: 188\n",
      "2312  :: 188\n",
      "2314  :: 188\n",
      "2316  :: 188\n",
      "2317  :: 188\n",
      "2318  :: 188\n",
      "2319  :: 188\n",
      "2321  :: 188\n",
      "2323  :: 188\n",
      "2297  :: 187\n",
      "2313  :: 187\n",
      "2315  :: 187\n",
      "2320  :: 187\n",
      "2322  :: 187\n",
      "2324  :: 187\n",
      "2325  :: 187\n",
      "2326  :: 187\n",
      "2328  :: 187\n",
      "2329  :: 187\n",
      "2330  :: 187\n",
      "2332  :: 187\n",
      "2334  :: 187\n",
      "2335  :: 187\n",
      "2327  :: 186\n",
      "2331  :: 186\n",
      "2336  :: 186\n",
      "2339  :: 186\n",
      "2341  :: 186\n",
      "2342  :: 186\n",
      "2343  :: 186\n",
      "2344  :: 186\n",
      "2348  :: 186\n",
      "2333  :: 185\n",
      "2338  :: 185\n",
      "2340  :: 185\n",
      "2350  :: 185\n",
      "2353  :: 185\n",
      "2354  :: 185\n",
      "2355  :: 185\n",
      "2356  :: 185\n",
      "2357  :: 185\n",
      "2359  :: 185\n",
      "2361  :: 185\n",
      "2337  :: 184\n",
      "2345  :: 184\n",
      "2349  :: 184\n",
      "2351  :: 184\n",
      "2358  :: 184\n",
      "2360  :: 184\n",
      "2362  :: 184\n",
      "2365  :: 184\n",
      "2367  :: 184\n",
      "2346  :: 183\n",
      "2352  :: 183\n",
      "2364  :: 183\n",
      "2368  :: 183\n",
      "2370  :: 183\n",
      "2371  :: 183\n",
      "2372  :: 183\n",
      "2373  :: 183\n",
      "2374  :: 183\n",
      "2375  :: 183\n",
      "2376  :: 183\n",
      "2363  :: 182\n",
      "2369  :: 182\n",
      "2379  :: 182\n",
      "2381  :: 182\n",
      "2382  :: 182\n",
      "2384  :: 182\n",
      "2377  :: 181\n",
      "2378  :: 181\n",
      "2386  :: 181\n",
      "2388  :: 181\n",
      "2393  :: 181\n",
      "2383  :: 180\n",
      "2385  :: 180\n",
      "2390  :: 180\n",
      "2391  :: 180\n",
      "2394  :: 180\n",
      "2397  :: 180\n",
      "2399  :: 180\n",
      "2400  :: 180\n",
      "2402  :: 180\n",
      "2404  :: 180\n",
      "2405  :: 180\n",
      "2347  :: 179\n",
      "2380  :: 179\n",
      "2392  :: 179\n",
      "2395  :: 179\n",
      "2396  :: 179\n",
      "2398  :: 179\n",
      "2401  :: 179\n",
      "2403  :: 179\n",
      "2406  :: 179\n",
      "2407  :: 179\n",
      "2408  :: 179\n",
      "2409  :: 179\n",
      "2410  :: 179\n",
      "2411  :: 179\n",
      "2366  :: 178\n",
      "2412  :: 178\n",
      "2413  :: 178\n",
      "2414  :: 178\n",
      "2420  :: 178\n",
      "2387  :: 177\n",
      "2415  :: 177\n",
      "2417  :: 177\n",
      "2419  :: 177\n",
      "2422  :: 177\n",
      "2423  :: 177\n",
      "2427  :: 177\n",
      "2428  :: 177\n",
      "2431  :: 177\n",
      "2389  :: 176\n",
      "2416  :: 176\n",
      "2425  :: 176\n",
      "2426  :: 176\n",
      "2430  :: 176\n",
      "2434  :: 176\n",
      "2435  :: 176\n",
      "2436  :: 176\n",
      "2418  :: 175\n",
      "2421  :: 175\n",
      "2424  :: 175\n",
      "2432  :: 175\n",
      "2437  :: 175\n",
      "2438  :: 175\n",
      "2440  :: 175\n",
      "2441  :: 175\n",
      "2442  :: 175\n",
      "2443  :: 175\n",
      "2445  :: 175\n",
      "2446  :: 175\n",
      "2429  :: 174\n",
      "2433  :: 174\n",
      "2439  :: 174\n",
      "2449  :: 174\n",
      "2450  :: 174\n",
      "2451  :: 174\n",
      "2452  :: 174\n",
      "2453  :: 174\n",
      "2454  :: 174\n",
      "2447  :: 173\n",
      "2455  :: 173\n",
      "2456  :: 173\n",
      "2457  :: 173\n",
      "2459  :: 173\n",
      "2460  :: 173\n",
      "2444  :: 172\n",
      "2448  :: 172\n",
      "2461  :: 172\n",
      "2462  :: 172\n",
      "2463  :: 172\n",
      "2469  :: 172\n",
      "2470  :: 172\n",
      "2458  :: 171\n",
      "2464  :: 171\n",
      "2465  :: 171\n",
      "2466  :: 171\n",
      "2467  :: 171\n",
      "2471  :: 171\n",
      "2472  :: 171\n",
      "2473  :: 171\n",
      "2474  :: 171\n",
      "2475  :: 171\n",
      "2478  :: 171\n",
      "2479  :: 171\n",
      "2480  :: 171\n",
      "2476  :: 170\n",
      "2477  :: 170\n",
      "2481  :: 170\n",
      "2482  :: 170\n",
      "2484  :: 170\n",
      "2486  :: 170\n",
      "2487  :: 170\n",
      "2488  :: 170\n",
      "2489  :: 170\n",
      "2490  :: 170\n",
      "2485  :: 169\n",
      "2493  :: 169\n",
      "2494  :: 169\n",
      "2495  :: 169\n",
      "2496  :: 169\n",
      "2497  :: 169\n",
      "2498  :: 169\n",
      "2499  :: 169\n",
      "2468  :: 168\n",
      "2491  :: 168\n",
      "2492  :: 168\n",
      "2501  :: 168\n",
      "2504  :: 168\n",
      "2505  :: 168\n",
      "2506  :: 168\n",
      "2507  :: 168\n",
      "2509  :: 168\n",
      "2511  :: 168\n",
      "2512  :: 168\n",
      "2513  :: 168\n",
      "2514  :: 168\n",
      "2515  :: 168\n",
      "2517  :: 168\n",
      "2518  :: 168\n",
      "2483  :: 167\n",
      "2502  :: 167\n",
      "2516  :: 167\n",
      "2519  :: 167\n",
      "2520  :: 167\n",
      "2522  :: 167\n",
      "2523  :: 167\n",
      "2524  :: 167\n",
      "2526  :: 167\n",
      "2527  :: 167\n",
      "2528  :: 167\n",
      "2508  :: 166\n",
      "2521  :: 166\n",
      "2525  :: 166\n",
      "2529  :: 166\n",
      "2530  :: 166\n",
      "2531  :: 166\n",
      "2532  :: 166\n",
      "2503  :: 165\n",
      "2510  :: 165\n",
      "2534  :: 165\n",
      "2535  :: 165\n",
      "2536  :: 165\n",
      "2537  :: 165\n",
      "2538  :: 165\n",
      "2539  :: 165\n",
      "2540  :: 165\n",
      "2541  :: 165\n",
      "2542  :: 165\n",
      "2543  :: 165\n",
      "2544  :: 165\n",
      "2500  :: 164\n",
      "2545  :: 164\n",
      "2547  :: 164\n",
      "2548  :: 164\n",
      "2550  :: 164\n",
      "2552  :: 164\n",
      "2553  :: 164\n",
      "2533  :: 163\n",
      "2549  :: 163\n",
      "2551  :: 163\n",
      "2554  :: 163\n",
      "2555  :: 163\n",
      "2560  :: 163\n",
      "2561  :: 163\n",
      "2563  :: 163\n",
      "2557  :: 162\n",
      "2558  :: 162\n",
      "2566  :: 162\n",
      "2567  :: 162\n",
      "2568  :: 162\n",
      "2569  :: 162\n",
      "2571  :: 162\n",
      "2572  :: 162\n",
      "2573  :: 162\n",
      "2576  :: 162\n",
      "2577  :: 162\n",
      "2578  :: 162\n",
      "2546  :: 161\n",
      "2556  :: 161\n",
      "2559  :: 161\n",
      "2562  :: 161\n",
      "2565  :: 161\n",
      "2574  :: 161\n",
      "2575  :: 161\n",
      "2580  :: 161\n",
      "2581  :: 161\n",
      "2582  :: 161\n",
      "2585  :: 161\n",
      "2586  :: 161\n",
      "2587  :: 161\n",
      "2588  :: 161\n",
      "2589  :: 161\n",
      "2564  :: 160\n",
      "2570  :: 160\n",
      "2579  :: 160\n",
      "2583  :: 160\n",
      "2592  :: 160\n",
      "2593  :: 160\n",
      "2594  :: 160\n",
      "2595  :: 160\n",
      "2597  :: 160\n",
      "2584  :: 159\n",
      "2590  :: 159\n",
      "2591  :: 159\n",
      "2596  :: 159\n",
      "2599  :: 159\n",
      "2601  :: 159\n",
      "2603  :: 159\n",
      "2604  :: 159\n",
      "2605  :: 159\n",
      "2598  :: 158\n",
      "2607  :: 158\n",
      "2608  :: 158\n",
      "2609  :: 158\n",
      "2612  :: 158\n",
      "2614  :: 158\n",
      "2616  :: 158\n",
      "2600  :: 157\n",
      "2606  :: 157\n",
      "2610  :: 157\n",
      "2611  :: 157\n",
      "2615  :: 157\n",
      "2622  :: 157\n",
      "2623  :: 157\n",
      "2624  :: 157\n",
      "2625  :: 157\n",
      "2627  :: 157\n",
      "2629  :: 157\n",
      "2630  :: 157\n",
      "2602  :: 156\n",
      "2613  :: 156\n",
      "2617  :: 156\n",
      "2619  :: 156\n",
      "2620  :: 156\n",
      "2621  :: 156\n",
      "2628  :: 156\n",
      "2631  :: 156\n",
      "2633  :: 156\n",
      "2634  :: 156\n",
      "2635  :: 156\n",
      "2636  :: 156\n",
      "2637  :: 156\n",
      "2639  :: 156\n",
      "2642  :: 156\n",
      "2626  :: 155\n",
      "2638  :: 155\n",
      "2640  :: 155\n",
      "2641  :: 155\n",
      "2643  :: 155\n",
      "2645  :: 155\n",
      "2646  :: 155\n",
      "2647  :: 155\n",
      "2648  :: 155\n",
      "2649  :: 155\n",
      "2650  :: 155\n",
      "2652  :: 155\n",
      "2653  :: 155\n",
      "2654  :: 155\n",
      "2655  :: 155\n",
      "2656  :: 155\n",
      "2657  :: 155\n",
      "2658  :: 155\n",
      "2659  :: 155\n",
      "2661  :: 155\n",
      "2618  :: 154\n",
      "2632  :: 154\n",
      "2644  :: 154\n",
      "2660  :: 154\n",
      "2662  :: 154\n",
      "2665  :: 154\n",
      "2667  :: 154\n",
      "2669  :: 154\n",
      "2670  :: 154\n",
      "2671  :: 154\n",
      "2672  :: 154\n",
      "2673  :: 154\n",
      "2675  :: 154\n",
      "2663  :: 153\n",
      "2666  :: 153\n",
      "2674  :: 153\n",
      "2677  :: 153\n",
      "2680  :: 153\n",
      "2681  :: 153\n",
      "2683  :: 153\n",
      "2684  :: 153\n",
      "2687  :: 153\n",
      "2688  :: 153\n",
      "2690  :: 153\n",
      "2692  :: 153\n",
      "2694  :: 153\n",
      "2696  :: 153\n",
      "2664  :: 152\n",
      "2676  :: 152\n",
      "2678  :: 152\n",
      "2679  :: 152\n",
      "2686  :: 152\n",
      "2689  :: 152\n",
      "2691  :: 152\n",
      "2693  :: 152\n",
      "2695  :: 152\n",
      "2697  :: 152\n",
      "2698  :: 152\n",
      "2699  :: 152\n",
      "2700  :: 152\n",
      "2701  :: 152\n",
      "2702  :: 152\n",
      "2703  :: 152\n",
      "2705  :: 152\n",
      "2708  :: 152\n",
      "2651  :: 151\n",
      "2682  :: 151\n",
      "2706  :: 151\n",
      "2707  :: 151\n",
      "2709  :: 151\n",
      "2710  :: 151\n",
      "2712  :: 151\n",
      "2713  :: 151\n",
      "2715  :: 151\n",
      "2716  :: 151\n",
      "2717  :: 151\n",
      "2704  :: 150\n",
      "2718  :: 150\n",
      "2720  :: 150\n",
      "2723  :: 150\n",
      "2724  :: 150\n",
      "2726  :: 150\n",
      "2727  :: 150\n",
      "2728  :: 150\n",
      "2668  :: 149\n",
      "2685  :: 149\n",
      "2711  :: 149\n",
      "2722  :: 149\n",
      "2725  :: 149\n",
      "2729  :: 149\n",
      "2732  :: 149\n",
      "2734  :: 149\n",
      "2735  :: 149\n",
      "2736  :: 149\n",
      "2737  :: 149\n",
      "2740  :: 149\n",
      "2741  :: 149\n",
      "2742  :: 149\n",
      "2743  :: 149\n",
      "2719  :: 148\n",
      "2721  :: 148\n",
      "2738  :: 148\n",
      "2746  :: 148\n",
      "2747  :: 148\n",
      "2748  :: 148\n",
      "2749  :: 148\n",
      "2750  :: 148\n",
      "2751  :: 148\n",
      "2752  :: 148\n",
      "2753  :: 148\n",
      "2754  :: 148\n",
      "2755  :: 148\n",
      "2730  :: 147\n",
      "2733  :: 147\n",
      "2744  :: 147\n",
      "2745  :: 147\n",
      "2756  :: 147\n",
      "2758  :: 147\n",
      "2759  :: 147\n",
      "2760  :: 147\n",
      "2762  :: 147\n",
      "2763  :: 147\n",
      "2764  :: 147\n",
      "2765  :: 147\n",
      "2766  :: 147\n",
      "2769  :: 147\n",
      "2770  :: 147\n",
      "2714  :: 146\n",
      "2739  :: 146\n",
      "2757  :: 146\n",
      "2767  :: 146\n",
      "2772  :: 146\n",
      "2774  :: 146\n",
      "2775  :: 146\n",
      "2777  :: 146\n",
      "2778  :: 146\n",
      "2779  :: 146\n",
      "2780  :: 146\n",
      "2782  :: 146\n",
      "2731  :: 145\n",
      "2761  :: 145\n",
      "2768  :: 145\n",
      "2771  :: 145\n",
      "2773  :: 145\n",
      "2783  :: 145\n",
      "2784  :: 145\n",
      "2785  :: 145\n",
      "2786  :: 145\n",
      "2788  :: 145\n",
      "2789  :: 145\n",
      "2790  :: 145\n",
      "2791  :: 145\n",
      "2776  :: 144\n",
      "2781  :: 144\n",
      "2787  :: 144\n",
      "2792  :: 144\n",
      "2793  :: 144\n",
      "2796  :: 144\n",
      "2797  :: 144\n",
      "2798  :: 144\n",
      "2800  :: 144\n",
      "2801  :: 144\n",
      "2802  :: 144\n",
      "2803  :: 144\n",
      "2804  :: 144\n",
      "2805  :: 144\n",
      "2806  :: 144\n",
      "2807  :: 144\n",
      "2808  :: 144\n",
      "2809  :: 144\n",
      "2810  :: 144\n",
      "2794  :: 143\n",
      "2799  :: 143\n",
      "2811  :: 143\n",
      "2812  :: 143\n",
      "2813  :: 143\n",
      "2814  :: 143\n",
      "2815  :: 143\n",
      "2817  :: 143\n",
      "2818  :: 143\n",
      "2819  :: 143\n",
      "2820  :: 143\n",
      "2821  :: 143\n",
      "2823  :: 143\n",
      "2824  :: 143\n",
      "2826  :: 143\n",
      "2827  :: 143\n",
      "2828  :: 143\n",
      "2795  :: 142\n",
      "2822  :: 142\n",
      "2825  :: 142\n",
      "2829  :: 142\n",
      "2830  :: 142\n",
      "2831  :: 142\n",
      "2832  :: 142\n",
      "2834  :: 142\n",
      "2835  :: 142\n",
      "2837  :: 142\n",
      "2840  :: 142\n",
      "2841  :: 142\n",
      "2816  :: 141\n",
      "2833  :: 141\n",
      "2838  :: 141\n",
      "2839  :: 141\n",
      "2842  :: 141\n",
      "2843  :: 141\n",
      "2844  :: 141\n",
      "2847  :: 141\n",
      "2848  :: 141\n",
      "2849  :: 141\n",
      "2836  :: 140\n",
      "2845  :: 140\n",
      "2846  :: 140\n",
      "2850  :: 140\n",
      "2852  :: 140\n",
      "2854  :: 140\n",
      "2855  :: 140\n",
      "2860  :: 140\n",
      "2861  :: 140\n",
      "2862  :: 140\n",
      "2851  :: 139\n",
      "2853  :: 139\n",
      "2856  :: 139\n",
      "2857  :: 139\n",
      "2858  :: 139\n",
      "2859  :: 139\n",
      "2863  :: 139\n",
      "2864  :: 139\n",
      "2865  :: 139\n",
      "2867  :: 139\n",
      "2868  :: 139\n",
      "2870  :: 139\n",
      "2871  :: 139\n",
      "2872  :: 139\n",
      "2873  :: 139\n",
      "2874  :: 139\n",
      "2875  :: 139\n",
      "2878  :: 139\n",
      "2879  :: 139\n",
      "2880  :: 139\n",
      "2881  :: 139\n",
      "2866  :: 138\n",
      "2869  :: 138\n",
      "2876  :: 138\n",
      "2882  :: 138\n",
      "2883  :: 138\n",
      "2885  :: 138\n",
      "2886  :: 138\n",
      "2887  :: 138\n",
      "2888  :: 138\n",
      "2889  :: 138\n",
      "2890  :: 138\n",
      "2892  :: 138\n",
      "2884  :: 137\n",
      "2891  :: 137\n",
      "2893  :: 137\n",
      "2895  :: 137\n",
      "2896  :: 137\n",
      "2897  :: 137\n",
      "2898  :: 137\n",
      "2899  :: 137\n",
      "2900  :: 137\n",
      "2901  :: 137\n",
      "2902  :: 137\n",
      "2903  :: 137\n",
      "2904  :: 137\n",
      "2905  :: 137\n",
      "2906  :: 137\n",
      "2877  :: 136\n",
      "2894  :: 136\n",
      "2907  :: 136\n",
      "2908  :: 136\n",
      "2909  :: 136\n",
      "2910  :: 136\n",
      "2912  :: 136\n",
      "2913  :: 136\n",
      "2916  :: 136\n",
      "2911  :: 135\n",
      "2914  :: 135\n",
      "2917  :: 135\n",
      "2920  :: 135\n",
      "2921  :: 135\n",
      "2922  :: 135\n",
      "2923  :: 135\n",
      "2919  :: 134\n",
      "2924  :: 134\n",
      "2925  :: 134\n",
      "2926  :: 134\n",
      "2927  :: 134\n",
      "2929  :: 134\n",
      "2931  :: 134\n",
      "2933  :: 134\n",
      "2918  :: 133\n",
      "2928  :: 133\n",
      "2930  :: 133\n",
      "2932  :: 133\n",
      "2935  :: 133\n",
      "2936  :: 133\n",
      "2937  :: 133\n",
      "2938  :: 133\n",
      "2940  :: 133\n",
      "2941  :: 133\n",
      "2943  :: 133\n",
      "2944  :: 133\n",
      "2945  :: 133\n",
      "2948  :: 133\n",
      "2949  :: 133\n",
      "2950  :: 133\n",
      "2915  :: 132\n",
      "2946  :: 132\n",
      "2947  :: 132\n",
      "2951  :: 132\n",
      "2952  :: 132\n",
      "2953  :: 132\n",
      "2957  :: 132\n",
      "2958  :: 132\n",
      "2960  :: 132\n",
      "2963  :: 132\n",
      "2966  :: 132\n",
      "2934  :: 131\n",
      "2942  :: 131\n",
      "2955  :: 131\n",
      "2956  :: 131\n",
      "2961  :: 131\n",
      "2962  :: 131\n",
      "2965  :: 131\n",
      "2967  :: 131\n",
      "2968  :: 131\n",
      "2969  :: 131\n",
      "2970  :: 131\n",
      "2971  :: 131\n",
      "2973  :: 131\n",
      "2975  :: 131\n",
      "2976  :: 131\n",
      "2954  :: 130\n",
      "2959  :: 130\n",
      "2972  :: 130\n",
      "2974  :: 130\n",
      "2977  :: 130\n",
      "2978  :: 130\n",
      "2980  :: 130\n",
      "2982  :: 130\n",
      "2983  :: 130\n",
      "2984  :: 130\n",
      "2985  :: 130\n",
      "2986  :: 130\n",
      "2987  :: 130\n",
      "2989  :: 130\n",
      "2990  :: 130\n",
      "2979  :: 129\n",
      "2981  :: 129\n",
      "2991  :: 129\n",
      "2992  :: 129\n",
      "2993  :: 129\n",
      "2994  :: 129\n",
      "2995  :: 129\n",
      "2998  :: 129\n",
      "2999  :: 129\n",
      "3000  :: 129\n",
      "3002  :: 129\n",
      "3003  :: 129\n",
      "3004  :: 129\n",
      "3005  :: 129\n",
      "3006  :: 129\n",
      "2939  :: 128\n",
      "2988  :: 128\n",
      "2997  :: 128\n",
      "3001  :: 128\n",
      "3007  :: 128\n",
      "3009  :: 128\n",
      "3010  :: 128\n",
      "3011  :: 128\n",
      "3014  :: 128\n",
      "3015  :: 128\n",
      "3016  :: 128\n",
      "3017  :: 128\n",
      "3019  :: 128\n",
      "3023  :: 128\n",
      "3024  :: 128\n",
      "3025  :: 128\n",
      "3026  :: 128\n",
      "3027  :: 128\n",
      "2964  :: 127\n",
      "3012  :: 127\n",
      "3013  :: 127\n",
      "3020  :: 127\n",
      "3021  :: 127\n",
      "3022  :: 127\n",
      "3028  :: 127\n",
      "3029  :: 127\n",
      "3032  :: 127\n",
      "3033  :: 127\n",
      "3035  :: 127\n",
      "3036  :: 127\n",
      "3037  :: 127\n",
      "3038  :: 127\n",
      "3039  :: 127\n",
      "3040  :: 127\n",
      "3042  :: 127\n",
      "3043  :: 127\n",
      "3044  :: 127\n",
      "3046  :: 127\n",
      "3048  :: 127\n",
      "3008  :: 126\n",
      "3034  :: 126\n",
      "3041  :: 126\n",
      "3047  :: 126\n",
      "3050  :: 126\n",
      "3051  :: 126\n",
      "3052  :: 126\n",
      "3053  :: 126\n",
      "3054  :: 126\n",
      "3055  :: 126\n",
      "3056  :: 126\n",
      "3057  :: 126\n",
      "3059  :: 126\n",
      "3060  :: 126\n",
      "3061  :: 126\n",
      "3062  :: 126\n",
      "3063  :: 126\n",
      "3064  :: 126\n",
      "3066  :: 126\n",
      "3018  :: 125\n",
      "3030  :: 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031  :: 125\n",
      "3045  :: 125\n",
      "3049  :: 125\n",
      "3058  :: 125\n",
      "3071  :: 125\n",
      "3072  :: 125\n",
      "3074  :: 125\n",
      "3075  :: 125\n",
      "3076  :: 125\n",
      "3081  :: 125\n",
      "3082  :: 125\n",
      "3084  :: 125\n",
      "3065  :: 124\n",
      "3068  :: 124\n",
      "3069  :: 124\n",
      "3077  :: 124\n",
      "3078  :: 124\n",
      "3079  :: 124\n",
      "3080  :: 124\n",
      "3085  :: 124\n",
      "3086  :: 124\n",
      "3087  :: 124\n",
      "3089  :: 124\n",
      "3090  :: 124\n",
      "3093  :: 124\n",
      "3094  :: 124\n",
      "3097  :: 124\n",
      "3098  :: 124\n",
      "3099  :: 124\n",
      "3102  :: 124\n",
      "3104  :: 124\n",
      "3105  :: 124\n",
      "3108  :: 124\n",
      "3109  :: 124\n",
      "3067  :: 123\n",
      "3070  :: 123\n",
      "3083  :: 123\n",
      "3088  :: 123\n",
      "3091  :: 123\n",
      "3092  :: 123\n",
      "3100  :: 123\n",
      "3101  :: 123\n",
      "3103  :: 123\n",
      "3106  :: 123\n",
      "3107  :: 123\n",
      "3111  :: 123\n",
      "3112  :: 123\n",
      "3113  :: 123\n",
      "3114  :: 123\n",
      "3116  :: 123\n",
      "3117  :: 123\n",
      "3118  :: 123\n",
      "3119  :: 123\n",
      "3120  :: 123\n",
      "3121  :: 123\n",
      "3123  :: 123\n",
      "3124  :: 123\n",
      "3128  :: 123\n",
      "3129  :: 123\n",
      "3130  :: 123\n",
      "3073  :: 122\n",
      "3096  :: 122\n",
      "3115  :: 122\n",
      "3122  :: 122\n",
      "3125  :: 122\n",
      "3126  :: 122\n",
      "3131  :: 122\n",
      "3132  :: 122\n",
      "3133  :: 122\n",
      "3135  :: 122\n",
      "3136  :: 122\n",
      "3137  :: 122\n",
      "3138  :: 122\n",
      "3139  :: 122\n",
      "3140  :: 122\n",
      "3141  :: 122\n",
      "3142  :: 122\n",
      "3144  :: 122\n",
      "3145  :: 122\n",
      "3148  :: 122\n",
      "3149  :: 122\n",
      "3127  :: 121\n",
      "3134  :: 121\n",
      "3146  :: 121\n",
      "3147  :: 121\n",
      "3150  :: 121\n",
      "3151  :: 121\n",
      "3152  :: 121\n",
      "3153  :: 121\n",
      "3158  :: 121\n",
      "3159  :: 121\n",
      "3160  :: 121\n",
      "3161  :: 121\n",
      "3164  :: 121\n",
      "3165  :: 121\n",
      "3095  :: 120\n",
      "3154  :: 120\n",
      "3157  :: 120\n",
      "3163  :: 120\n",
      "3167  :: 120\n",
      "3168  :: 120\n",
      "3169  :: 120\n",
      "3170  :: 120\n",
      "3171  :: 120\n",
      "3173  :: 120\n",
      "3174  :: 120\n",
      "3175  :: 120\n",
      "3178  :: 120\n",
      "3179  :: 120\n",
      "3143  :: 119\n",
      "3155  :: 119\n",
      "3156  :: 119\n",
      "3162  :: 119\n",
      "3172  :: 119\n",
      "3176  :: 119\n",
      "3177  :: 119\n",
      "3181  :: 119\n",
      "3183  :: 119\n",
      "3185  :: 119\n",
      "3186  :: 119\n",
      "3191  :: 119\n",
      "3192  :: 119\n",
      "3193  :: 119\n",
      "3110  :: 118\n",
      "3166  :: 118\n",
      "3180  :: 118\n",
      "3184  :: 118\n",
      "3187  :: 118\n",
      "3189  :: 118\n",
      "3194  :: 118\n",
      "3195  :: 118\n",
      "3196  :: 118\n",
      "3197  :: 118\n",
      "3199  :: 118\n",
      "3201  :: 118\n",
      "3202  :: 118\n",
      "3204  :: 118\n",
      "3207  :: 118\n",
      "3208  :: 118\n",
      "3209  :: 118\n",
      "3210  :: 118\n",
      "3211  :: 118\n",
      "3212  :: 118\n",
      "3213  :: 118\n",
      "3214  :: 118\n",
      "3215  :: 118\n",
      "3216  :: 118\n",
      "3217  :: 118\n",
      "3182  :: 117\n",
      "3190  :: 117\n",
      "3198  :: 117\n",
      "3200  :: 117\n",
      "3203  :: 117\n",
      "3205  :: 117\n",
      "3206  :: 117\n",
      "3218  :: 117\n",
      "3219  :: 117\n",
      "3221  :: 117\n",
      "3222  :: 117\n",
      "3223  :: 117\n",
      "3226  :: 117\n",
      "3228  :: 117\n",
      "3231  :: 117\n",
      "3232  :: 117\n",
      "3234  :: 117\n",
      "3235  :: 117\n",
      "3236  :: 117\n",
      "2996  :: 116\n",
      "3188  :: 116\n",
      "3224  :: 116\n",
      "3225  :: 116\n",
      "3227  :: 116\n",
      "3229  :: 116\n",
      "3233  :: 116\n",
      "3237  :: 116\n",
      "3239  :: 116\n",
      "3241  :: 116\n",
      "3242  :: 116\n",
      "3243  :: 116\n",
      "3245  :: 116\n",
      "3246  :: 116\n",
      "3247  :: 116\n",
      "3248  :: 116\n",
      "3249  :: 116\n",
      "3251  :: 116\n",
      "3254  :: 116\n",
      "3255  :: 116\n",
      "3256  :: 116\n",
      "3259  :: 116\n",
      "3260  :: 116\n",
      "3261  :: 116\n",
      "3262  :: 116\n",
      "3263  :: 116\n",
      "3230  :: 115\n",
      "3240  :: 115\n",
      "3244  :: 115\n",
      "3250  :: 115\n",
      "3252  :: 115\n",
      "3253  :: 115\n",
      "3257  :: 115\n",
      "3258  :: 115\n",
      "3266  :: 115\n",
      "3268  :: 115\n",
      "3269  :: 115\n",
      "3271  :: 115\n",
      "3272  :: 115\n",
      "3273  :: 115\n",
      "3274  :: 115\n",
      "3276  :: 115\n",
      "3277  :: 115\n",
      "3279  :: 115\n",
      "3280  :: 115\n",
      "3238  :: 114\n",
      "3264  :: 114\n",
      "3265  :: 114\n",
      "3275  :: 114\n",
      "3278  :: 114\n",
      "3281  :: 114\n",
      "3285  :: 114\n",
      "3289  :: 114\n",
      "3290  :: 114\n",
      "3292  :: 114\n",
      "3293  :: 114\n",
      "3294  :: 114\n",
      "3267  :: 113\n",
      "3270  :: 113\n",
      "3283  :: 113\n",
      "3284  :: 113\n",
      "3286  :: 113\n",
      "3288  :: 113\n",
      "3291  :: 113\n",
      "3296  :: 113\n",
      "3297  :: 113\n",
      "3298  :: 113\n",
      "3299  :: 113\n",
      "3301  :: 113\n",
      "3302  :: 113\n",
      "3303  :: 113\n",
      "3304  :: 113\n",
      "3307  :: 113\n",
      "3308  :: 113\n",
      "3309  :: 113\n",
      "3310  :: 113\n",
      "3282  :: 112\n",
      "3287  :: 112\n",
      "3300  :: 112\n",
      "3305  :: 112\n",
      "3306  :: 112\n",
      "3311  :: 112\n",
      "3313  :: 112\n",
      "3314  :: 112\n",
      "3315  :: 112\n",
      "3316  :: 112\n",
      "3317  :: 112\n",
      "3318  :: 112\n",
      "3319  :: 112\n",
      "3320  :: 112\n",
      "3322  :: 112\n",
      "3323  :: 112\n",
      "3324  :: 112\n",
      "3326  :: 112\n",
      "3328  :: 112\n",
      "3329  :: 112\n",
      "3295  :: 111\n",
      "3312  :: 111\n",
      "3321  :: 111\n",
      "3325  :: 111\n",
      "3330  :: 111\n",
      "3331  :: 111\n",
      "3332  :: 111\n",
      "3333  :: 111\n",
      "3334  :: 111\n",
      "3335  :: 111\n",
      "3336  :: 111\n",
      "3337  :: 111\n",
      "3339  :: 111\n",
      "3341  :: 111\n",
      "3342  :: 111\n",
      "3346  :: 111\n",
      "3347  :: 111\n",
      "3351  :: 111\n",
      "3353  :: 111\n",
      "3354  :: 111\n",
      "3327  :: 110\n",
      "3340  :: 110\n",
      "3343  :: 110\n",
      "3345  :: 110\n",
      "3348  :: 110\n",
      "3349  :: 110\n",
      "3355  :: 110\n",
      "3356  :: 110\n",
      "3357  :: 110\n",
      "3358  :: 110\n",
      "3359  :: 110\n",
      "3362  :: 110\n",
      "3364  :: 110\n",
      "3367  :: 110\n",
      "3368  :: 110\n",
      "3369  :: 110\n",
      "3370  :: 110\n",
      "3371  :: 110\n",
      "3372  :: 110\n",
      "3373  :: 110\n",
      "3374  :: 110\n",
      "3375  :: 110\n",
      "3338  :: 109\n",
      "3352  :: 109\n",
      "3360  :: 109\n",
      "3361  :: 109\n",
      "3363  :: 109\n",
      "3366  :: 109\n",
      "3376  :: 109\n",
      "3377  :: 109\n",
      "3378  :: 109\n",
      "3379  :: 109\n",
      "3381  :: 109\n",
      "3382  :: 109\n",
      "3383  :: 109\n",
      "3385  :: 109\n",
      "3386  :: 109\n",
      "3388  :: 109\n",
      "3389  :: 109\n",
      "3390  :: 109\n",
      "3391  :: 109\n",
      "3392  :: 109\n",
      "3393  :: 109\n",
      "3394  :: 109\n",
      "3395  :: 109\n",
      "3397  :: 109\n",
      "3398  :: 109\n",
      "3400  :: 109\n",
      "3220  :: 108\n",
      "3350  :: 108\n",
      "3380  :: 108\n",
      "3384  :: 108\n",
      "3387  :: 108\n",
      "3401  :: 108\n",
      "3402  :: 108\n",
      "3403  :: 108\n",
      "3404  :: 108\n",
      "3405  :: 108\n",
      "3406  :: 108\n",
      "3407  :: 108\n",
      "3411  :: 108\n",
      "3412  :: 108\n",
      "3414  :: 108\n",
      "3415  :: 108\n",
      "3365  :: 107\n",
      "3396  :: 107\n",
      "3399  :: 107\n",
      "3408  :: 107\n",
      "3410  :: 107\n",
      "3413  :: 107\n",
      "3417  :: 107\n",
      "3418  :: 107\n",
      "3419  :: 107\n",
      "3420  :: 107\n",
      "3421  :: 107\n",
      "3422  :: 107\n",
      "3424  :: 107\n",
      "3426  :: 107\n",
      "3427  :: 107\n",
      "3428  :: 107\n",
      "3429  :: 107\n",
      "3430  :: 107\n",
      "3435  :: 107\n",
      "3436  :: 107\n",
      "3437  :: 107\n",
      "3438  :: 107\n",
      "3416  :: 106\n",
      "3423  :: 106\n",
      "3425  :: 106\n",
      "3431  :: 106\n",
      "3432  :: 106\n",
      "3434  :: 106\n",
      "3439  :: 106\n",
      "3440  :: 106\n",
      "3441  :: 106\n",
      "3442  :: 106\n",
      "3444  :: 106\n",
      "3446  :: 106\n",
      "3447  :: 106\n",
      "3448  :: 106\n",
      "3449  :: 106\n",
      "3450  :: 106\n",
      "3451  :: 106\n",
      "3454  :: 106\n",
      "3455  :: 106\n",
      "3456  :: 106\n",
      "3457  :: 106\n",
      "3459  :: 106\n",
      "3460  :: 106\n",
      "3462  :: 106\n",
      "3344  :: 105\n",
      "3409  :: 105\n",
      "3433  :: 105\n",
      "3445  :: 105\n",
      "3458  :: 105\n",
      "3461  :: 105\n",
      "3463  :: 105\n",
      "3464  :: 105\n",
      "3465  :: 105\n",
      "3466  :: 105\n",
      "3468  :: 105\n",
      "3469  :: 105\n",
      "3470  :: 105\n",
      "3471  :: 105\n",
      "3473  :: 105\n",
      "3474  :: 105\n",
      "3475  :: 105\n",
      "3477  :: 105\n",
      "3478  :: 105\n",
      "3480  :: 105\n",
      "3481  :: 105\n",
      "3484  :: 105\n",
      "3443  :: 104\n",
      "3452  :: 104\n",
      "3453  :: 104\n",
      "3467  :: 104\n",
      "3472  :: 104\n",
      "3476  :: 104\n",
      "3482  :: 104\n",
      "3485  :: 104\n",
      "3486  :: 104\n",
      "3487  :: 104\n",
      "3491  :: 104\n",
      "3492  :: 104\n",
      "3494  :: 104\n",
      "3495  :: 104\n",
      "3497  :: 104\n",
      "3499  :: 104\n",
      "3501  :: 104\n",
      "3503  :: 104\n",
      "3504  :: 104\n",
      "3505  :: 104\n",
      "3506  :: 104\n",
      "3479  :: 103\n",
      "3483  :: 103\n",
      "3488  :: 103\n",
      "3489  :: 103\n",
      "3490  :: 103\n",
      "3493  :: 103\n",
      "3498  :: 103\n",
      "3500  :: 103\n",
      "3502  :: 103\n",
      "3507  :: 103\n",
      "3508  :: 103\n",
      "3509  :: 103\n",
      "3511  :: 103\n",
      "3513  :: 103\n",
      "3514  :: 103\n",
      "3516  :: 103\n",
      "3518  :: 103\n",
      "3519  :: 103\n",
      "3520  :: 103\n",
      "3521  :: 103\n",
      "3522  :: 103\n",
      "3524  :: 103\n",
      "3525  :: 103\n",
      "3526  :: 103\n",
      "3527  :: 103\n",
      "3528  :: 103\n",
      "3529  :: 103\n",
      "3530  :: 103\n",
      "3531  :: 103\n",
      "3496  :: 102\n",
      "3510  :: 102\n",
      "3512  :: 102\n",
      "3515  :: 102\n",
      "3517  :: 102\n",
      "3523  :: 102\n",
      "3532  :: 102\n",
      "3533  :: 102\n",
      "3534  :: 102\n",
      "3535  :: 102\n",
      "3538  :: 102\n",
      "3539  :: 102\n",
      "3540  :: 102\n",
      "3541  :: 102\n",
      "3542  :: 102\n",
      "3543  :: 102\n",
      "3544  :: 102\n",
      "3545  :: 102\n",
      "3547  :: 102\n",
      "3548  :: 102\n",
      "3549  :: 102\n",
      "3550  :: 102\n",
      "3551  :: 102\n",
      "3553  :: 102\n",
      "3554  :: 102\n",
      "3555  :: 102\n",
      "3556  :: 102\n",
      "3557  :: 102\n",
      "3558  :: 102\n",
      "3559  :: 102\n",
      "3536  :: 101\n",
      "3560  :: 101\n",
      "3561  :: 101\n",
      "3562  :: 101\n",
      "3563  :: 101\n",
      "3564  :: 101\n",
      "3565  :: 101\n",
      "3566  :: 101\n",
      "3569  :: 101\n",
      "3570  :: 101\n",
      "3572  :: 101\n",
      "3573  :: 101\n",
      "3574  :: 101\n",
      "3575  :: 101\n",
      "3576  :: 101\n",
      "3579  :: 101\n",
      "3582  :: 101\n",
      "3583  :: 101\n",
      "3584  :: 101\n",
      "3537  :: 100\n",
      "3546  :: 100\n",
      "3552  :: 100\n",
      "3568  :: 100\n",
      "3578  :: 100\n",
      "3580  :: 100\n",
      "3585  :: 100\n",
      "3586  :: 100\n",
      "3588  :: 100\n",
      "3589  :: 100\n",
      "3591  :: 100\n",
      "3594  :: 100\n",
      "3595  :: 100\n",
      "3598  :: 100\n",
      "3599  :: 100\n",
      "3600  :: 100\n",
      "3601  :: 100\n",
      "3602  :: 100\n",
      "3603  :: 100\n",
      "3604  :: 100\n",
      "3605  :: 100\n",
      "3567  :: 99\n",
      "3571  :: 99\n",
      "3577  :: 99\n",
      "3590  :: 99\n",
      "3593  :: 99\n",
      "3596  :: 99\n",
      "3597  :: 99\n",
      "3607  :: 99\n",
      "3608  :: 99\n",
      "3609  :: 99\n",
      "3611  :: 99\n",
      "3612  :: 99\n",
      "3613  :: 99\n",
      "3615  :: 99\n",
      "3616  :: 99\n",
      "3617  :: 99\n",
      "3618  :: 99\n",
      "3620  :: 99\n",
      "3621  :: 99\n",
      "3623  :: 99\n",
      "3624  :: 99\n",
      "3625  :: 99\n",
      "3627  :: 99\n",
      "3629  :: 99\n",
      "3631  :: 99\n",
      "3632  :: 99\n",
      "3634  :: 99\n",
      "3636  :: 99\n",
      "3637  :: 99\n",
      "3581  :: 98\n",
      "3587  :: 98\n",
      "3592  :: 98\n",
      "3606  :: 98\n",
      "3622  :: 98\n",
      "3626  :: 98\n",
      "3628  :: 98\n",
      "3633  :: 98\n",
      "3639  :: 98\n",
      "3640  :: 98\n",
      "3642  :: 98\n",
      "3643  :: 98\n",
      "3644  :: 98\n",
      "3645  :: 98\n",
      "3648  :: 98\n",
      "3649  :: 98\n",
      "3650  :: 98\n",
      "3651  :: 98\n",
      "3652  :: 98\n",
      "3655  :: 98\n",
      "3656  :: 98\n",
      "3657  :: 98\n",
      "3659  :: 98\n",
      "3660  :: 98\n",
      "3663  :: 98\n",
      "3610  :: 97\n",
      "3614  :: 97\n",
      "3619  :: 97\n",
      "3635  :: 97\n",
      "3638  :: 97\n",
      "3641  :: 97\n",
      "3646  :: 97\n",
      "3647  :: 97\n",
      "3653  :: 97\n",
      "3654  :: 97\n",
      "3662  :: 97\n",
      "3664  :: 97\n",
      "3665  :: 97\n",
      "3666  :: 97\n",
      "3667  :: 97\n",
      "3668  :: 97\n",
      "3669  :: 97\n",
      "3670  :: 97\n",
      "3671  :: 97\n",
      "3672  :: 97\n",
      "3674  :: 97\n",
      "3675  :: 97\n",
      "3676  :: 97\n",
      "3678  :: 97\n",
      "3679  :: 97\n",
      "3680  :: 97\n",
      "3682  :: 97\n",
      "3683  :: 97\n",
      "3688  :: 97\n",
      "3689  :: 97\n",
      "3690  :: 97\n",
      "3691  :: 97\n",
      "3692  :: 97\n",
      "3693  :: 97\n",
      "3694  :: 97\n",
      "3695  :: 97\n",
      "3697  :: 97\n",
      "3699  :: 97\n",
      "3700  :: 97\n",
      "3701  :: 97\n",
      "3702  :: 97\n",
      "3705  :: 97\n",
      "3630  :: 96\n",
      "3661  :: 96\n",
      "3673  :: 96\n",
      "3677  :: 96\n",
      "3681  :: 96\n",
      "3684  :: 96\n",
      "3685  :: 96\n",
      "3687  :: 96\n",
      "3696  :: 96\n",
      "3704  :: 96\n",
      "3706  :: 96\n",
      "3707  :: 96\n",
      "3708  :: 96\n",
      "3709  :: 96\n",
      "3710  :: 96\n",
      "3712  :: 96\n",
      "3713  :: 96\n",
      "3714  :: 96\n",
      "3715  :: 96\n",
      "3716  :: 96\n",
      "3717  :: 96\n",
      "3718  :: 96\n",
      "3720  :: 96\n",
      "3722  :: 96\n",
      "3726  :: 96\n",
      "3728  :: 96\n",
      "3729  :: 96\n",
      "3658  :: 95\n",
      "3698  :: 95\n",
      "3703  :: 95\n",
      "3711  :: 95\n",
      "3719  :: 95\n",
      "3723  :: 95\n",
      "3724  :: 95\n",
      "3725  :: 95\n",
      "3730  :: 95\n",
      "3732  :: 95\n",
      "3733  :: 95\n",
      "3734  :: 95\n",
      "3735  :: 95\n",
      "3736  :: 95\n",
      "3738  :: 95\n",
      "3739  :: 95\n",
      "3741  :: 95\n",
      "3742  :: 95\n",
      "3743  :: 95\n",
      "3744  :: 95\n",
      "3745  :: 95\n",
      "3746  :: 95\n",
      "3747  :: 95\n",
      "3748  :: 95\n",
      "3749  :: 95\n",
      "3750  :: 95\n",
      "3752  :: 95\n",
      "3753  :: 95\n",
      "3755  :: 95\n",
      "3721  :: 94\n",
      "3737  :: 94\n",
      "3740  :: 94\n",
      "3751  :: 94\n",
      "3754  :: 94\n",
      "3756  :: 94\n",
      "3758  :: 94\n",
      "3759  :: 94\n",
      "3760  :: 94\n",
      "3762  :: 94\n",
      "3763  :: 94\n",
      "3764  :: 94\n",
      "3765  :: 94\n",
      "3766  :: 94\n",
      "3768  :: 94\n",
      "3769  :: 94\n",
      "3770  :: 94\n",
      "3771  :: 94\n",
      "3772  :: 94\n",
      "3774  :: 94\n",
      "3775  :: 94\n",
      "3776  :: 94\n",
      "3777  :: 94\n",
      "3778  :: 94\n",
      "3779  :: 94\n",
      "3780  :: 94\n",
      "3781  :: 94\n",
      "3686  :: 93\n",
      "3727  :: 93\n",
      "3767  :: 93\n",
      "3773  :: 93\n",
      "3782  :: 93\n",
      "3783  :: 93\n",
      "3785  :: 93\n",
      "3787  :: 93\n",
      "3788  :: 93\n",
      "3789  :: 93\n",
      "3790  :: 93\n",
      "3791  :: 93\n",
      "3792  :: 93\n",
      "3794  :: 93\n",
      "3795  :: 93\n",
      "3796  :: 93\n",
      "3797  :: 93\n",
      "3798  :: 93\n",
      "3800  :: 93\n",
      "3802  :: 93\n",
      "3803  :: 93\n",
      "3807  :: 93\n",
      "3808  :: 93\n",
      "3810  :: 93\n",
      "3812  :: 93\n",
      "3813  :: 93\n",
      "3814  :: 93\n",
      "3757  :: 92\n",
      "3786  :: 92\n",
      "3799  :: 92\n",
      "3801  :: 92\n",
      "3804  :: 92\n",
      "3809  :: 92\n",
      "3811  :: 92\n",
      "3816  :: 92\n",
      "3817  :: 92\n",
      "3818  :: 92\n",
      "3819  :: 92\n",
      "3820  :: 92\n",
      "3821  :: 92\n",
      "3822  :: 92\n",
      "3823  :: 92\n",
      "3824  :: 92\n",
      "3825  :: 92\n",
      "3826  :: 92\n",
      "3827  :: 92\n",
      "3828  :: 92\n",
      "3830  :: 92\n",
      "3831  :: 92\n",
      "3833  :: 92\n",
      "3834  :: 92\n",
      "3837  :: 92\n",
      "3838  :: 92\n",
      "3841  :: 92\n",
      "3842  :: 92\n",
      "3843  :: 92\n",
      "3844  :: 92\n",
      "3731  :: 91\n",
      "3761  :: 91\n",
      "3784  :: 91\n",
      "3793  :: 91\n",
      "3806  :: 91\n",
      "3832  :: 91\n",
      "3835  :: 91\n",
      "3836  :: 91\n",
      "3839  :: 91\n",
      "3840  :: 91\n",
      "3845  :: 91\n",
      "3846  :: 91\n",
      "3850  :: 91\n",
      "3851  :: 91\n",
      "3852  :: 91\n",
      "3853  :: 91\n",
      "3856  :: 91\n",
      "3858  :: 91\n",
      "3860  :: 91\n",
      "3861  :: 91\n",
      "3864  :: 91\n",
      "3865  :: 91\n",
      "3866  :: 91\n",
      "3867  :: 91\n",
      "3868  :: 91\n",
      "3869  :: 91\n",
      "3870  :: 91\n",
      "3829  :: 90\n",
      "3848  :: 90\n",
      "3849  :: 90\n",
      "3854  :: 90\n",
      "3855  :: 90\n",
      "3857  :: 90\n",
      "3859  :: 90\n",
      "3863  :: 90\n",
      "3872  :: 90\n",
      "3874  :: 90\n",
      "3875  :: 90\n",
      "3876  :: 90\n",
      "3877  :: 90\n",
      "3878  :: 90\n",
      "3880  :: 90\n",
      "3881  :: 90\n",
      "3882  :: 90\n",
      "3884  :: 90\n",
      "3885  :: 90\n",
      "3886  :: 90\n",
      "3890  :: 90\n",
      "3893  :: 90\n",
      "3894  :: 90\n",
      "3896  :: 90\n",
      "3897  :: 90\n",
      "3898  :: 90\n",
      "3899  :: 90\n",
      "3900  :: 90\n",
      "3901  :: 90\n",
      "3903  :: 90\n",
      "3904  :: 90\n",
      "3905  :: 90\n",
      "3862  :: 89\n",
      "3873  :: 89\n",
      "3879  :: 89\n",
      "3883  :: 89\n",
      "3888  :: 89\n",
      "3889  :: 89\n",
      "3892  :: 89\n",
      "3895  :: 89\n",
      "3906  :: 89\n",
      "3907  :: 89\n",
      "3908  :: 89\n",
      "3909  :: 89\n",
      "3910  :: 89\n",
      "3911  :: 89\n",
      "3912  :: 89\n",
      "3914  :: 89\n",
      "3915  :: 89\n",
      "3916  :: 89\n",
      "3917  :: 89\n",
      "3918  :: 89\n",
      "3919  :: 89\n",
      "3920  :: 89\n",
      "3921  :: 89\n",
      "3922  :: 89\n",
      "3923  :: 89\n",
      "3924  :: 89\n",
      "3925  :: 89\n",
      "3927  :: 89\n",
      "3929  :: 89\n",
      "3931  :: 89\n",
      "3932  :: 89\n",
      "3933  :: 89\n",
      "3805  :: 88\n",
      "3847  :: 88\n",
      "3871  :: 88\n",
      "3887  :: 88\n",
      "3891  :: 88\n",
      "3902  :: 88\n",
      "3913  :: 88\n",
      "3926  :: 88\n",
      "3928  :: 88\n",
      "3930  :: 88\n",
      "3934  :: 88\n",
      "3935  :: 88\n",
      "3936  :: 88\n",
      "3938  :: 88\n",
      "3939  :: 88\n",
      "3940  :: 88\n",
      "3941  :: 88\n",
      "3943  :: 88\n",
      "3944  :: 88\n",
      "3946  :: 88\n",
      "3947  :: 88\n",
      "3948  :: 88\n",
      "3949  :: 88\n",
      "3951  :: 88\n",
      "3952  :: 88\n",
      "3953  :: 88\n",
      "3955  :: 88\n",
      "3956  :: 88\n",
      "3957  :: 88\n",
      "3958  :: 88\n",
      "3959  :: 88\n",
      "3960  :: 88\n",
      "3937  :: 87\n",
      "3942  :: 87\n",
      "3950  :: 87\n",
      "3954  :: 87\n",
      "3961  :: 87\n",
      "3964  :: 87\n",
      "3965  :: 87\n",
      "3966  :: 87\n",
      "3968  :: 87\n",
      "3969  :: 87\n",
      "3970  :: 87\n",
      "3971  :: 87\n",
      "3972  :: 87\n",
      "3973  :: 87\n",
      "3974  :: 87\n",
      "3976  :: 87\n",
      "3977  :: 87\n",
      "3978  :: 87\n",
      "3979  :: 87\n",
      "3980  :: 87\n",
      "3981  :: 87\n",
      "3982  :: 87\n",
      "3983  :: 87\n",
      "3984  :: 87\n",
      "3986  :: 87\n",
      "3987  :: 87\n",
      "3988  :: 87\n",
      "3989  :: 87\n",
      "3990  :: 87\n",
      "3945  :: 86\n",
      "3962  :: 86\n",
      "3963  :: 86\n",
      "3967  :: 86\n",
      "3975  :: 86\n",
      "3985  :: 86\n",
      "3991  :: 86\n",
      "3992  :: 86\n",
      "3993  :: 86\n",
      "3994  :: 86\n",
      "3995  :: 86\n",
      "3996  :: 86\n",
      "3997  :: 86\n",
      "3998  :: 86\n",
      "3999  :: 86\n",
      "4001  :: 86\n",
      "4002  :: 86\n",
      "4003  :: 86\n",
      "4004  :: 86\n",
      "4005  :: 86\n",
      "4006  :: 86\n",
      "4011  :: 86\n",
      "4012  :: 86\n",
      "4013  :: 86\n",
      "4015  :: 86\n",
      "4016  :: 86\n",
      "4017  :: 86\n",
      "4018  :: 86\n",
      "3815  :: 85\n",
      "4007  :: 85\n",
      "4008  :: 85\n",
      "4009  :: 85\n",
      "4014  :: 85\n",
      "4019  :: 85\n",
      "4021  :: 85\n",
      "4022  :: 85\n",
      "4023  :: 85\n",
      "4024  :: 85\n",
      "4025  :: 85\n",
      "4026  :: 85\n",
      "4028  :: 85\n",
      "4030  :: 85\n",
      "4031  :: 85\n",
      "4032  :: 85\n",
      "4033  :: 85\n",
      "4034  :: 85\n",
      "4035  :: 85\n",
      "4036  :: 85\n",
      "4038  :: 85\n",
      "4040  :: 85\n",
      "4041  :: 85\n",
      "4042  :: 85\n",
      "4044  :: 85\n",
      "4045  :: 85\n",
      "4046  :: 85\n",
      "4048  :: 85\n",
      "4049  :: 85\n",
      "4050  :: 85\n",
      "4052  :: 85\n",
      "4054  :: 85\n",
      "4010  :: 84\n",
      "4020  :: 84\n",
      "4029  :: 84\n",
      "4037  :: 84\n",
      "4039  :: 84\n",
      "4047  :: 84\n",
      "4051  :: 84\n",
      "4053  :: 84\n",
      "4055  :: 84\n",
      "4056  :: 84\n",
      "4058  :: 84\n",
      "4059  :: 84\n",
      "4061  :: 84\n",
      "4062  :: 84\n",
      "4064  :: 84\n",
      "4065  :: 84\n",
      "4066  :: 84\n",
      "4068  :: 84\n",
      "4070  :: 84\n",
      "4071  :: 84\n",
      "4072  :: 84\n",
      "4073  :: 84\n",
      "4074  :: 84\n",
      "4075  :: 84\n",
      "4076  :: 84\n",
      "4078  :: 84\n",
      "4080  :: 84\n",
      "4083  :: 84\n",
      "4084  :: 84\n",
      "4086  :: 84\n",
      "4087  :: 84\n",
      "4088  :: 84\n",
      "4090  :: 84\n",
      "4092  :: 84\n",
      "4093  :: 84\n",
      "4000  :: 83\n",
      "4027  :: 83\n",
      "4057  :: 83\n",
      "4060  :: 83\n",
      "4067  :: 83\n",
      "4069  :: 83\n",
      "4077  :: 83\n",
      "4079  :: 83\n",
      "4082  :: 83\n",
      "4089  :: 83\n",
      "4091  :: 83\n",
      "4094  :: 83\n",
      "4096  :: 83\n",
      "4097  :: 83\n",
      "4098  :: 83\n",
      "4099  :: 83\n",
      "4100  :: 83\n",
      "4101  :: 83\n",
      "4102  :: 83\n",
      "4103  :: 83\n",
      "4104  :: 83\n",
      "4105  :: 83\n",
      "4107  :: 83\n",
      "4109  :: 83\n",
      "4110  :: 83\n",
      "4111  :: 83\n",
      "4112  :: 83\n",
      "4113  :: 83\n",
      "4115  :: 83\n",
      "4116  :: 83\n",
      "4117  :: 83\n",
      "4118  :: 83\n",
      "4119  :: 83\n",
      "4122  :: 83\n",
      "4123  :: 83\n",
      "4124  :: 83\n",
      "4125  :: 83\n",
      "4128  :: 83\n",
      "4129  :: 83\n",
      "4130  :: 83\n",
      "4131  :: 83\n",
      "4132  :: 83\n",
      "4133  :: 83\n",
      "4134  :: 83\n",
      "4135  :: 83\n",
      "4136  :: 83\n",
      "4137  :: 83\n",
      "4138  :: 83\n",
      "4063  :: 82\n",
      "4081  :: 82\n",
      "4095  :: 82\n",
      "4106  :: 82\n",
      "4108  :: 82\n",
      "4114  :: 82\n",
      "4120  :: 82\n",
      "4121  :: 82\n",
      "4139  :: 82\n",
      "4140  :: 82\n",
      "4141  :: 82\n",
      "4142  :: 82\n",
      "4143  :: 82\n",
      "4144  :: 82\n",
      "4145  :: 82\n",
      "4146  :: 82\n",
      "4147  :: 82\n",
      "4148  :: 82\n",
      "4149  :: 82\n",
      "4150  :: 82\n",
      "4151  :: 82\n",
      "4152  :: 82\n",
      "4153  :: 82\n",
      "4154  :: 82\n",
      "4155  :: 82\n",
      "4156  :: 82\n",
      "4159  :: 82\n",
      "4160  :: 82\n",
      "4161  :: 82\n",
      "4162  :: 82\n",
      "4164  :: 82\n",
      "4165  :: 82\n",
      "4166  :: 82\n",
      "4167  :: 82\n",
      "4169  :: 82\n",
      "4170  :: 82\n",
      "4171  :: 82\n",
      "4085  :: 81\n",
      "4127  :: 81\n",
      "4158  :: 81\n",
      "4172  :: 81\n",
      "4173  :: 81\n",
      "4175  :: 81\n",
      "4176  :: 81\n",
      "4177  :: 81\n",
      "4179  :: 81\n",
      "4180  :: 81\n",
      "4181  :: 81\n",
      "4182  :: 81\n",
      "4183  :: 81\n",
      "4184  :: 81\n",
      "4185  :: 81\n",
      "4186  :: 81\n",
      "4187  :: 81\n",
      "4188  :: 81\n",
      "4189  :: 81\n",
      "4190  :: 81\n",
      "4191  :: 81\n",
      "4192  :: 81\n",
      "4193  :: 81\n",
      "4194  :: 81\n",
      "4196  :: 81\n",
      "4197  :: 81\n",
      "4199  :: 81\n",
      "4200  :: 81\n",
      "4201  :: 81\n",
      "4202  :: 81\n",
      "4203  :: 81\n",
      "4204  :: 81\n",
      "4207  :: 81\n",
      "4208  :: 81\n",
      "4209  :: 81\n",
      "4210  :: 81\n",
      "4211  :: 81\n",
      "4213  :: 81\n",
      "4157  :: 80\n",
      "4163  :: 80\n",
      "4168  :: 80\n",
      "4174  :: 80\n",
      "4178  :: 80\n",
      "4195  :: 80\n",
      "4198  :: 80\n",
      "4214  :: 80\n",
      "4215  :: 80\n",
      "4216  :: 80\n",
      "4218  :: 80\n",
      "4219  :: 80\n",
      "4220  :: 80\n",
      "4221  :: 80\n",
      "4222  :: 80\n",
      "4224  :: 80\n",
      "4225  :: 80\n",
      "4226  :: 80\n",
      "4227  :: 80\n",
      "4228  :: 80\n",
      "4229  :: 80\n",
      "4230  :: 80\n",
      "4231  :: 80\n",
      "4232  :: 80\n",
      "4233  :: 80\n",
      "4234  :: 80\n",
      "4235  :: 80\n",
      "4236  :: 80\n",
      "4239  :: 80\n",
      "4241  :: 80\n",
      "4242  :: 80\n",
      "4243  :: 80\n",
      "4244  :: 80\n",
      "4245  :: 80\n",
      "4246  :: 80\n",
      "4247  :: 80\n",
      "4043  :: 79\n",
      "4206  :: 79\n",
      "4212  :: 79\n",
      "4217  :: 79\n",
      "4223  :: 79\n",
      "4237  :: 79\n",
      "4238  :: 79\n",
      "4248  :: 79\n",
      "4249  :: 79\n",
      "4250  :: 79\n",
      "4251  :: 79\n",
      "4253  :: 79\n",
      "4254  :: 79\n",
      "4255  :: 79\n",
      "4256  :: 79\n",
      "4257  :: 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4258  :: 79\n",
      "4259  :: 79\n",
      "4260  :: 79\n",
      "4261  :: 79\n",
      "4262  :: 79\n",
      "4263  :: 79\n",
      "4264  :: 79\n",
      "4265  :: 79\n",
      "4266  :: 79\n",
      "4267  :: 79\n",
      "4268  :: 79\n",
      "4270  :: 79\n",
      "4272  :: 79\n",
      "4274  :: 79\n",
      "4275  :: 79\n",
      "4276  :: 79\n",
      "4277  :: 79\n",
      "4278  :: 79\n",
      "4279  :: 79\n",
      "4280  :: 79\n",
      "4281  :: 79\n",
      "4282  :: 79\n",
      "4283  :: 79\n",
      "4126  :: 78\n",
      "4205  :: 78\n",
      "4252  :: 78\n",
      "4271  :: 78\n",
      "4273  :: 78\n",
      "4285  :: 78\n",
      "4286  :: 78\n",
      "4287  :: 78\n",
      "4288  :: 78\n",
      "4289  :: 78\n",
      "4290  :: 78\n",
      "4291  :: 78\n",
      "4292  :: 78\n",
      "4293  :: 78\n",
      "4294  :: 78\n",
      "4295  :: 78\n",
      "4298  :: 78\n",
      "4300  :: 78\n",
      "4301  :: 78\n",
      "4302  :: 78\n",
      "4304  :: 78\n",
      "4305  :: 78\n",
      "4306  :: 78\n",
      "4308  :: 78\n",
      "4310  :: 78\n",
      "4311  :: 78\n",
      "4312  :: 78\n",
      "4313  :: 78\n",
      "4296  :: 77\n",
      "4297  :: 77\n",
      "4307  :: 77\n",
      "4309  :: 77\n",
      "4314  :: 77\n",
      "4317  :: 77\n",
      "4319  :: 77\n",
      "4320  :: 77\n",
      "4321  :: 77\n",
      "4322  :: 77\n",
      "4323  :: 77\n",
      "4324  :: 77\n",
      "4325  :: 77\n",
      "4326  :: 77\n",
      "4330  :: 77\n",
      "4331  :: 77\n",
      "4332  :: 77\n",
      "4333  :: 77\n",
      "4334  :: 77\n",
      "4335  :: 77\n",
      "4337  :: 77\n",
      "4338  :: 77\n",
      "4341  :: 77\n",
      "4343  :: 77\n",
      "4344  :: 77\n",
      "4345  :: 77\n",
      "4346  :: 77\n",
      "4348  :: 77\n",
      "4349  :: 77\n",
      "4350  :: 77\n",
      "4351  :: 77\n",
      "4353  :: 77\n",
      "4354  :: 77\n",
      "4355  :: 77\n",
      "4269  :: 76\n",
      "4315  :: 76\n",
      "4316  :: 76\n",
      "4318  :: 76\n",
      "4327  :: 76\n",
      "4328  :: 76\n",
      "4329  :: 76\n",
      "4336  :: 76\n",
      "4342  :: 76\n",
      "4347  :: 76\n",
      "4357  :: 76\n",
      "4359  :: 76\n",
      "4360  :: 76\n",
      "4362  :: 76\n",
      "4363  :: 76\n",
      "4364  :: 76\n",
      "4365  :: 76\n",
      "4366  :: 76\n",
      "4367  :: 76\n",
      "4369  :: 76\n",
      "4371  :: 76\n",
      "4372  :: 76\n",
      "4373  :: 76\n",
      "4374  :: 76\n",
      "4375  :: 76\n",
      "4376  :: 76\n",
      "4377  :: 76\n",
      "4378  :: 76\n",
      "4379  :: 76\n",
      "4380  :: 76\n",
      "4381  :: 76\n",
      "4382  :: 76\n",
      "4383  :: 76\n",
      "4384  :: 76\n",
      "4386  :: 76\n",
      "4387  :: 76\n",
      "4388  :: 76\n",
      "4389  :: 76\n",
      "4390  :: 76\n",
      "4391  :: 76\n",
      "4392  :: 76\n",
      "4393  :: 76\n",
      "4394  :: 76\n",
      "4395  :: 76\n",
      "4396  :: 76\n",
      "4397  :: 76\n",
      "4398  :: 76\n",
      "4399  :: 76\n",
      "4401  :: 76\n",
      "4402  :: 76\n",
      "4240  :: 75\n",
      "4284  :: 75\n",
      "4299  :: 75\n",
      "4339  :: 75\n",
      "4340  :: 75\n",
      "4352  :: 75\n",
      "4356  :: 75\n",
      "4358  :: 75\n",
      "4361  :: 75\n",
      "4370  :: 75\n",
      "4400  :: 75\n",
      "4403  :: 75\n",
      "4405  :: 75\n",
      "4406  :: 75\n",
      "4407  :: 75\n",
      "4408  :: 75\n",
      "4409  :: 75\n",
      "4410  :: 75\n",
      "4411  :: 75\n",
      "4413  :: 75\n",
      "4414  :: 75\n",
      "4415  :: 75\n",
      "4416  :: 75\n",
      "4417  :: 75\n",
      "4418  :: 75\n",
      "4421  :: 75\n",
      "4422  :: 75\n",
      "4424  :: 75\n",
      "4425  :: 75\n",
      "4426  :: 75\n",
      "4428  :: 75\n",
      "4429  :: 75\n",
      "4430  :: 75\n",
      "4431  :: 75\n",
      "4432  :: 75\n",
      "4434  :: 75\n",
      "4435  :: 75\n",
      "4303  :: 74\n",
      "4385  :: 74\n",
      "4404  :: 74\n",
      "4412  :: 74\n",
      "4420  :: 74\n",
      "4423  :: 74\n",
      "4427  :: 74\n",
      "4433  :: 74\n",
      "4436  :: 74\n",
      "4438  :: 74\n",
      "4440  :: 74\n",
      "4442  :: 74\n",
      "4443  :: 74\n",
      "4444  :: 74\n",
      "4446  :: 74\n",
      "4447  :: 74\n",
      "4448  :: 74\n",
      "4449  :: 74\n",
      "4450  :: 74\n",
      "4451  :: 74\n",
      "4452  :: 74\n",
      "4453  :: 74\n",
      "4454  :: 74\n",
      "4455  :: 74\n",
      "4456  :: 74\n",
      "4457  :: 74\n",
      "4460  :: 74\n",
      "4462  :: 74\n",
      "4463  :: 74\n",
      "4464  :: 74\n",
      "4465  :: 74\n",
      "4466  :: 74\n",
      "4467  :: 74\n",
      "4468  :: 74\n",
      "4469  :: 74\n",
      "4437  :: 73\n",
      "4439  :: 73\n",
      "4441  :: 73\n",
      "4445  :: 73\n",
      "4459  :: 73\n",
      "4461  :: 73\n",
      "4470  :: 73\n",
      "4471  :: 73\n",
      "4472  :: 73\n",
      "4474  :: 73\n",
      "4475  :: 73\n",
      "4476  :: 73\n",
      "4477  :: 73\n",
      "4478  :: 73\n",
      "4479  :: 73\n",
      "4480  :: 73\n",
      "4481  :: 73\n",
      "4483  :: 73\n",
      "4484  :: 73\n",
      "4485  :: 73\n",
      "4486  :: 73\n",
      "4487  :: 73\n",
      "4488  :: 73\n",
      "4489  :: 73\n",
      "4490  :: 73\n",
      "4491  :: 73\n",
      "4492  :: 73\n",
      "4493  :: 73\n",
      "4494  :: 73\n",
      "4495  :: 73\n",
      "4496  :: 73\n",
      "4497  :: 73\n",
      "4498  :: 73\n",
      "4499  :: 73\n",
      "4500  :: 73\n",
      "4501  :: 73\n",
      "4502  :: 73\n",
      "4503  :: 73\n",
      "4458  :: 72\n",
      "4473  :: 72\n",
      "4482  :: 72\n",
      "4504  :: 72\n",
      "4505  :: 72\n",
      "4506  :: 72\n",
      "4507  :: 72\n",
      "4509  :: 72\n",
      "4510  :: 72\n",
      "4511  :: 72\n",
      "4512  :: 72\n",
      "4513  :: 72\n",
      "4514  :: 72\n",
      "4515  :: 72\n",
      "4518  :: 72\n",
      "4520  :: 72\n",
      "4521  :: 72\n",
      "4522  :: 72\n",
      "4523  :: 72\n",
      "4524  :: 72\n",
      "4525  :: 72\n",
      "4526  :: 72\n",
      "4527  :: 72\n",
      "4528  :: 72\n",
      "4529  :: 72\n",
      "4531  :: 72\n",
      "4533  :: 72\n",
      "4535  :: 72\n",
      "4536  :: 72\n",
      "4537  :: 72\n",
      "4538  :: 72\n",
      "4539  :: 72\n",
      "4540  :: 72\n",
      "4541  :: 72\n",
      "4542  :: 72\n",
      "4368  :: 71\n",
      "4517  :: 71\n",
      "4519  :: 71\n",
      "4530  :: 71\n",
      "4532  :: 71\n",
      "4534  :: 71\n",
      "4544  :: 71\n",
      "4545  :: 71\n",
      "4547  :: 71\n",
      "4548  :: 71\n",
      "4550  :: 71\n",
      "4551  :: 71\n",
      "4552  :: 71\n",
      "4553  :: 71\n",
      "4554  :: 71\n",
      "4555  :: 71\n",
      "4556  :: 71\n",
      "4557  :: 71\n",
      "4558  :: 71\n",
      "4559  :: 71\n",
      "4560  :: 71\n",
      "4561  :: 71\n",
      "4562  :: 71\n",
      "4563  :: 71\n",
      "4564  :: 71\n",
      "4565  :: 71\n",
      "4566  :: 71\n",
      "4567  :: 71\n",
      "4568  :: 71\n",
      "4569  :: 71\n",
      "4570  :: 71\n",
      "4571  :: 71\n",
      "4572  :: 71\n",
      "4573  :: 71\n",
      "4574  :: 71\n",
      "4576  :: 71\n",
      "4577  :: 71\n",
      "4578  :: 71\n",
      "4579  :: 71\n",
      "4580  :: 71\n",
      "4581  :: 71\n",
      "4582  :: 71\n",
      "4583  :: 71\n",
      "4419  :: 70\n",
      "4508  :: 70\n",
      "4516  :: 70\n",
      "4543  :: 70\n",
      "4575  :: 70\n",
      "4584  :: 70\n",
      "4585  :: 70\n",
      "4586  :: 70\n",
      "4587  :: 70\n",
      "4588  :: 70\n",
      "4589  :: 70\n",
      "4590  :: 70\n",
      "4591  :: 70\n",
      "4592  :: 70\n",
      "4593  :: 70\n",
      "4594  :: 70\n",
      "4595  :: 70\n",
      "4596  :: 70\n",
      "4597  :: 70\n",
      "4598  :: 70\n",
      "4599  :: 70\n",
      "4600  :: 70\n",
      "4601  :: 70\n",
      "4603  :: 70\n",
      "4605  :: 70\n",
      "4606  :: 70\n",
      "4607  :: 70\n",
      "4608  :: 70\n",
      "4609  :: 70\n",
      "4610  :: 70\n",
      "4613  :: 70\n",
      "4614  :: 70\n",
      "4615  :: 70\n",
      "4616  :: 70\n",
      "4617  :: 70\n",
      "4619  :: 70\n",
      "4620  :: 70\n",
      "4621  :: 70\n",
      "4622  :: 70\n",
      "4623  :: 70\n",
      "4624  :: 70\n",
      "4625  :: 70\n",
      "4626  :: 70\n",
      "4627  :: 70\n",
      "4628  :: 70\n",
      "4629  :: 70\n",
      "4630  :: 70\n",
      "4631  :: 70\n",
      "4632  :: 70\n",
      "4546  :: 69\n",
      "4602  :: 69\n",
      "4611  :: 69\n",
      "4612  :: 69\n",
      "4618  :: 69\n",
      "4633  :: 69\n",
      "4634  :: 69\n",
      "4635  :: 69\n",
      "4637  :: 69\n",
      "4638  :: 69\n",
      "4639  :: 69\n",
      "4640  :: 69\n",
      "4641  :: 69\n",
      "4642  :: 69\n",
      "4643  :: 69\n",
      "4644  :: 69\n",
      "4646  :: 69\n",
      "4648  :: 69\n",
      "4649  :: 69\n",
      "4650  :: 69\n",
      "4651  :: 69\n",
      "4653  :: 69\n",
      "4655  :: 69\n",
      "4658  :: 69\n",
      "4659  :: 69\n",
      "4660  :: 69\n",
      "4661  :: 69\n",
      "4662  :: 69\n",
      "4663  :: 69\n",
      "4664  :: 69\n",
      "4665  :: 69\n",
      "4666  :: 69\n",
      "4667  :: 69\n",
      "4668  :: 69\n",
      "4670  :: 69\n",
      "4673  :: 69\n",
      "4604  :: 68\n",
      "4636  :: 68\n",
      "4647  :: 68\n",
      "4654  :: 68\n",
      "4656  :: 68\n",
      "4657  :: 68\n",
      "4671  :: 68\n",
      "4672  :: 68\n",
      "4675  :: 68\n",
      "4676  :: 68\n",
      "4678  :: 68\n",
      "4680  :: 68\n",
      "4681  :: 68\n",
      "4682  :: 68\n",
      "4683  :: 68\n",
      "4684  :: 68\n",
      "4685  :: 68\n",
      "4686  :: 68\n",
      "4687  :: 68\n",
      "4688  :: 68\n",
      "4689  :: 68\n",
      "4690  :: 68\n",
      "4691  :: 68\n",
      "4693  :: 68\n",
      "4694  :: 68\n",
      "4695  :: 68\n",
      "4696  :: 68\n",
      "4697  :: 68\n",
      "4698  :: 68\n",
      "4700  :: 68\n",
      "4701  :: 68\n",
      "4703  :: 68\n",
      "4704  :: 68\n",
      "4705  :: 68\n",
      "4706  :: 68\n",
      "4707  :: 68\n",
      "4708  :: 68\n",
      "4709  :: 68\n",
      "4710  :: 68\n",
      "4711  :: 68\n",
      "4713  :: 68\n",
      "4714  :: 68\n",
      "4715  :: 68\n",
      "4717  :: 68\n",
      "4718  :: 68\n",
      "4719  :: 68\n",
      "4720  :: 68\n",
      "4721  :: 68\n",
      "4722  :: 68\n",
      "4723  :: 68\n",
      "4724  :: 68\n",
      "4674  :: 67\n",
      "4679  :: 67\n",
      "4699  :: 67\n",
      "4712  :: 67\n",
      "4716  :: 67\n",
      "4725  :: 67\n",
      "4726  :: 67\n",
      "4727  :: 67\n",
      "4728  :: 67\n",
      "4729  :: 67\n",
      "4731  :: 67\n",
      "4732  :: 67\n",
      "4733  :: 67\n",
      "4734  :: 67\n",
      "4736  :: 67\n",
      "4737  :: 67\n",
      "4738  :: 67\n",
      "4739  :: 67\n",
      "4740  :: 67\n",
      "4741  :: 67\n",
      "4742  :: 67\n",
      "4743  :: 67\n",
      "4744  :: 67\n",
      "4745  :: 67\n",
      "4746  :: 67\n",
      "4747  :: 67\n",
      "4748  :: 67\n",
      "4749  :: 67\n",
      "4750  :: 67\n",
      "4751  :: 67\n",
      "4752  :: 67\n",
      "4753  :: 67\n",
      "4754  :: 67\n",
      "4756  :: 67\n",
      "4757  :: 67\n",
      "4758  :: 67\n",
      "4759  :: 67\n",
      "4760  :: 67\n",
      "4761  :: 67\n",
      "4762  :: 67\n",
      "4763  :: 67\n",
      "4765  :: 67\n",
      "4768  :: 67\n",
      "4769  :: 67\n",
      "4770  :: 67\n",
      "4771  :: 67\n",
      "4772  :: 67\n",
      "4774  :: 67\n",
      "4775  :: 67\n",
      "4652  :: 66\n",
      "4669  :: 66\n",
      "4677  :: 66\n",
      "4702  :: 66\n",
      "4730  :: 66\n",
      "4735  :: 66\n",
      "4766  :: 66\n",
      "4773  :: 66\n",
      "4777  :: 66\n",
      "4778  :: 66\n",
      "4779  :: 66\n",
      "4780  :: 66\n",
      "4781  :: 66\n",
      "4783  :: 66\n",
      "4784  :: 66\n",
      "4785  :: 66\n",
      "4787  :: 66\n",
      "4788  :: 66\n",
      "4789  :: 66\n",
      "4790  :: 66\n",
      "4791  :: 66\n",
      "4792  :: 66\n",
      "4794  :: 66\n",
      "4795  :: 66\n",
      "4796  :: 66\n",
      "4798  :: 66\n",
      "4799  :: 66\n",
      "4800  :: 66\n",
      "4801  :: 66\n",
      "4802  :: 66\n",
      "4803  :: 66\n",
      "4805  :: 66\n",
      "4806  :: 66\n",
      "4807  :: 66\n",
      "4809  :: 66\n",
      "4811  :: 66\n",
      "4812  :: 66\n",
      "4813  :: 66\n",
      "4645  :: 65\n",
      "4692  :: 65\n",
      "4764  :: 65\n",
      "4776  :: 65\n",
      "4793  :: 65\n",
      "4804  :: 65\n",
      "4810  :: 65\n",
      "4815  :: 65\n",
      "4816  :: 65\n",
      "4819  :: 65\n",
      "4822  :: 65\n",
      "4823  :: 65\n",
      "4824  :: 65\n",
      "4825  :: 65\n",
      "4826  :: 65\n",
      "4827  :: 65\n",
      "4828  :: 65\n",
      "4831  :: 65\n",
      "4832  :: 65\n",
      "4833  :: 65\n",
      "4834  :: 65\n",
      "4835  :: 65\n",
      "4836  :: 65\n",
      "4837  :: 65\n",
      "4838  :: 65\n",
      "4842  :: 65\n",
      "4843  :: 65\n",
      "4844  :: 65\n",
      "4845  :: 65\n",
      "4846  :: 65\n",
      "4847  :: 65\n",
      "4848  :: 65\n",
      "4849  :: 65\n",
      "4850  :: 65\n",
      "4852  :: 65\n",
      "4854  :: 65\n",
      "4855  :: 65\n",
      "4856  :: 65\n",
      "4857  :: 65\n",
      "4858  :: 65\n",
      "4767  :: 64\n",
      "4782  :: 64\n",
      "4786  :: 64\n",
      "4797  :: 64\n",
      "4808  :: 64\n",
      "4814  :: 64\n",
      "4818  :: 64\n",
      "4820  :: 64\n",
      "4829  :: 64\n",
      "4830  :: 64\n",
      "4839  :: 64\n",
      "4840  :: 64\n",
      "4841  :: 64\n",
      "4851  :: 64\n",
      "4853  :: 64\n",
      "4860  :: 64\n",
      "4861 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4998it [00:00, 806863.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: 64\n",
      "4862  :: 64\n",
      "4864  :: 64\n",
      "4866  :: 64\n",
      "4870  :: 64\n",
      "4871  :: 64\n",
      "4874  :: 64\n",
      "4875  :: 64\n",
      "4876  :: 64\n",
      "4877  :: 64\n",
      "4878  :: 64\n",
      "4879  :: 64\n",
      "4880  :: 64\n",
      "4883  :: 64\n",
      "4884  :: 64\n",
      "4885  :: 64\n",
      "4886  :: 64\n",
      "4887  :: 64\n",
      "4888  :: 64\n",
      "4889  :: 64\n",
      "4890  :: 64\n",
      "4891  :: 64\n",
      "4892  :: 64\n",
      "4893  :: 64\n",
      "4894  :: 64\n",
      "4895  :: 64\n",
      "4898  :: 64\n",
      "4899  :: 64\n",
      "4900  :: 64\n",
      "4901  :: 64\n",
      "4902  :: 64\n",
      "4903  :: 64\n",
      "4904  :: 64\n",
      "4905  :: 64\n",
      "4907  :: 64\n",
      "4908  :: 64\n",
      "4821  :: 63\n",
      "4867  :: 63\n",
      "4868  :: 63\n",
      "4869  :: 63\n",
      "4872  :: 63\n",
      "4873  :: 63\n",
      "4881  :: 63\n",
      "4882  :: 63\n",
      "4896  :: 63\n",
      "4897  :: 63\n",
      "4909  :: 63\n",
      "4910  :: 63\n",
      "4911  :: 63\n",
      "4912  :: 63\n",
      "4913  :: 63\n",
      "4914  :: 63\n",
      "4915  :: 63\n",
      "4916  :: 63\n",
      "4918  :: 63\n",
      "4920  :: 63\n",
      "4921  :: 63\n",
      "4923  :: 63\n",
      "4925  :: 63\n",
      "4926  :: 63\n",
      "4927  :: 63\n",
      "4928  :: 63\n",
      "4929  :: 63\n",
      "4931  :: 63\n",
      "4932  :: 63\n",
      "4933  :: 63\n",
      "4934  :: 63\n",
      "4935  :: 63\n",
      "4936  :: 63\n",
      "4937  :: 63\n",
      "4938  :: 63\n",
      "4939  :: 63\n",
      "4940  :: 63\n",
      "4941  :: 63\n",
      "4942  :: 63\n",
      "4943  :: 63\n",
      "4944  :: 63\n",
      "4945  :: 63\n",
      "4946  :: 63\n",
      "4947  :: 63\n",
      "4948  :: 63\n",
      "4949  :: 63\n",
      "4951  :: 63\n",
      "4953  :: 63\n",
      "4954  :: 63\n",
      "4955  :: 63\n",
      "4956  :: 63\n",
      "4957  :: 63\n",
      "4958  :: 63\n",
      "4959  :: 63\n",
      "4960  :: 63\n",
      "4961  :: 63\n",
      "4962  :: 63\n",
      "4963  :: 63\n",
      "4817  :: 62\n",
      "4863  :: 62\n",
      "4865  :: 62\n",
      "4906  :: 62\n",
      "4917  :: 62\n",
      "4919  :: 62\n",
      "4924  :: 62\n",
      "4930  :: 62\n",
      "4950  :: 62\n",
      "4952  :: 62\n",
      "4964  :: 62\n",
      "4965  :: 62\n",
      "4966  :: 62\n",
      "4968  :: 62\n",
      "4969  :: 62\n",
      "4970  :: 62\n",
      "4971  :: 62\n",
      "4972  :: 62\n",
      "4973  :: 62\n",
      "4974  :: 62\n",
      "4975  :: 62\n",
      "4976  :: 62\n",
      "4978  :: 62\n",
      "4980  :: 62\n",
      "4981  :: 62\n",
      "4982  :: 62\n",
      "4983  :: 62\n",
      "4985  :: 62\n",
      "4987  :: 62\n",
      "4988  :: 62\n",
      "4989  :: 62\n",
      "4990  :: 62\n",
      "4991  :: 62\n",
      "4992  :: 62\n",
      "4994  :: 62\n",
      "4995  :: 62\n",
      "4996  :: 62\n",
      "4997  :: 62\n",
      "4998  :: 62\n",
      "4999  :: 62\n",
      "4967  :: 61\n",
      "4977  :: 61\n",
      "4979  :: 61\n",
      "4984  :: 61\n",
      "4993  :: 61\n",
      "4922  :: 60\n",
      "4986  :: 60\n",
      "4859  :: 57\n",
      "4549  :: 56\n",
      "4755  :: 53\n",
      "word counts with keys\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 46, 48, 50, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 92, 94, 95, 96, 98, 97, 99, 100, 101, 102, 104, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 114, 116, 118, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 148, 150, 151, 152, 153, 154, 155, 157, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 167, 169, 170, 171, 172, 174, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 197, 199, 200, 201, 202, 204, 203, 205, 206, 207, 208, 209, 211, 210, 212, 213, 215, 216, 214, 217, 218, 219, 221, 220, 222, 223, 224, 225, 226, 227, 229, 228, 230, 231, 232, 235, 234, 233, 236, 237, 238, 239, 241, 240, 242, 243, 244, 246, 247, 245, 248, 250, 249, 251, 252, 254, 253, 255, 256, 257, 260, 259, 258, 261, 262, 263, 264, 265, 266, 268, 267, 269, 270, 272, 271, 274, 275, 273, 276, 277, 278, 279, 280, 281, 282, 284, 283, 285, 287, 286, 288, 289, 292, 290, 291, 293, 294, 296, 298, 295, 297, 299, 300, 301, 302, 304, 303, 306, 307, 308, 305, 309, 311, 310, 312, 314, 313, 315, 316, 317, 318, 320, 321, 322, 319, 324, 323, 325, 326, 327, 329, 330, 328, 331, 332, 333, 334, 335, 336, 338, 340, 337, 339, 341, 342, 343, 345, 344, 346, 347, 350, 349, 348, 351, 352, 353, 354, 355, 356, 357, 358, 362, 363, 360, 359, 361, 365, 366, 367, 364, 368, 369, 370, 372, 371, 374, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 389, 388, 391, 390, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 404, 403, 406, 405, 408, 407, 410, 411, 409, 413, 412, 414, 418, 416, 419, 415, 417, 421, 420, 422, 423, 425, 424, 426, 427, 429, 430, 428, 431, 432, 435, 434, 433, 436, 437, 438, 440, 441, 439, 442, 443, 444, 445, 446, 447, 448, 450, 449, 451, 452, 453, 455, 454, 456, 458, 457, 459, 460, 461, 462, 464, 463, 465, 466, 467, 468, 469, 470, 472, 473, 474, 471, 475, 478, 476, 479, 477, 480, 482, 481, 483, 484, 486, 487, 485, 488, 489, 490, 491, 492, 496, 497, 494, 493, 495, 498, 500, 499, 501, 502, 503, 505, 506, 504, 507, 509, 508, 510, 511, 512, 513, 517, 516, 515, 519, 520, 521, 518, 522, 523, 526, 525, 529, 524, 528, 532, 527, 530, 531, 533, 535, 536, 534, 537, 538, 514, 542, 539, 541, 543, 540, 544, 546, 545, 547, 548, 549, 552, 550, 553, 554, 551, 555, 556, 558, 560, 563, 559, 565, 561, 562, 564, 557, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 577, 576, 579, 578, 580, 583, 581, 582, 585, 584, 587, 586, 588, 592, 590, 594, 593, 589, 591, 597, 596, 599, 602, 595, 601, 603, 598, 604, 605, 606, 607, 600, 608, 610, 612, 614, 609, 611, 615, 613, 618, 619, 617, 616, 621, 623, 620, 622, 625, 627, 628, 630, 631, 624, 626, 637, 633, 638, 629, 635, 632, 634, 639, 640, 636, 642, 641, 644, 643, 645, 646, 647, 648, 649, 650, 651, 653, 652, 654, 655, 656, 658, 657, 659, 663, 661, 662, 665, 664, 660, 667, 666, 668, 669, 670, 671, 672, 673, 674, 675, 677, 678, 676, 679, 680, 682, 681, 683, 684, 685, 689, 686, 688, 690, 687, 692, 694, 693, 695, 697, 696, 700, 701, 703, 699, 698, 704, 702, 707, 691, 705, 708, 706, 709, 712, 710, 717, 715, 713, 716, 711, 714, 719, 720, 718, 722, 721, 724, 726, 725, 728, 723, 729, 730, 731, 727, 733, 732, 734, 735, 737, 739, 736, 738, 740, 743, 744, 741, 748, 747, 749, 742, 745, 750, 746, 751, 752, 754, 753, 759, 756, 757, 758, 762, 760, 761, 764, 763, 755, 765, 766, 767, 768, 769, 770, 771, 773, 775, 772, 774, 776, 777, 778, 779, 780, 781, 782, 783, 784, 787, 786, 790, 785, 788, 792, 789, 791, 793, 794, 796, 795, 797, 799, 800, 804, 805, 806, 798, 801, 802, 807, 803, 809, 808, 812, 811, 814, 810, 813, 815, 816, 819, 817, 818, 820, 822, 823, 821, 824, 825, 827, 828, 829, 826, 831, 832, 830, 833, 834, 835, 836, 838, 839, 842, 845, 837, 847, 844, 841, 846, 843, 840, 850, 851, 852, 848, 853, 854, 857, 849, 858, 855, 856, 861, 859, 860, 862, 863, 864, 865, 866, 867, 868, 869, 871, 873, 872, 874, 870, 875, 876, 878, 879, 880, 877, 883, 884, 881, 882, 888, 889, 885, 886, 887, 892, 890, 894, 891, 893, 895, 897, 896, 898, 900, 903, 904, 902, 899, 905, 901, 906, 907, 909, 910, 908, 911, 912, 913, 915, 914, 917, 918, 916, 919, 921, 922, 920, 924, 923, 926, 925, 929, 928, 927, 931, 932, 933, 935, 934, 936, 938, 940, 941, 942, 943, 937, 939, 945, 930, 947, 948, 950, 946, 949, 953, 944, 951, 952, 956, 955, 958, 954, 957, 960, 959, 962, 961, 963, 964, 965, 966, 968, 971, 972, 967, 969, 970, 973, 974, 978, 979, 975, 976, 977, 982, 981, 980, 986, 983, 984, 987, 989, 990, 985, 988, 992, 991, 994, 998, 995, 1002, 996, 997, 1001, 999, 1000, 1003, 1004, 1006, 993, 1007, 1008, 1010, 1011, 1005, 1009, 1013, 1015, 1016, 1012, 1014, 1017, 1020, 1018, 1021, 1022, 1023, 1024, 1019, 1027, 1028, 1029, 1026, 1030, 1031, 1032, 1034, 1036, 1038, 1039, 1035, 1037, 1040, 1041, 1042, 1045, 1025, 1033, 1043, 1047, 1044, 1046, 1048, 1050, 1052, 1049, 1053, 1054, 1055, 1057, 1059, 1058, 1062, 1056, 1065, 1063, 1051, 1061, 1066, 1067, 1060, 1064, 1068, 1073, 1070, 1072, 1075, 1069, 1071, 1076, 1078, 1080, 1074, 1079, 1077, 1081, 1083, 1084, 1085, 1086, 1087, 1082, 1088, 1089, 1090, 1092, 1093, 1091, 1094, 1099, 1095, 1097, 1101, 1102, 1096, 1103, 1098, 1100, 1106, 1104, 1107, 1112, 1110, 1111, 1113, 1109, 1115, 1108, 1114, 1116, 1118, 1117, 1119, 1121, 1105, 1120, 1122, 1123, 1125, 1126, 1124, 1127, 1128, 1130, 1131, 1132, 1133, 1140, 1129, 1136, 1141, 1142, 1134, 1138, 1143, 1144, 1137, 1139, 1145, 1147, 1148, 1149, 1150, 1151, 1154, 1155, 1146, 1152, 1157, 1158, 1153, 1159, 1135, 1161, 1156, 1163, 1162, 1164, 1165, 1167, 1160, 1168, 1169, 1170, 1171, 1166, 1172, 1173, 1176, 1177, 1175, 1179, 1178, 1181, 1180, 1182, 1186, 1174, 1184, 1185, 1189, 1188, 1187, 1191, 1192, 1190, 1183, 1194, 1196, 1197, 1199, 1201, 1195, 1198, 1193, 1204, 1205, 1200, 1202, 1209, 1208, 1207, 1210, 1203, 1211, 1213, 1217, 1218, 1206, 1212, 1214, 1215, 1216, 1220, 1219, 1223, 1225, 1221, 1222, 1224, 1226, 1228, 1231, 1229, 1233, 1227, 1230, 1234, 1232, 1236, 1235, 1237, 1241, 1238, 1239, 1240, 1242, 1243, 1244, 1245, 1247, 1246, 1250, 1252, 1249, 1248, 1251, 1253, 1254, 1259, 1257, 1258, 1262, 1255, 1256, 1260, 1263, 1264, 1265, 1261, 1268, 1270, 1267, 1271, 1272, 1266, 1273, 1274, 1269, 1277, 1279, 1278, 1275, 1276, 1280, 1281, 1285, 1286, 1282, 1283, 1284, 1287, 1288, 1291, 1289, 1290, 1292, 1297, 1293, 1294, 1298, 1299, 1296, 1301, 1300, 1302, 1304, 1303, 1305, 1307, 1309, 1311, 1306, 1310, 1312, 1314, 1315, 1316, 1308, 1317, 1318, 1313, 1320, 1321, 1322, 1324, 1326, 1319, 1323, 1325, 1327, 1328, 1329, 1332, 1330, 1331, 1334, 1333, 1336, 1335, 1337, 1338, 1341, 1342, 1339, 1340, 1343, 1346, 1347, 1348, 1344, 1345, 1350, 1349, 1353, 1355, 1357, 1351, 1352, 1356, 1358, 1354, 1361, 1295, 1359, 1362, 1363, 1364, 1365, 1367, 1368, 1360, 1366, 1374, 1375, 1369, 1370, 1372, 1376, 1378, 1371, 1377, 1380, 1381, 1385, 1379, 1383, 1384, 1386, 1387, 1373, 1382, 1388, 1389, 1390, 1395, 1391, 1392, 1393, 1396, 1397, 1399, 1394, 1400, 1401, 1404, 1405, 1398, 1403, 1406, 1407, 1408, 1411, 1409, 1410, 1412, 1413, 1415, 1402, 1417, 1418, 1420, 1421, 1423, 1419, 1422, 1414, 1428, 1424, 1425, 1426, 1431, 1432, 1427, 1429, 1430, 1433, 1435, 1436, 1437, 1434, 1440, 1438, 1442, 1441, 1443, 1444, 1447, 1450, 1445, 1446, 1448, 1451, 1452, 1453, 1455, 1462, 1439, 1454, 1456, 1458, 1459, 1460, 1461, 1464, 1457, 1465, 1467, 1468, 1449, 1463, 1469, 1471, 1472, 1475, 1466, 1470, 1474, 1479, 1416, 1476, 1480, 1481, 1483, 1473, 1477, 1478, 1482, 1484, 1485, 1487, 1488, 1489, 1490, 1486, 1492, 1491, 1495, 1493, 1494, 1497, 1499, 1496, 1498, 1500, 1501, 1504, 1505, 1502, 1503, 1506, 1507, 1508, 1512, 1510, 1511, 1514, 1516, 1517, 1509, 1519, 1515, 1518, 1521, 1513, 1520, 1526, 1523, 1524, 1525, 1522, 1527, 1528, 1530, 1531, 1532, 1529, 1534, 1536, 1537, 1538, 1539, 1541, 1542, 1535, 1533, 1540, 1544, 1545, 1547, 1548, 1550, 1551, 1543, 1549, 1552, 1553, 1546, 1555, 1557, 1558, 1560, 1561, 1564, 1565, 1566, 1567, 1568, 1554, 1556, 1559, 1562, 1570, 1563, 1571, 1572, 1573, 1575, 1569, 1574, 1577, 1579, 1578, 1581, 1585, 1576, 1580, 1583, 1590, 1582, 1584, 1586, 1587, 1589, 1592, 1597, 1588, 1594, 1596, 1599, 1601, 1591, 1593, 1595, 1598, 1600, 1602, 1603, 1604, 1606, 1608, 1610, 1613, 1614, 1605, 1607, 1609, 1611, 1612, 1615, 1616, 1618, 1619, 1620, 1622, 1617, 1621, 1624, 1625, 1626, 1627, 1632, 1635, 1623, 1631, 1634, 1636, 1637, 1640, 1628, 1629, 1639, 1641, 1642, 1630, 1633, 1643, 1644, 1646, 1647, 1650, 1653, 1654, 1645, 1648, 1649, 1651, 1655, 1656, 1657, 1652, 1659, 1662, 1660, 1661, 1665, 1670, 1638, 1658, 1666, 1667, 1668, 1673, 1674, 1676, 1663, 1669, 1672, 1675, 1678, 1679, 1680, 1677, 1681, 1682, 1683, 1664, 1671, 1685, 1690, 1686, 1687, 1694, 1684, 1688, 1691, 1692, 1693, 1695, 1696, 1699, 1689, 1697, 1698, 1701, 1702, 1703, 1705, 1700, 1704, 1706, 1709, 1710, 1711, 1708, 1712, 1713, 1715, 1718, 1719, 1714, 1716, 1720, 1721, 1724, 1725, 1707, 1722, 1723, 1728, 1731, 1726, 1729, 1734, 1738, 1739, 1732, 1737, 1740, 1741, 1742, 1744, 1745, 1746, 1717, 1730, 1727, 1733, 1735, 1743, 1747, 1748, 1750, 1751, 1755, 1749, 1756, 1757, 1736, 1753, 1752, 1758, 1763, 1760, 1761, 1762, 1765, 1767, 1754, 1766, 1769, 1770, 1771, 1774, 1772, 1773, 1775, 1778, 1779, 1777, 1780, 1781, 1782, 1784, 1783, 1785, 1786, 1787, 1789, 1792, 1759, 1764, 1788, 1795, 1776, 1791, 1793, 1794, 1797, 1799, 1800, 1801, 1802, 1803, 1804, 1790, 1796, 1798, 1805, 1806, 1809, 1810, 1811, 1807, 1808, 1815, 1816, 1819, 1813, 1814, 1818, 1820, 1822, 1817, 1825, 1827, 1812, 1821, 1823, 1824, 1826, 1828, 1830, 1829, 1832, 1835, 1836, 1838, 1768, 1833, 1837, 1839, 1841, 1842, 1834, 1840, 1843, 1844, 1845, 1847, 1831, 1849, 1850, 1853, 1854, 1855, 1856, 1857, 1848, 1851, 1858, 1860, 1861, 1846, 1852, 1862, 1863, 1864, 1867, 1868, 1871, 1872, 1873, 1874, 1876, 1877, 1878, 1879, 1859, 1865, 1869, 1880, 1882, 1886, 1888, 1889, 1890, 1866, 1870, 1881, 1884, 1885, 1891, 1892, 1894, 1896, 1897, 1875, 1883, 1887, 1893, 1899, 1900, 1901, 1902, 1903, 1906, 1907, 1908, 1909, 1895, 1898, 1904, 1905, 1910, 1911, 1912, 1913, 1915, 1917, 1918, 1920, 1914, 1919, 1922, 1924, 1925, 1926, 1916, 1921, 1923, 1931, 1928, 1929, 1932, 1927, 1930, 1933, 1935, 1936, 1937, 1940, 1941, 1938, 1943, 1944, 1945, 1939, 1942, 1949, 1950, 1951, 1952, 1946, 1947, 1948, 1953, 1957, 1960, 1961, 1962, 1955, 1956, 1958, 1959, 1965, 1967, 1970, 1934, 1954, 1963, 1964, 1966, 1968, 1969, 1971, 1973, 1972, 1975, 1976, 1978, 1974, 1980, 1982, 1984, 1985, 1979, 1981, 1983, 1986, 1977, 1989, 1992, 1994, 1997, 1998, 1988, 1993, 1995, 1999, 2002, 1987, 1991, 2000, 2003, 2004, 1990, 1996, 2001, 2005, 2009, 2011, 2015, 2017, 2006, 2008, 2010, 2012, 2013, 2014, 2016, 2019, 2020, 2021, 2024, 2018, 2023, 2025, 2026, 2022, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2027, 2035, 2036, 2041, 2042, 2044, 2045, 2047, 2048, 2049, 2037, 2040, 2043, 2046, 2050, 2038, 2054, 2052, 2055, 2056, 2057, 2060, 2061, 2039, 2051, 2053, 2059, 2064, 2065, 2062, 2063, 2066, 2067, 2068, 2071, 2058, 2069, 2070, 2072, 2074, 2075, 2076, 2078, 2079, 2081, 2082, 2073, 2077, 2083, 2084, 2085, 2086, 2088, 2090, 2092, 2094, 2080, 2091, 2095, 2097, 2099, 2100, 2101, 2007, 2087, 2093, 2096, 2098, 2102, 2105, 2106, 2103, 2104, 2108, 2109, 2110, 2112, 2113, 2114, 2115, 2107, 2111, 2117, 2119, 2120, 2121, 2122, 2118, 2123, 2124, 2125, 2126, 2116, 2127, 2128, 2129, 2130, 2131, 2132, 2135, 2136, 2138, 2139, 2141, 2133, 2134, 2142, 2143, 2147, 2140, 2144, 2145, 2146, 2148, 2149, 2152, 2153, 2154, 2137, 2150, 2151, 2161, 2155, 2156, 2160, 2162, 2163, 2165, 2166, 2167, 2168, 2171, 2157, 2158, 2159, 2164, 2169, 2170, 2173, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2183, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2195, 2172, 2174, 2182, 2198, 2200, 2201, 2202, 2203, 2204, 2184, 2193, 2194, 2196, 2197, 2207, 2209, 2210, 2212, 2213, 2215, 2216, 2217, 2218, 2219, 2089, 2205, 2214, 2220, 2221, 2223, 2224, 2225, 2199, 2206, 2208, 2211, 2227, 2228, 2230, 2234, 2235, 2222, 2226, 2229, 2231, 2233, 2236, 2239, 2242, 2243, 2237, 2240, 2241, 2244, 2247, 2248, 2249, 2251, 2253, 2256, 2257, 2238, 2245, 2250, 2252, 2254, 2255, 2259, 2260, 2262, 2263, 2232, 2246, 2261, 2265, 2268, 2269, 2270, 2271, 2272, 2273, 2258, 2264, 2266, 2267, 2274, 2275, 2276, 2279, 2280, 2281, 2283, 2284, 2282, 2285, 2286, 2287, 2288, 2292, 2293, 2277, 2278, 2290, 2291, 2294, 2295, 2296, 2300, 2301, 2302, 2303, 2305, 2307, 2289, 2299, 2304, 2306, 2308, 2309, 2311, 2298, 2310, 2312, 2314, 2316, 2317, 2318, 2319, 2321, 2323, 2297, 2313, 2315, 2320, 2322, 2324, 2325, 2326, 2328, 2329, 2330, 2332, 2334, 2335, 2327, 2331, 2336, 2339, 2341, 2342, 2343, 2344, 2348, 2333, 2338, 2340, 2350, 2353, 2354, 2355, 2356, 2357, 2359, 2361, 2337, 2345, 2349, 2351, 2358, 2360, 2362, 2365, 2367, 2346, 2352, 2364, 2368, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2363, 2369, 2379, 2381, 2382, 2384, 2377, 2378, 2386, 2388, 2393, 2383, 2385, 2390, 2391, 2394, 2397, 2399, 2400, 2402, 2404, 2405, 2347, 2380, 2392, 2395, 2396, 2398, 2401, 2403, 2406, 2407, 2408, 2409, 2410, 2411, 2366, 2412, 2413, 2414, 2420, 2387, 2415, 2417, 2419, 2422, 2423, 2427, 2428, 2431, 2389, 2416, 2425, 2426, 2430, 2434, 2435, 2436, 2418, 2421, 2424, 2432, 2437, 2438, 2440, 2441, 2442, 2443, 2445, 2446, 2429, 2433, 2439, 2449, 2450, 2451, 2452, 2453, 2454, 2447, 2455, 2456, 2457, 2459, 2460, 2444, 2448, 2461, 2462, 2463, 2469, 2470, 2458, 2464, 2465, 2466, 2467, 2471, 2472, 2473, 2474, 2475, 2478, 2479, 2480, 2476, 2477, 2481, 2482, 2484, 2486, 2487, 2488, 2489, 2490, 2485, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2468, 2491, 2492, 2501, 2504, 2505, 2506, 2507, 2509, 2511, 2512, 2513, 2514, 2515, 2517, 2518, 2483, 2502, 2516, 2519, 2520, 2522, 2523, 2524, 2526, 2527, 2528, 2508, 2521, 2525, 2529, 2530, 2531, 2532, 2503, 2510, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2500, 2545, 2547, 2548, 2550, 2552, 2553, 2533, 2549, 2551, 2554, 2555, 2560, 2561, 2563, 2557, 2558, 2566, 2567, 2568, 2569, 2571, 2572, 2573, 2576, 2577, 2578, 2546, 2556, 2559, 2562, 2565, 2574, 2575, 2580, 2581, 2582, 2585, 2586, 2587, 2588, 2589, 2564, 2570, 2579, 2583, 2592, 2593, 2594, 2595, 2597, 2584, 2590, 2591, 2596, 2599, 2601, 2603, 2604, 2605, 2598, 2607, 2608, 2609, 2612, 2614, 2616, 2600, 2606, 2610, 2611, 2615, 2622, 2623, 2624, 2625, 2627, 2629, 2630, 2602, 2613, 2617, 2619, 2620, 2621, 2628, 2631, 2633, 2634, 2635, 2636, 2637, 2639, 2642, 2626, 2638, 2640, 2641, 2643, 2645, 2646, 2647, 2648, 2649, 2650, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2661, 2618, 2632, 2644, 2660, 2662, 2665, 2667, 2669, 2670, 2671, 2672, 2673, 2675, 2663, 2666, 2674, 2677, 2680, 2681, 2683, 2684, 2687, 2688, 2690, 2692, 2694, 2696, 2664, 2676, 2678, 2679, 2686, 2689, 2691, 2693, 2695, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2705, 2708, 2651, 2682, 2706, 2707, 2709, 2710, 2712, 2713, 2715, 2716, 2717, 2704, 2718, 2720, 2723, 2724, 2726, 2727, 2728, 2668, 2685, 2711, 2722, 2725, 2729, 2732, 2734, 2735, 2736, 2737, 2740, 2741, 2742, 2743, 2719, 2721, 2738, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2730, 2733, 2744, 2745, 2756, 2758, 2759, 2760, 2762, 2763, 2764, 2765, 2766, 2769, 2770, 2714, 2739, 2757, 2767, 2772, 2774, 2775, 2777, 2778, 2779, 2780, 2782, 2731, 2761, 2768, 2771, 2773, 2783, 2784, 2785, 2786, 2788, 2789, 2790, 2791, 2776, 2781, 2787, 2792, 2793, 2796, 2797, 2798, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2794, 2799, 2811, 2812, 2813, 2814, 2815, 2817, 2818, 2819, 2820, 2821, 2823, 2824, 2826, 2827, 2828, 2795, 2822, 2825, 2829, 2830, 2831, 2832, 2834, 2835, 2837, 2840, 2841, 2816, 2833, 2838, 2839, 2842, 2843, 2844, 2847, 2848, 2849, 2836, 2845, 2846, 2850, 2852, 2854, 2855, 2860, 2861, 2862, 2851, 2853, 2856, 2857, 2858, 2859, 2863, 2864, 2865, 2867, 2868, 2870, 2871, 2872, 2873, 2874, 2875, 2878, 2879, 2880, 2881, 2866, 2869, 2876, 2882, 2883, 2885, 2886, 2887, 2888, 2889, 2890, 2892, 2884, 2891, 2893, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2877, 2894, 2907, 2908, 2909, 2910, 2912, 2913, 2916, 2911, 2914, 2917, 2920, 2921, 2922, 2923, 2919, 2924, 2925, 2926, 2927, 2929, 2931, 2933, 2918, 2928, 2930, 2932, 2935, 2936, 2937, 2938, 2940, 2941, 2943, 2944, 2945, 2948, 2949, 2950, 2915, 2946, 2947, 2951, 2952, 2953, 2957, 2958, 2960, 2963, 2966, 2934, 2942, 2955, 2956, 2961, 2962, 2965, 2967, 2968, 2969, 2970, 2971, 2973, 2975, 2976, 2954, 2959, 2972, 2974, 2977, 2978, 2980, 2982, 2983, 2984, 2985, 2986, 2987, 2989, 2990, 2979, 2981, 2991, 2992, 2993, 2994, 2995, 2998, 2999, 3000, 3002, 3003, 3004, 3005, 3006, 2939, 2988, 2997, 3001, 3007, 3009, 3010, 3011, 3014, 3015, 3016, 3017, 3019, 3023, 3024, 3025, 3026, 3027, 2964, 3012, 3013, 3020, 3021, 3022, 3028, 3029, 3032, 3033, 3035, 3036, 3037, 3038, 3039, 3040, 3042, 3043, 3044, 3046, 3048, 3008, 3034, 3041, 3047, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3059, 3060, 3061, 3062, 3063, 3064, 3066, 3018, 3030, 3031, 3045, 3049, 3058, 3071, 3072, 3074, 3075, 3076, 3081, 3082, 3084, 3065, 3068, 3069, 3077, 3078, 3079, 3080, 3085, 3086, 3087, 3089, 3090, 3093, 3094, 3097, 3098, 3099, 3102, 3104, 3105, 3108, 3109, 3067, 3070, 3083, 3088, 3091, 3092, 3100, 3101, 3103, 3106, 3107, 3111, 3112, 3113, 3114, 3116, 3117, 3118, 3119, 3120, 3121, 3123, 3124, 3128, 3129, 3130, 3073, 3096, 3115, 3122, 3125, 3126, 3131, 3132, 3133, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3144, 3145, 3148, 3149, 3127, 3134, 3146, 3147, 3150, 3151, 3152, 3153, 3158, 3159, 3160, 3161, 3164, 3165, 3095, 3154, 3157, 3163, 3167, 3168, 3169, 3170, 3171, 3173, 3174, 3175, 3178, 3179, 3143, 3155, 3156, 3162, 3172, 3176, 3177, 3181, 3183, 3185, 3186, 3191, 3192, 3193, 3110, 3166, 3180, 3184, 3187, 3189, 3194, 3195, 3196, 3197, 3199, 3201, 3202, 3204, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3182, 3190, 3198, 3200, 3203, 3205, 3206, 3218, 3219, 3221, 3222, 3223, 3226, 3228, 3231, 3232, 3234, 3235, 3236, 2996, 3188, 3224, 3225, 3227, 3229, 3233, 3237, 3239, 3241, 3242, 3243, 3245, 3246, 3247, 3248, 3249, 3251, 3254, 3255, 3256, 3259, 3260, 3261, 3262, 3263, 3230, 3240, 3244, 3250, 3252, 3253, 3257, 3258, 3266, 3268, 3269, 3271, 3272, 3273, 3274, 3276, 3277, 3279, 3280, 3238, 3264, 3265, 3275, 3278, 3281, 3285, 3289, 3290, 3292, 3293, 3294, 3267, 3270, 3283, 3284, 3286, 3288, 3291, 3296, 3297, 3298, 3299, 3301, 3302, 3303, 3304, 3307, 3308, 3309, 3310, 3282, 3287, 3300, 3305, 3306, 3311, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3322, 3323, 3324, 3326, 3328, 3329, 3295, 3312, 3321, 3325, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3339, 3341, 3342, 3346, 3347, 3351, 3353, 3354, 3327, 3340, 3343, 3345, 3348, 3349, 3355, 3356, 3357, 3358, 3359, 3362, 3364, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3338, 3352, 3360, 3361, 3363, 3366, 3376, 3377, 3378, 3379, 3381, 3382, 3383, 3385, 3386, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3397, 3398, 3400, 3220, 3350, 3380, 3384, 3387, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3411, 3412, 3414, 3415, 3365, 3396, 3399, 3408, 3410, 3413, 3417, 3418, 3419, 3420, 3421, 3422, 3424, 3426, 3427, 3428, 3429, 3430, 3435, 3436, 3437, 3438, 3416, 3423, 3425, 3431, 3432, 3434, 3439, 3440, 3441, 3442, 3444, 3446, 3447, 3448, 3449, 3450, 3451, 3454, 3455, 3456, 3457, 3459, 3460, 3462, 3344, 3409, 3433, 3445, 3458, 3461, 3463, 3464, 3465, 3466, 3468, 3469, 3470, 3471, 3473, 3474, 3475, 3477, 3478, 3480, 3481, 3484, 3443, 3452, 3453, 3467, 3472, 3476, 3482, 3485, 3486, 3487, 3491, 3492, 3494, 3495, 3497, 3499, 3501, 3503, 3504, 3505, 3506, 3479, 3483, 3488, 3489, 3490, 3493, 3498, 3500, 3502, 3507, 3508, 3509, 3511, 3513, 3514, 3516, 3518, 3519, 3520, 3521, 3522, 3524, 3525, 3526, 3527, 3528, 3529, 3530, 3531, 3496, 3510, 3512, 3515, 3517, 3523, 3532, 3533, 3534, 3535, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3547, 3548, 3549, 3550, 3551, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3536, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3569, 3570, 3572, 3573, 3574, 3575, 3576, 3579, 3582, 3583, 3584, 3537, 3546, 3552, 3568, 3578, 3580, 3585, 3586, 3588, 3589, 3591, 3594, 3595, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3567, 3571, 3577, 3590, 3593, 3596, 3597, 3607, 3608, 3609, 3611, 3612, 3613, 3615, 3616, 3617, 3618, 3620, 3621, 3623, 3624, 3625, 3627, 3629, 3631, 3632, 3634, 3636, 3637, 3581, 3587, 3592, 3606, 3622, 3626, 3628, 3633, 3639, 3640, 3642, 3643, 3644, 3645, 3648, 3649, 3650, 3651, 3652, 3655, 3656, 3657, 3659, 3660, 3663, 3610, 3614, 3619, 3635, 3638, 3641, 3646, 3647, 3653, 3654, 3662, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3674, 3675, 3676, 3678, 3679, 3680, 3682, 3683, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3697, 3699, 3700, 3701, 3702, 3705, 3630, 3661, 3673, 3677, 3681, 3684, 3685, 3687, 3696, 3704, 3706, 3707, 3708, 3709, 3710, 3712, 3713, 3714, 3715, 3716, 3717, 3718, 3720, 3722, 3726, 3728, 3729, 3658, 3698, 3703, 3711, 3719, 3723, 3724, 3725, 3730, 3732, 3733, 3734, 3735, 3736, 3738, 3739, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3752, 3753, 3755, 3721, 3737, 3740, 3751, 3754, 3756, 3758, 3759, 3760, 3762, 3763, 3764, 3765, 3766, 3768, 3769, 3770, 3771, 3772, 3774, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3686, 3727, 3767, 3773, 3782, 3783, 3785, 3787, 3788, 3789, 3790, 3791, 3792, 3794, 3795, 3796, 3797, 3798, 3800, 3802, 3803, 3807, 3808, 3810, 3812, 3813, 3814, 3757, 3786, 3799, 3801, 3804, 3809, 3811, 3816, 3817, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3830, 3831, 3833, 3834, 3837, 3838, 3841, 3842, 3843, 3844, 3731, 3761, 3784, 3793, 3806, 3832, 3835, 3836, 3839, 3840, 3845, 3846, 3850, 3851, 3852, 3853, 3856, 3858, 3860, 3861, 3864, 3865, 3866, 3867, 3868, 3869, 3870, 3829, 3848, 3849, 3854, 3855, 3857, 3859, 3863, 3872, 3874, 3875, 3876, 3877, 3878, 3880, 3881, 3882, 3884, 3885, 3886, 3890, 3893, 3894, 3896, 3897, 3898, 3899, 3900, 3901, 3903, 3904, 3905, 3862, 3873, 3879, 3883, 3888, 3889, 3892, 3895, 3906, 3907, 3908, 3909, 3910, 3911, 3912, 3914, 3915, 3916, 3917, 3918, 3919, 3920, 3921, 3922, 3923, 3924, 3925, 3927, 3929, 3931, 3932, 3933, 3805, 3847, 3871, 3887, 3891, 3902, 3913, 3926, 3928, 3930, 3934, 3935, 3936, 3938, 3939, 3940, 3941, 3943, 3944, 3946, 3947, 3948, 3949, 3951, 3952, 3953, 3955, 3956, 3957, 3958, 3959, 3960, 3937, 3942, 3950, 3954, 3961, 3964, 3965, 3966, 3968, 3969, 3970, 3971, 3972, 3973, 3974, 3976, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3986, 3987, 3988, 3989, 3990, 3945, 3962, 3963, 3967, 3975, 3985, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999, 4001, 4002, 4003, 4004, 4005, 4006, 4011, 4012, 4013, 4015, 4016, 4017, 4018, 3815, 4007, 4008, 4009, 4014, 4019, 4021, 4022, 4023, 4024, 4025, 4026, 4028, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4038, 4040, 4041, 4042, 4044, 4045, 4046, 4048, 4049, 4050, 4052, 4054, 4010, 4020, 4029, 4037, 4039, 4047, 4051, 4053, 4055, 4056, 4058, 4059, 4061, 4062, 4064, 4065, 4066, 4068, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4078, 4080, 4083, 4084, 4086, 4087, 4088, 4090, 4092, 4093, 4000, 4027, 4057, 4060, 4067, 4069, 4077, 4079, 4082, 4089, 4091, 4094, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4107, 4109, 4110, 4111, 4112, 4113, 4115, 4116, 4117, 4118, 4119, 4122, 4123, 4124, 4125, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4063, 4081, 4095, 4106, 4108, 4114, 4120, 4121, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4159, 4160, 4161, 4162, 4164, 4165, 4166, 4167, 4169, 4170, 4171, 4085, 4127, 4158, 4172, 4173, 4175, 4176, 4177, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4196, 4197, 4199, 4200, 4201, 4202, 4203, 4204, 4207, 4208, 4209, 4210, 4211, 4213, 4157, 4163, 4168, 4174, 4178, 4195, 4198, 4214, 4215, 4216, 4218, 4219, 4220, 4221, 4222, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4239, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4043, 4206, 4212, 4217, 4223, 4237, 4238, 4248, 4249, 4250, 4251, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4260, 4261, 4262, 4263, 4264, 4265, 4266, 4267, 4268, 4270, 4272, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4283, 4126, 4205, 4252, 4271, 4273, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4298, 4300, 4301, 4302, 4304, 4305, 4306, 4308, 4310, 4311, 4312, 4313, 4296, 4297, 4307, 4309, 4314, 4317, 4319, 4320, 4321, 4322, 4323, 4324, 4325, 4326, 4330, 4331, 4332, 4333, 4334, 4335, 4337, 4338, 4341, 4343, 4344, 4345, 4346, 4348, 4349, 4350, 4351, 4353, 4354, 4355, 4269, 4315, 4316, 4318, 4327, 4328, 4329, 4336, 4342, 4347, 4357, 4359, 4360, 4362, 4363, 4364, 4365, 4366, 4367, 4369, 4371, 4372, 4373, 4374, 4375, 4376, 4377, 4378, 4379, 4380, 4381, 4382, 4383, 4384, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4401, 4402, 4240, 4284, 4299, 4339, 4340, 4352, 4356, 4358, 4361, 4370, 4400, 4403, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4413, 4414, 4415, 4416, 4417, 4418, 4421, 4422, 4424, 4425, 4426, 4428, 4429, 4430, 4431, 4432, 4434, 4435, 4303, 4385, 4404, 4412, 4420, 4423, 4427, 4433, 4436, 4438, 4440, 4442, 4443, 4444, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4460, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4437, 4439, 4441, 4445, 4459, 4461, 4470, 4471, 4472, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4458, 4473, 4482, 4504, 4505, 4506, 4507, 4509, 4510, 4511, 4512, 4513, 4514, 4515, 4518, 4520, 4521, 4522, 4523, 4524, 4525, 4526, 4527, 4528, 4529, 4531, 4533, 4535, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4368, 4517, 4519, 4530, 4532, 4534, 4544, 4545, 4547, 4548, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4576, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4419, 4508, 4516, 4543, 4575, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4601, 4603, 4605, 4606, 4607, 4608, 4609, 4610, 4613, 4614, 4615, 4616, 4617, 4619, 4620, 4621, 4622, 4623, 4624, 4625, 4626, 4627, 4628, 4629, 4630, 4631, 4632, 4546, 4602, 4611, 4612, 4618, 4633, 4634, 4635, 4637, 4638, 4639, 4640, 4641, 4642, 4643, 4644, 4646, 4648, 4649, 4650, 4651, 4653, 4655, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666, 4667, 4668, 4670, 4673, 4604, 4636, 4647, 4654, 4656, 4657, 4671, 4672, 4675, 4676, 4678, 4680, 4681, 4682, 4683, 4684, 4685, 4686, 4687, 4688, 4689, 4690, 4691, 4693, 4694, 4695, 4696, 4697, 4698, 4700, 4701, 4703, 4704, 4705, 4706, 4707, 4708, 4709, 4710, 4711, 4713, 4714, 4715, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4724, 4674, 4679, 4699, 4712, 4716, 4725, 4726, 4727, 4728, 4729, 4731, 4732, 4733, 4734, 4736, 4737, 4738, 4739, 4740, 4741, 4742, 4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4765, 4768, 4769, 4770, 4771, 4772, 4774, 4775, 4652, 4669, 4677, 4702, 4730, 4735, 4766, 4773, 4777, 4778, 4779, 4780, 4781, 4783, 4784, 4785, 4787, 4788, 4789, 4790, 4791, 4792, 4794, 4795, 4796, 4798, 4799, 4800, 4801, 4802, 4803, 4805, 4806, 4807, 4809, 4811, 4812, 4813, 4645, 4692, 4764, 4776, 4793, 4804, 4810, 4815, 4816, 4819, 4822, 4823, 4824, 4825, 4826, 4827, 4828, 4831, 4832, 4833, 4834, 4835, 4836, 4837, 4838, 4842, 4843, 4844, 4845, 4846, 4847, 4848, 4849, 4850, 4852, 4854, 4855, 4856, 4857, 4858, 4767, 4782, 4786, 4797, 4808, 4814, 4818, 4820, 4829, 4830, 4839, 4840, 4841, 4851, 4853, 4860, 4861, 4862, 4864, 4866, 4870, 4871, 4874, 4875, 4876, 4877, 4878, 4879, 4880, 4883, 4884, 4885, 4886, 4887, 4888, 4889, 4890, 4891, 4892, 4893, 4894, 4895, 4898, 4899, 4900, 4901, 4902, 4903, 4904, 4905, 4907, 4908, 4821, 4867, 4868, 4869, 4872, 4873, 4881, 4882, 4896, 4897, 4909, 4910, 4911, 4912, 4913, 4914, 4915, 4916, 4918, 4920, 4921, 4923, 4925, 4926, 4927, 4928, 4929, 4931, 4932, 4933, 4934, 4935, 4936, 4937, 4938, 4939, 4940, 4941, 4942, 4943, 4944, 4945, 4946, 4947, 4948, 4949, 4951, 4953, 4954, 4955, 4956, 4957, 4958, 4959, 4960, 4961, 4962, 4963, 4817, 4863, 4865, 4906, 4917, 4919, 4924, 4930, 4950, 4952, 4964, 4965, 4966, 4968, 4969, 4970, 4971, 4972, 4973, 4974, 4975, 4976, 4978, 4980, 4981, 4982, 4983, 4985, 4987, 4988, 4989, 4990, 4991, 4992, 4994, 4995, 4996, 4997, 4998, 4999, 4967, 4977, 4979, 4984, 4993, 4922, 4986, 4859, 4549, 4755]\n",
      "dict: \n",
      "CPU times: user 28min, sys: 1.11 s, total: 28min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_dict = build_dict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movi  :: 2\n",
      "film  :: 3\n",
      "one  :: 4\n",
      "like  :: 5\n",
      "time  :: 6\n",
      "good  :: 7\n",
      "make  :: 8\n",
      "charact  :: 9\n",
      "get  :: 10\n",
      "see  :: 11\n",
      "watch  :: 12\n",
      "stori  :: 13\n",
      "even  :: 14\n",
      "would  :: 15\n",
      "realli  :: 16\n",
      "well  :: 17\n",
      "scene  :: 18\n",
      "look  :: 19\n",
      "show  :: 20\n",
      "much  :: 21\n",
      "end  :: 22\n",
      "peopl  :: 23\n",
      "bad  :: 24\n",
      "go  :: 25\n",
      "great  :: 26\n",
      "also  :: 27\n",
      "first  :: 28\n",
      "love  :: 29\n",
      "think  :: 30\n",
      "way  :: 31\n",
      "act  :: 32\n",
      "play  :: 33\n",
      "made  :: 34\n",
      "thing  :: 35\n",
      "could  :: 36\n",
      "know  :: 37\n",
      "say  :: 38\n",
      "seem  :: 39\n",
      "work  :: 40\n",
      "plot  :: 41\n",
      "two  :: 42\n",
      "actor  :: 43\n",
      "year  :: 44\n",
      "come  :: 45\n",
      "mani  :: 46\n",
      "seen  :: 47\n",
      "take  :: 48\n",
      "life  :: 49\n",
      "want  :: 50\n",
      "never  :: 51\n",
      "littl  :: 52\n",
      "best  :: 53\n",
      "tri  :: 54\n",
      "man  :: 55\n",
      "ever  :: 56\n",
      "give  :: 57\n",
      "better  :: 58\n",
      "still  :: 59\n",
      "perform  :: 60\n",
      "find  :: 61\n",
      "feel  :: 62\n",
      "part  :: 63\n",
      "back  :: 64\n",
      "use  :: 65\n",
      "someth  :: 66\n",
      "director  :: 67\n",
      "actual  :: 68\n",
      "interest  :: 69\n",
      "lot  :: 70\n",
      "real  :: 71\n",
      "old  :: 72\n",
      "cast  :: 73\n",
      "though  :: 74\n",
      "live  :: 75\n",
      "star  :: 76\n",
      "enjoy  :: 77\n",
      "guy  :: 78\n",
      "anoth  :: 79\n",
      "new  :: 80\n",
      "role  :: 81\n",
      "noth  :: 82\n",
      "10  :: 83\n",
      "funni  :: 84\n",
      "music  :: 85\n",
      "point  :: 86\n",
      "start  :: 87\n",
      "set  :: 88\n",
      "girl  :: 89\n",
      "origin  :: 90\n",
      "day  :: 91\n",
      "world  :: 92\n",
      "everi  :: 93\n",
      "believ  :: 94\n",
      "turn  :: 95\n",
      "quit  :: 96\n",
      "us  :: 97\n",
      "direct  :: 98\n",
      "thought  :: 99\n",
      "fact  :: 100\n",
      "minut  :: 101\n",
      "horror  :: 102\n",
      "kill  :: 103\n",
      "action  :: 104\n",
      "comedi  :: 105\n",
      "pretti  :: 106\n",
      "young  :: 107\n",
      "wonder  :: 108\n",
      "happen  :: 109\n",
      "around  :: 110\n",
      "got  :: 111\n",
      "effect  :: 112\n",
      "right  :: 113\n",
      "long  :: 114\n",
      "howev  :: 115\n",
      "big  :: 116\n",
      "line  :: 117\n",
      "famili  :: 118\n",
      "enough  :: 119\n",
      "seri  :: 120\n",
      "may  :: 121\n",
      "need  :: 122\n",
      "fan  :: 123\n",
      "bit  :: 124\n",
      "script  :: 125\n",
      "beauti  :: 126\n",
      "person  :: 127\n",
      "becom  :: 128\n",
      "without  :: 129\n",
      "must  :: 130\n",
      "alway  :: 131\n",
      "friend  :: 132\n",
      "tell  :: 133\n",
      "reason  :: 134\n",
      "saw  :: 135\n",
      "last  :: 136\n",
      "final  :: 137\n",
      "kid  :: 138\n",
      "almost  :: 139\n",
      "put  :: 140\n",
      "least  :: 141\n",
      "sure  :: 142\n",
      "done  :: 143\n",
      "whole  :: 144\n",
      "place  :: 145\n",
      "complet  :: 146\n",
      "kind  :: 147\n",
      "differ  :: 148\n",
      "expect  :: 149\n",
      "shot  :: 150\n",
      "far  :: 151\n",
      "mean  :: 152\n",
      "anyth  :: 153\n",
      "book  :: 154\n",
      "laugh  :: 155\n",
      "might  :: 156\n",
      "name  :: 157\n",
      "sinc  :: 158\n",
      "begin  :: 159\n",
      "2  :: 160\n",
      "probabl  :: 161\n",
      "woman  :: 162\n",
      "help  :: 163\n",
      "entertain  :: 164\n",
      "let  :: 165\n",
      "screen  :: 166\n",
      "call  :: 167\n",
      "tv  :: 168\n",
      "moment  :: 169\n",
      "away  :: 170\n",
      "read  :: 171\n",
      "yet  :: 172\n",
      "rather  :: 173\n",
      "worst  :: 174\n",
      "run  :: 175\n",
      "fun  :: 176\n",
      "lead  :: 177\n",
      "hard  :: 178\n",
      "audienc  :: 179\n",
      "idea  :: 180\n",
      "anyon  :: 181\n",
      "episod  :: 182\n",
      "american  :: 183\n",
      "found  :: 184\n",
      "appear  :: 185\n",
      "bore  :: 186\n",
      "especi  :: 187\n",
      "although  :: 188\n",
      "hope  :: 189\n",
      "keep  :: 190\n",
      "cours  :: 191\n",
      "anim  :: 192\n",
      "job  :: 193\n",
      "goe  :: 194\n",
      "move  :: 195\n",
      "sens  :: 196\n",
      "version  :: 197\n",
      "dvd  :: 198\n",
      "war  :: 199\n",
      "money  :: 200\n",
      "someon  :: 201\n",
      "mind  :: 202\n",
      "mayb  :: 203\n",
      "problem  :: 204\n",
      "true  :: 205\n",
      "hous  :: 206\n",
      "everyth  :: 207\n",
      "nice  :: 208\n",
      "second  :: 209\n",
      "rate  :: 210\n",
      "three  :: 211\n",
      "night  :: 212\n",
      "follow  :: 213\n",
      "face  :: 214\n",
      "recommend  :: 215\n",
      "product  :: 216\n",
      "main  :: 217\n",
      "worth  :: 218\n",
      "leav  :: 219\n",
      "human  :: 220\n",
      "special  :: 221\n",
      "excel  :: 222\n",
      "togeth  :: 223\n",
      "wast  :: 224\n",
      "everyon  :: 225\n",
      "sound  :: 226\n",
      "john  :: 227\n",
      "hand  :: 228\n",
      "1  :: 229\n",
      "father  :: 230\n",
      "later  :: 231\n",
      "eye  :: 232\n",
      "said  :: 233\n",
      "view  :: 234\n",
      "instead  :: 235\n",
      "review  :: 236\n",
      "boy  :: 237\n",
      "high  :: 238\n",
      "hour  :: 239\n",
      "miss  :: 240\n",
      "talk  :: 241\n",
      "classic  :: 242\n",
      "wife  :: 243\n",
      "understand  :: 244\n",
      "left  :: 245\n",
      "care  :: 246\n",
      "black  :: 247\n",
      "death  :: 248\n",
      "open  :: 249\n",
      "murder  :: 250\n",
      "write  :: 251\n",
      "half  :: 252\n",
      "head  :: 253\n",
      "rememb  :: 254\n",
      "chang  :: 255\n",
      "viewer  :: 256\n",
      "fight  :: 257\n",
      "gener  :: 258\n",
      "surpris  :: 259\n",
      "short  :: 260\n",
      "includ  :: 261\n",
      "die  :: 262\n",
      "fall  :: 263\n",
      "less  :: 264\n",
      "els  :: 265\n",
      "entir  :: 266\n",
      "piec  :: 267\n",
      "involv  :: 268\n",
      "pictur  :: 269\n",
      "simpli  :: 270\n",
      "top  :: 271\n",
      "home  :: 272\n",
      "power  :: 273\n",
      "total  :: 274\n",
      "usual  :: 275\n",
      "budget  :: 276\n",
      "attempt  :: 277\n",
      "suppos  :: 278\n",
      "releas  :: 279\n",
      "hollywood  :: 280\n",
      "terribl  :: 281\n",
      "song  :: 282\n",
      "men  :: 283\n",
      "possibl  :: 284\n",
      "featur  :: 285\n",
      "portray  :: 286\n",
      "disappoint  :: 287\n",
      "poor  :: 288\n",
      "3  :: 289\n",
      "coupl  :: 290\n",
      "camera  :: 291\n",
      "stupid  :: 292\n",
      "dead  :: 293\n",
      "wrong  :: 294\n",
      "produc  :: 295\n",
      "low  :: 296\n",
      "either  :: 297\n",
      "video  :: 298\n",
      "aw  :: 299\n",
      "definit  :: 300\n",
      "except  :: 301\n",
      "rest  :: 302\n",
      "given  :: 303\n",
      "absolut  :: 304\n",
      "women  :: 305\n",
      "lack  :: 306\n",
      "word  :: 307\n",
      "writer  :: 308\n",
      "titl  :: 309\n",
      "talent  :: 310\n",
      "decid  :: 311\n",
      "full  :: 312\n",
      "perfect  :: 313\n",
      "along  :: 314\n",
      "style  :: 315\n",
      "close  :: 316\n",
      "truli  :: 317\n",
      "school  :: 318\n",
      "save  :: 319\n",
      "emot  :: 320\n",
      "age  :: 321\n",
      "sex  :: 322\n",
      "next  :: 323\n",
      "bring  :: 324\n",
      "mr  :: 325\n",
      "case  :: 326\n",
      "killer  :: 327\n",
      "heart  :: 328\n",
      "comment  :: 329\n",
      "sort  :: 330\n",
      "creat  :: 331\n",
      "perhap  :: 332\n",
      "came  :: 333\n",
      "brother  :: 334\n",
      "sever  :: 335\n",
      "joke  :: 336\n",
      "art  :: 337\n",
      "dialogu  :: 338\n",
      "game  :: 339\n",
      "small  :: 340\n",
      "base  :: 341\n",
      "flick  :: 342\n",
      "written  :: 343\n",
      "sequenc  :: 344\n",
      "meet  :: 345\n",
      "earli  :: 346\n",
      "often  :: 347\n",
      "other  :: 348\n",
      "mother  :: 349\n",
      "develop  :: 350\n",
      "humor  :: 351\n",
      "actress  :: 352\n",
      "consid  :: 353\n",
      "dark  :: 354\n",
      "guess  :: 355\n",
      "amaz  :: 356\n",
      "unfortun  :: 357\n",
      "light  :: 358\n",
      "lost  :: 359\n",
      "exampl  :: 360\n",
      "cinema  :: 361\n",
      "drama  :: 362\n",
      "ye  :: 363\n",
      "white  :: 364\n",
      "experi  :: 365\n",
      "imagin  :: 366\n",
      "mention  :: 367\n",
      "stop  :: 368\n",
      "natur  :: 369\n",
      "forc  :: 370\n",
      "manag  :: 371\n",
      "felt  :: 372\n",
      "cut  :: 373\n",
      "present  :: 374\n",
      "children  :: 375\n",
      "fail  :: 376\n",
      "son  :: 377\n",
      "car  :: 378\n",
      "qualiti  :: 379\n",
      "support  :: 380\n",
      "ask  :: 381\n",
      "hit  :: 382\n",
      "side  :: 383\n",
      "voic  :: 384\n",
      "extrem  :: 385\n",
      "impress  :: 386\n",
      "wors  :: 387\n",
      "evil  :: 388\n",
      "stand  :: 389\n",
      "went  :: 390\n",
      "certainli  :: 391\n",
      "basic  :: 392\n",
      "oh  :: 393\n",
      "overal  :: 394\n",
      "favorit  :: 395\n",
      "horribl  :: 396\n",
      "mysteri  :: 397\n",
      "number  :: 398\n",
      "type  :: 399\n",
      "danc  :: 400\n",
      "wait  :: 401\n",
      "hero  :: 402\n",
      "5  :: 403\n",
      "alreadi  :: 404\n",
      "learn  :: 405\n",
      "matter  :: 406\n",
      "4  :: 407\n",
      "michael  :: 408\n",
      "genr  :: 409\n",
      "fine  :: 410\n",
      "despit  :: 411\n",
      "throughout  :: 412\n",
      "walk  :: 413\n",
      "success  :: 414\n",
      "histori  :: 415\n",
      "question  :: 416\n",
      "zombi  :: 417\n",
      "town  :: 418\n",
      "relationship  :: 419\n",
      "realiz  :: 420\n",
      "child  :: 421\n",
      "past  :: 422\n",
      "daughter  :: 423\n",
      "late  :: 424\n",
      "b  :: 425\n",
      "wish  :: 426\n",
      "hate  :: 427\n",
      "credit  :: 428\n",
      "event  :: 429\n",
      "theme  :: 430\n",
      "touch  :: 431\n",
      "citi  :: 432\n",
      "today  :: 433\n",
      "sometim  :: 434\n",
      "behind  :: 435\n",
      "god  :: 436\n",
      "twist  :: 437\n",
      "sit  :: 438\n",
      "stay  :: 439\n",
      "annoy  :: 440\n",
      "deal  :: 441\n",
      "abl  :: 442\n",
      "rent  :: 443\n",
      "pleas  :: 444\n",
      "edit  :: 445\n",
      "blood  :: 446\n",
      "deserv  :: 447\n",
      "anyway  :: 448\n",
      "comic  :: 449\n",
      "appar  :: 450\n",
      "soon  :: 451\n",
      "gave  :: 452\n",
      "etc  :: 453\n",
      "level  :: 454\n",
      "slow  :: 455\n",
      "chanc  :: 456\n",
      "score  :: 457\n",
      "bodi  :: 458\n",
      "brilliant  :: 459\n",
      "incred  :: 460\n",
      "figur  :: 461\n",
      "situat  :: 462\n",
      "self  :: 463\n",
      "major  :: 464\n",
      "stuff  :: 465\n",
      "decent  :: 466\n",
      "element  :: 467\n",
      "dream  :: 468\n",
      "return  :: 469\n",
      "obvious  :: 470\n",
      "continu  :: 471\n",
      "order  :: 472\n",
      "pace  :: 473\n",
      "ridicul  :: 474\n",
      "happi  :: 475\n",
      "add  :: 476\n",
      "highli  :: 477\n",
      "group  :: 478\n",
      "thank  :: 479\n",
      "ladi  :: 480\n",
      "novel  :: 481\n",
      "pain  :: 482\n",
      "speak  :: 483\n",
      "career  :: 484\n",
      "shoot  :: 485\n",
      "strang  :: 486\n",
      "heard  :: 487\n",
      "sad  :: 488\n",
      "polic  :: 489\n",
      "husband  :: 490\n",
      "import  :: 491\n",
      "break  :: 492\n",
      "took  :: 493\n",
      "strong  :: 494\n",
      "cannot  :: 495\n",
      "robert  :: 496\n",
      "predict  :: 497\n",
      "violenc  :: 498\n",
      "hilari  :: 499\n",
      "recent  :: 500\n",
      "countri  :: 501\n",
      "known  :: 502\n",
      "particularli  :: 503\n",
      "pick  :: 504\n",
      "documentari  :: 505\n",
      "season  :: 506\n",
      "critic  :: 507\n",
      "jame  :: 508\n",
      "compar  :: 509\n",
      "obviou  :: 510\n",
      "alon  :: 511\n",
      "told  :: 512\n",
      "state  :: 513\n",
      "rock  :: 514\n",
      "visual  :: 515\n",
      "offer  :: 516\n",
      "theater  :: 517\n",
      "exist  :: 518\n",
      "opinion  :: 519\n",
      "gore  :: 520\n",
      "crap  :: 521\n",
      "hold  :: 522\n",
      "result  :: 523\n",
      "room  :: 524\n",
      "realiti  :: 525\n",
      "hear  :: 526\n",
      "effort  :: 527\n",
      "clich  :: 528\n",
      "thriller  :: 529\n",
      "caus  :: 530\n",
      "explain  :: 531\n",
      "serious  :: 532\n",
      "sequel  :: 533\n",
      "king  :: 534\n",
      "local  :: 535\n",
      "ago  :: 536\n",
      "none  :: 537\n",
      "hell  :: 538\n",
      "note  :: 539\n",
      "allow  :: 540\n",
      "david  :: 541\n",
      "sister  :: 542\n",
      "simpl  :: 543\n",
      "femal  :: 544\n",
      "deliv  :: 545\n",
      "ok  :: 546\n",
      "convinc  :: 547\n",
      "class  :: 548\n",
      "check  :: 549\n",
      "suspens  :: 550\n",
      "win  :: 551\n",
      "oscar  :: 552\n",
      "buy  :: 553\n",
      "huge  :: 554\n",
      "valu  :: 555\n",
      "sexual  :: 556\n",
      "scari  :: 557\n",
      "cool  :: 558\n",
      "excit  :: 559\n",
      "similar  :: 560\n",
      "exactli  :: 561\n",
      "provid  :: 562\n",
      "apart  :: 563\n",
      "avoid  :: 564\n",
      "shown  :: 565\n",
      "seriou  :: 566\n",
      "english  :: 567\n",
      "whose  :: 568\n",
      "taken  :: 569\n",
      "cinematographi  :: 570\n",
      "shock  :: 571\n",
      "polit  :: 572\n",
      "spoiler  :: 573\n",
      "offic  :: 574\n",
      "across  :: 575\n",
      "middl  :: 576\n",
      "street  :: 577\n",
      "pass  :: 578\n",
      "messag  :: 579\n",
      "somewhat  :: 580\n",
      "silli  :: 581\n",
      "charm  :: 582\n",
      "modern  :: 583\n",
      "confus  :: 584\n",
      "filmmak  :: 585\n",
      "form  :: 586\n",
      "tale  :: 587\n",
      "singl  :: 588\n",
      "jack  :: 589\n",
      "mostli  :: 590\n",
      "attent  :: 591\n",
      "william  :: 592\n",
      "carri  :: 593\n",
      "sing  :: 594\n",
      "subject  :: 595\n",
      "five  :: 596\n",
      "richard  :: 597\n",
      "prove  :: 598\n",
      "stage  :: 599\n",
      "team  :: 600\n",
      "cop  :: 601\n",
      "unlik  :: 602\n",
      "georg  :: 603\n",
      "monster  :: 604\n",
      "televis  :: 605\n",
      "earth  :: 606\n",
      "villain  :: 607\n",
      "cover  :: 608\n",
      "pay  :: 609\n",
      "marri  :: 610\n",
      "toward  :: 611\n",
      "build  :: 612\n",
      "pull  :: 613\n",
      "parent  :: 614\n",
      "due  :: 615\n",
      "fill  :: 616\n",
      "respect  :: 617\n",
      "dialog  :: 618\n",
      "four  :: 619\n",
      "remind  :: 620\n",
      "futur  :: 621\n",
      "weak  :: 622\n",
      "typic  :: 623\n",
      "7  :: 624\n",
      "cheap  :: 625\n",
      "intellig  :: 626\n",
      "atmospher  :: 627\n",
      "british  :: 628\n",
      "clearli  :: 629\n",
      "80  :: 630\n",
      "non  :: 631\n",
      "dog  :: 632\n",
      "paul  :: 633\n",
      "artist  :: 634\n",
      "knew  :: 635\n",
      "8  :: 636\n",
      "fast  :: 637\n",
      "crime  :: 638\n",
      "easili  :: 639\n",
      "escap  :: 640\n",
      "doubt  :: 641\n",
      "adult  :: 642\n",
      "detail  :: 643\n",
      "date  :: 644\n",
      "member  :: 645\n",
      "romant  :: 646\n",
      "fire  :: 647\n",
      "drive  :: 648\n",
      "gun  :: 649\n",
      "straight  :: 650\n",
      "beyond  :: 651\n",
      "fit  :: 652\n",
      "attack  :: 653\n",
      "imag  :: 654\n",
      "upon  :: 655\n",
      "posit  :: 656\n",
      "whether  :: 657\n",
      "peter  :: 658\n",
      "fantast  :: 659\n",
      "appreci  :: 660\n",
      "aspect  :: 661\n",
      "captur  :: 662\n",
      "ten  :: 663\n",
      "plan  :: 664\n",
      "discov  :: 665\n",
      "remain  :: 666\n",
      "period  :: 667\n",
      "near  :: 668\n",
      "air  :: 669\n",
      "realist  :: 670\n",
      "mark  :: 671\n",
      "red  :: 672\n",
      "dull  :: 673\n",
      "adapt  :: 674\n",
      "within  :: 675\n",
      "lose  :: 676\n",
      "spend  :: 677\n",
      "color  :: 678\n",
      "materi  :: 679\n",
      "chase  :: 680\n",
      "mari  :: 681\n",
      "storylin  :: 682\n",
      "forget  :: 683\n",
      "bunch  :: 684\n",
      "clear  :: 685\n",
      "lee  :: 686\n",
      "victim  :: 687\n",
      "nearli  :: 688\n",
      "box  :: 689\n",
      "york  :: 690\n",
      "match  :: 691\n",
      "inspir  :: 692\n",
      "mess  :: 693\n",
      "finish  :: 694\n",
      "standard  :: 695\n",
      "easi  :: 696\n",
      "truth  :: 697\n",
      "suffer  :: 698\n",
      "busi  :: 699\n",
      "bill  :: 700\n",
      "space  :: 701\n",
      "dramat  :: 702\n",
      "western  :: 703\n",
      "e  :: 704\n",
      "list  :: 705\n",
      "battl  :: 706\n",
      "notic  :: 707\n",
      "de  :: 708\n",
      "french  :: 709\n",
      "ad  :: 710\n",
      "9  :: 711\n",
      "tom  :: 712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "larg  :: 713\n",
      "among  :: 714\n",
      "eventu  :: 715\n",
      "accept  :: 716\n",
      "train  :: 717\n",
      "agre  :: 718\n",
      "spirit  :: 719\n",
      "soundtrack  :: 720\n",
      "third  :: 721\n",
      "teenag  :: 722\n",
      "soldier  :: 723\n",
      "adventur  :: 724\n",
      "sorri  :: 725\n",
      "famou  :: 726\n",
      "suggest  :: 727\n",
      "drug  :: 728\n",
      "normal  :: 729\n",
      "cri  :: 730\n",
      "babi  :: 731\n",
      "ultim  :: 732\n",
      "troubl  :: 733\n",
      "contain  :: 734\n",
      "certain  :: 735\n",
      "cultur  :: 736\n",
      "romanc  :: 737\n",
      "rare  :: 738\n",
      "lame  :: 739\n",
      "somehow  :: 740\n",
      "mix  :: 741\n",
      "disney  :: 742\n",
      "gone  :: 743\n",
      "cartoon  :: 744\n",
      "student  :: 745\n",
      "reveal  :: 746\n",
      "fear  :: 747\n",
      "suck  :: 748\n",
      "kept  :: 749\n",
      "attract  :: 750\n",
      "appeal  :: 751\n",
      "premis  :: 752\n",
      "secret  :: 753\n",
      "design  :: 754\n",
      "greatest  :: 755\n",
      "shame  :: 756\n",
      "throw  :: 757\n",
      "copi  :: 758\n",
      "scare  :: 759\n",
      "wit  :: 760\n",
      "america  :: 761\n",
      "admit  :: 762\n",
      "relat  :: 763\n",
      "particular  :: 764\n",
      "brought  :: 765\n",
      "screenplay  :: 766\n",
      "whatev  :: 767\n",
      "pure  :: 768\n",
      "70  :: 769\n",
      "harri  :: 770\n",
      "averag  :: 771\n",
      "master  :: 772\n",
      "describ  :: 773\n",
      "treat  :: 774\n",
      "male  :: 775\n",
      "20  :: 776\n",
      "issu  :: 777\n",
      "fantasi  :: 778\n",
      "warn  :: 779\n",
      "inde  :: 780\n",
      "forward  :: 781\n",
      "background  :: 782\n",
      "free  :: 783\n",
      "project  :: 784\n",
      "japanes  :: 785\n",
      "memor  :: 786\n",
      "poorli  :: 787\n",
      "award  :: 788\n",
      "locat  :: 789\n",
      "amus  :: 790\n",
      "potenti  :: 791\n",
      "struggl  :: 792\n",
      "weird  :: 793\n",
      "magic  :: 794\n",
      "societi  :: 795\n",
      "okay  :: 796\n",
      "doctor  :: 797\n",
      "accent  :: 798\n",
      "imdb  :: 799\n",
      "hot  :: 800\n",
      "water  :: 801\n",
      "30  :: 802\n",
      "express  :: 803\n",
      "dr  :: 804\n",
      "alien  :: 805\n",
      "odd  :: 806\n",
      "choic  :: 807\n",
      "crazi  :: 808\n",
      "studio  :: 809\n",
      "fiction  :: 810\n",
      "control  :: 811\n",
      "becam  :: 812\n",
      "masterpiec  :: 813\n",
      "difficult  :: 814\n",
      "fli  :: 815\n",
      "joe  :: 816\n",
      "scream  :: 817\n",
      "costum  :: 818\n",
      "lover  :: 819\n",
      "refer  :: 820\n",
      "uniqu  :: 821\n",
      "remak  :: 822\n",
      "girlfriend  :: 823\n",
      "vampir  :: 824\n",
      "prison  :: 825\n",
      "execut  :: 826\n",
      "wear  :: 827\n",
      "jump  :: 828\n",
      "wood  :: 829\n",
      "unless  :: 830\n",
      "creepi  :: 831\n",
      "cheesi  :: 832\n",
      "superb  :: 833\n",
      "otherwis  :: 834\n",
      "parti  :: 835\n",
      "ghost  :: 836\n",
      "roll  :: 837\n",
      "public  :: 838\n",
      "mad  :: 839\n",
      "depict  :: 840\n",
      "earlier  :: 841\n",
      "week  :: 842\n",
      "jane  :: 843\n",
      "moral  :: 844\n",
      "badli  :: 845\n",
      "fi  :: 846\n",
      "dumb  :: 847\n",
      "grow  :: 848\n",
      "flaw  :: 849\n",
      "sci  :: 850\n",
      "deep  :: 851\n",
      "cat  :: 852\n",
      "maker  :: 853\n",
      "connect  :: 854\n",
      "footag  :: 855\n",
      "older  :: 856\n",
      "plenti  :: 857\n",
      "bother  :: 858\n",
      "outsid  :: 859\n",
      "stick  :: 860\n",
      "gay  :: 861\n",
      "catch  :: 862\n",
      "plu  :: 863\n",
      "co  :: 864\n",
      "popular  :: 865\n",
      "equal  :: 866\n",
      "social  :: 867\n",
      "disturb  :: 868\n",
      "quickli  :: 869\n",
      "perfectli  :: 870\n",
      "dress  :: 871\n",
      "era  :: 872\n",
      "90  :: 873\n",
      "mistak  :: 874\n",
      "lie  :: 875\n",
      "previou  :: 876\n",
      "ride  :: 877\n",
      "combin  :: 878\n",
      "band  :: 879\n",
      "concept  :: 880\n",
      "rich  :: 881\n",
      "answer  :: 882\n",
      "surviv  :: 883\n",
      "front  :: 884\n",
      "christma  :: 885\n",
      "sweet  :: 886\n",
      "insid  :: 887\n",
      "concern  :: 888\n",
      "bare  :: 889\n",
      "eat  :: 890\n",
      "beat  :: 891\n",
      "ben  :: 892\n",
      "listen  :: 893\n",
      "c  :: 894\n",
      "serv  :: 895\n",
      "term  :: 896\n",
      "la  :: 897\n",
      "meant  :: 898\n",
      "german  :: 899\n",
      "stereotyp  :: 900\n",
      "hardli  :: 901\n",
      "innoc  :: 902\n",
      "law  :: 903\n",
      "desper  :: 904\n",
      "memori  :: 905\n",
      "promis  :: 906\n",
      "cute  :: 907\n",
      "intent  :: 908\n",
      "inform  :: 909\n",
      "variou  :: 910\n",
      "steal  :: 911\n",
      "brain  :: 912\n",
      "post  :: 913\n",
      "tone  :: 914\n",
      "island  :: 915\n",
      "amount  :: 916\n",
      "compani  :: 917\n",
      "nuditi  :: 918\n",
      "track  :: 919\n",
      "claim  :: 920\n",
      "store  :: 921\n",
      "50  :: 922\n",
      "flat  :: 923\n",
      "hair  :: 924\n",
      "univers  :: 925\n",
      "land  :: 926\n",
      "danger  :: 927\n",
      "fairli  :: 928\n",
      "scott  :: 929\n",
      "kick  :: 930\n",
      "player  :: 931\n",
      "plain  :: 932\n",
      "crew  :: 933\n",
      "step  :: 934\n",
      "toni  :: 935\n",
      "share  :: 936\n",
      "centuri  :: 937\n",
      "tast  :: 938\n",
      "achiev  :: 939\n",
      "engag  :: 940\n",
      "travel  :: 941\n",
      "cold  :: 942\n",
      "record  :: 943\n",
      "rip  :: 944\n",
      "suit  :: 945\n",
      "manner  :: 946\n",
      "sadli  :: 947\n",
      "tension  :: 948\n",
      "spot  :: 949\n",
      "wrote  :: 950\n",
      "fascin  :: 951\n",
      "intens  :: 952\n",
      "familiar  :: 953\n",
      "remark  :: 954\n",
      "depth  :: 955\n",
      "burn  :: 956\n",
      "histor  :: 957\n",
      "destroy  :: 958\n",
      "sleep  :: 959\n",
      "purpos  :: 960\n",
      "languag  :: 961\n",
      "ruin  :: 962\n",
      "ignor  :: 963\n",
      "delight  :: 964\n",
      "italian  :: 965\n",
      "unbeliev  :: 966\n",
      "collect  :: 967\n",
      "abil  :: 968\n",
      "soul  :: 969\n",
      "clever  :: 970\n",
      "detect  :: 971\n",
      "violent  :: 972\n",
      "rape  :: 973\n",
      "reach  :: 974\n",
      "door  :: 975\n",
      "liter  :: 976\n",
      "scienc  :: 977\n",
      "trash  :: 978\n",
      "reveng  :: 979\n",
      "caught  :: 980\n",
      "commun  :: 981\n",
      "creatur  :: 982\n",
      "trip  :: 983\n",
      "approach  :: 984\n",
      "intrigu  :: 985\n",
      "fashion  :: 986\n",
      "skill  :: 987\n",
      "paint  :: 988\n",
      "introduc  :: 989\n",
      "channel  :: 990\n",
      "complex  :: 991\n",
      "camp  :: 992\n",
      "christian  :: 993\n",
      "extra  :: 994\n",
      "hole  :: 995\n",
      "limit  :: 996\n",
      "immedi  :: 997\n",
      "ann  :: 998\n",
      "mental  :: 999\n",
      "6  :: 1000\n",
      "slightli  :: 1001\n",
      "comput  :: 1002\n",
      "million  :: 1003\n",
      "mere  :: 1004\n",
      "conclus  :: 1005\n",
      "slasher  :: 1006\n",
      "imposs  :: 1007\n",
      "suddenli  :: 1008\n",
      "crimin  :: 1009\n",
      "teen  :: 1010\n",
      "neither  :: 1011\n",
      "spent  :: 1012\n",
      "nation  :: 1013\n",
      "physic  :: 1014\n",
      "respons  :: 1015\n",
      "planet  :: 1016\n",
      "receiv  :: 1017\n",
      "fake  :: 1018\n",
      "blue  :: 1019\n",
      "sick  :: 1020\n",
      "bizarr  :: 1021\n",
      "embarrass  :: 1022\n",
      "indian  :: 1023\n",
      "15  :: 1024\n",
      "ring  :: 1025\n",
      "drop  :: 1026\n",
      "pop  :: 1027\n",
      "drag  :: 1028\n",
      "haunt  :: 1029\n",
      "pointless  :: 1030\n",
      "suspect  :: 1031\n",
      "search  :: 1032\n",
      "edg  :: 1033\n",
      "handl  :: 1034\n",
      "common  :: 1035\n",
      "biggest  :: 1036\n",
      "faith  :: 1037\n",
      "hurt  :: 1038\n",
      "arriv  :: 1039\n",
      "technic  :: 1040\n",
      "angel  :: 1041\n",
      "genuin  :: 1042\n",
      "dad  :: 1043\n",
      "solid  :: 1044\n",
      "awesom  :: 1045\n",
      "f  :: 1046\n",
      "focu  :: 1047\n",
      "colleg  :: 1048\n",
      "van  :: 1049\n",
      "former  :: 1050\n",
      "count  :: 1051\n",
      "heavi  :: 1052\n",
      "tear  :: 1053\n",
      "rais  :: 1054\n",
      "wall  :: 1055\n",
      "younger  :: 1056\n",
      "visit  :: 1057\n",
      "laughabl  :: 1058\n",
      "fair  :: 1059\n",
      "sign  :: 1060\n",
      "excus  :: 1061\n",
      "cult  :: 1062\n",
      "key  :: 1063\n",
      "motion  :: 1064\n",
      "tough  :: 1065\n",
      "super  :: 1066\n",
      "desir  :: 1067\n",
      "stun  :: 1068\n",
      "addit  :: 1069\n",
      "cloth  :: 1070\n",
      "exploit  :: 1071\n",
      "tortur  :: 1072\n",
      "smith  :: 1073\n",
      "race  :: 1074\n",
      "davi  :: 1075\n",
      "author  :: 1076\n",
      "cross  :: 1077\n",
      "jim  :: 1078\n",
      "consist  :: 1079\n",
      "compel  :: 1080\n",
      "focus  :: 1081\n",
      "minor  :: 1082\n",
      "pathet  :: 1083\n",
      "commit  :: 1084\n",
      "chemistri  :: 1085\n",
      "park  :: 1086\n",
      "frank  :: 1087\n",
      "tradit  :: 1088\n",
      "obsess  :: 1089\n",
      "grade  :: 1090\n",
      "asid  :: 1091\n",
      "60  :: 1092\n",
      "brutal  :: 1093\n",
      "steve  :: 1094\n",
      "somewher  :: 1095\n",
      "rule  :: 1096\n",
      "explor  :: 1097\n",
      "u  :: 1098\n",
      "grant  :: 1099\n",
      "opportun  :: 1100\n",
      "depress  :: 1101\n",
      "besid  :: 1102\n",
      "honest  :: 1103\n",
      "anti  :: 1104\n",
      "dub  :: 1105\n",
      "trailer  :: 1106\n",
      "intend  :: 1107\n",
      "bar  :: 1108\n",
      "longer  :: 1109\n",
      "scientist  :: 1110\n",
      "west  :: 1111\n",
      "regard  :: 1112\n",
      "judg  :: 1113\n",
      "decad  :: 1114\n",
      "silent  :: 1115\n",
      "armi  :: 1116\n",
      "creativ  :: 1117\n",
      "wild  :: 1118\n",
      "south  :: 1119\n",
      "stewart  :: 1120\n",
      "g  :: 1121\n",
      "draw  :: 1122\n",
      "road  :: 1123\n",
      "govern  :: 1124\n",
      "boss  :: 1125\n",
      "ex  :: 1126\n",
      "practic  :: 1127\n",
      "gang  :: 1128\n",
      "motiv  :: 1129\n",
      "surprisingli  :: 1130\n",
      "festiv  :: 1131\n",
      "club  :: 1132\n",
      "london  :: 1133\n",
      "redeem  :: 1134\n",
      "page  :: 1135\n",
      "green  :: 1136\n",
      "militari  :: 1137\n",
      "aliv  :: 1138\n",
      "machin  :: 1139\n",
      "display  :: 1140\n",
      "idiot  :: 1141\n",
      "repeat  :: 1142\n",
      "thrill  :: 1143\n",
      "yeah  :: 1144\n",
      "nobodi  :: 1145\n",
      "folk  :: 1146\n",
      "100  :: 1147\n",
      "40  :: 1148\n",
      "journey  :: 1149\n",
      "garbag  :: 1150\n",
      "smile  :: 1151\n",
      "tire  :: 1152\n",
      "ground  :: 1153\n",
      "mood  :: 1154\n",
      "bought  :: 1155\n",
      "cost  :: 1156\n",
      "sam  :: 1157\n",
      "stone  :: 1158\n",
      "noir  :: 1159\n",
      "mouth  :: 1160\n",
      "agent  :: 1161\n",
      "terrif  :: 1162\n",
      "requir  :: 1163\n",
      "utterli  :: 1164\n",
      "sexi  :: 1165\n",
      "area  :: 1166\n",
      "honestli  :: 1167\n",
      "geniu  :: 1168\n",
      "report  :: 1169\n",
      "humour  :: 1170\n",
      "glad  :: 1171\n",
      "investig  :: 1172\n",
      "enter  :: 1173\n",
      "serial  :: 1174\n",
      "passion  :: 1175\n",
      "occasion  :: 1176\n",
      "narr  :: 1177\n",
      "climax  :: 1178\n",
      "marriag  :: 1179\n",
      "studi  :: 1180\n",
      "industri  :: 1181\n",
      "charli  :: 1182\n",
      "ship  :: 1183\n",
      "nowher  :: 1184\n",
      "demon  :: 1185\n",
      "center  :: 1186\n",
      "hors  :: 1187\n",
      "bear  :: 1188\n",
      "loos  :: 1189\n",
      "hang  :: 1190\n",
      "wow  :: 1191\n",
      "graphic  :: 1192\n",
      "giant  :: 1193\n",
      "admir  :: 1194\n",
      "send  :: 1195\n",
      "damn  :: 1196\n",
      "loud  :: 1197\n",
      "nake  :: 1198\n",
      "subtl  :: 1199\n",
      "rel  :: 1200\n",
      "profession  :: 1201\n",
      "blow  :: 1202\n",
      "bottom  :: 1203\n",
      "insult  :: 1204\n",
      "batman  :: 1205\n",
      "kelli  :: 1206\n",
      "doubl  :: 1207\n",
      "boyfriend  :: 1208\n",
      "r  :: 1209\n",
      "initi  :: 1210\n",
      "frame  :: 1211\n",
      "gem  :: 1212\n",
      "opera  :: 1213\n",
      "challeng  :: 1214\n",
      "drawn  :: 1215\n",
      "cinemat  :: 1216\n",
      "affect  :: 1217\n",
      "church  :: 1218\n",
      "l  :: 1219\n",
      "nightmar  :: 1220\n",
      "evid  :: 1221\n",
      "fulli  :: 1222\n",
      "j  :: 1223\n",
      "seek  :: 1224\n",
      "conflict  :: 1225\n",
      "essenti  :: 1226\n",
      "arm  :: 1227\n",
      "grace  :: 1228\n",
      "christoph  :: 1229\n",
      "wind  :: 1230\n",
      "henri  :: 1231\n",
      "narrat  :: 1232\n",
      "witch  :: 1233\n",
      "assum  :: 1234\n",
      "push  :: 1235\n",
      "hunt  :: 1236\n",
      "wise  :: 1237\n",
      "chri  :: 1238\n",
      "month  :: 1239\n",
      "nomin  :: 1240\n",
      "repres  :: 1241\n",
      "affair  :: 1242\n",
      "avail  :: 1243\n",
      "sceneri  :: 1244\n",
      "hide  :: 1245\n",
      "bond  :: 1246\n",
      "smart  :: 1247\n",
      "justic  :: 1248\n",
      "thu  :: 1249\n",
      "flashback  :: 1250\n",
      "outstand  :: 1251\n",
      "interview  :: 1252\n",
      "presenc  :: 1253\n",
      "constantli  :: 1254\n",
      "satisfi  :: 1255\n",
      "bed  :: 1256\n",
      "central  :: 1257\n",
      "content  :: 1258\n",
      "iron  :: 1259\n",
      "sell  :: 1260\n",
      "everybodi  :: 1261\n",
      "gag  :: 1262\n",
      "hotel  :: 1263\n",
      "slowli  :: 1264\n",
      "hire  :: 1265\n",
      "system  :: 1266\n",
      "charl  :: 1267\n",
      "individu  :: 1268\n",
      "hey  :: 1269\n",
      "adam  :: 1270\n",
      "thrown  :: 1271\n",
      "mediocr  :: 1272\n",
      "allen  :: 1273\n",
      "jone  :: 1274\n",
      "lesson  :: 1275\n",
      "ray  :: 1276\n",
      "billi  :: 1277\n",
      "cameo  :: 1278\n",
      "photographi  :: 1279\n",
      "pari  :: 1280\n",
      "fellow  :: 1281\n",
      "strike  :: 1282\n",
      "brief  :: 1283\n",
      "rise  :: 1284\n",
      "independ  :: 1285\n",
      "absurd  :: 1286\n",
      "neg  :: 1287\n",
      "phone  :: 1288\n",
      "impact  :: 1289\n",
      "model  :: 1290\n",
      "ill  :: 1291\n",
      "born  :: 1292\n",
      "spoil  :: 1293\n",
      "fresh  :: 1294\n",
      "angl  :: 1295\n",
      "likabl  :: 1296\n",
      "abus  :: 1297\n",
      "discuss  :: 1298\n",
      "hill  :: 1299\n",
      "sight  :: 1300\n",
      "ahead  :: 1301\n",
      "sent  :: 1302\n",
      "photograph  :: 1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occur  :: 1304\n",
      "blame  :: 1305\n",
      "shine  :: 1306\n",
      "logic  :: 1307\n",
      "bruce  :: 1308\n",
      "mainli  :: 1309\n",
      "commerci  :: 1310\n",
      "forev  :: 1311\n",
      "skip  :: 1312\n",
      "segment  :: 1313\n",
      "surround  :: 1314\n",
      "teacher  :: 1315\n",
      "held  :: 1316\n",
      "blond  :: 1317\n",
      "zero  :: 1318\n",
      "trap  :: 1319\n",
      "summer  :: 1320\n",
      "resembl  :: 1321\n",
      "satir  :: 1322\n",
      "six  :: 1323\n",
      "ball  :: 1324\n",
      "fool  :: 1325\n",
      "queen  :: 1326\n",
      "sub  :: 1327\n",
      "twice  :: 1328\n",
      "tragedi  :: 1329\n",
      "reaction  :: 1330\n",
      "pack  :: 1331\n",
      "bomb  :: 1332\n",
      "will  :: 1333\n",
      "protagonist  :: 1334\n",
      "hospit  :: 1335\n",
      "mile  :: 1336\n",
      "sport  :: 1337\n",
      "vote  :: 1338\n",
      "drink  :: 1339\n",
      "jerri  :: 1340\n",
      "trust  :: 1341\n",
      "mom  :: 1342\n",
      "encount  :: 1343\n",
      "plane  :: 1344\n",
      "program  :: 1345\n",
      "current  :: 1346\n",
      "station  :: 1347\n",
      "al  :: 1348\n",
      "martin  :: 1349\n",
      "choos  :: 1350\n",
      "celebr  :: 1351\n",
      "join  :: 1352\n",
      "favourit  :: 1353\n",
      "tragic  :: 1354\n",
      "lord  :: 1355\n",
      "round  :: 1356\n",
      "field  :: 1357\n",
      "jean  :: 1358\n",
      "vision  :: 1359\n",
      "robot  :: 1360\n",
      "arthur  :: 1361\n",
      "tie  :: 1362\n",
      "roger  :: 1363\n",
      "random  :: 1364\n",
      "fortun  :: 1365\n",
      "intern  :: 1366\n",
      "dread  :: 1367\n",
      "psycholog  :: 1368\n",
      "epic  :: 1369\n",
      "improv  :: 1370\n",
      "nonsens  :: 1371\n",
      "prefer  :: 1372\n",
      "legend  :: 1373\n",
      "pleasur  :: 1374\n",
      "formula  :: 1375\n",
      "highlight  :: 1376\n",
      "11  :: 1377\n",
      "tape  :: 1378\n",
      "dollar  :: 1379\n",
      "wide  :: 1380\n",
      "object  :: 1381\n",
      "thin  :: 1382\n",
      "gorgeou  :: 1383\n",
      "fox  :: 1384\n",
      "porn  :: 1385\n",
      "buddi  :: 1386\n",
      "influenc  :: 1387\n",
      "ugli  :: 1388\n",
      "ii  :: 1389\n",
      "prepar  :: 1390\n",
      "nasti  :: 1391\n",
      "supposedli  :: 1392\n",
      "reflect  :: 1393\n",
      "progress  :: 1394\n",
      "warm  :: 1395\n",
      "youth  :: 1396\n",
      "worthi  :: 1397\n",
      "unusu  :: 1398\n",
      "latter  :: 1399\n",
      "length  :: 1400\n",
      "crash  :: 1401\n",
      "superior  :: 1402\n",
      "shop  :: 1403\n",
      "seven  :: 1404\n",
      "childhood  :: 1405\n",
      "theatr  :: 1406\n",
      "remot  :: 1407\n",
      "pilot  :: 1408\n",
      "disgust  :: 1409\n",
      "paid  :: 1410\n",
      "funniest  :: 1411\n",
      "convers  :: 1412\n",
      "fell  :: 1413\n",
      "castl  :: 1414\n",
      "trick  :: 1415\n",
      "rob  :: 1416\n",
      "establish  :: 1417\n",
      "gangster  :: 1418\n",
      "disast  :: 1419\n",
      "ident  :: 1420\n",
      "mine  :: 1421\n",
      "disappear  :: 1422\n",
      "suicid  :: 1423\n",
      "heaven  :: 1424\n",
      "singer  :: 1425\n",
      "tend  :: 1426\n",
      "mask  :: 1427\n",
      "heroin  :: 1428\n",
      "forgotten  :: 1429\n",
      "decis  :: 1430\n",
      "brian  :: 1431\n",
      "partner  :: 1432\n",
      "alan  :: 1433\n",
      "recogn  :: 1434\n",
      "desert  :: 1435\n",
      "ms  :: 1436\n",
      "p  :: 1437\n",
      "thoroughli  :: 1438\n",
      "sky  :: 1439\n",
      "stuck  :: 1440\n",
      "replac  :: 1441\n",
      "accur  :: 1442\n",
      "market  :: 1443\n",
      "uncl  :: 1444\n",
      "andi  :: 1445\n",
      "clue  :: 1446\n",
      "eddi  :: 1447\n",
      "commentari  :: 1448\n",
      "danni  :: 1449\n",
      "seemingli  :: 1450\n",
      "jackson  :: 1451\n",
      "devil  :: 1452\n",
      "that  :: 1453\n",
      "refus  :: 1454\n",
      "pair  :: 1455\n",
      "therefor  :: 1456\n",
      "ed  :: 1457\n",
      "fault  :: 1458\n",
      "river  :: 1459\n",
      "fate  :: 1460\n",
      "unit  :: 1461\n",
      "accid  :: 1462\n",
      "afraid  :: 1463\n",
      "tune  :: 1464\n",
      "clean  :: 1465\n",
      "stephen  :: 1466\n",
      "hidden  :: 1467\n",
      "russian  :: 1468\n",
      "captain  :: 1469\n",
      "irrit  :: 1470\n",
      "readi  :: 1471\n",
      "instanc  :: 1472\n",
      "quick  :: 1473\n",
      "test  :: 1474\n",
      "convey  :: 1475\n",
      "european  :: 1476\n",
      "frustrat  :: 1477\n",
      "insan  :: 1478\n",
      "daniel  :: 1479\n",
      "wed  :: 1480\n",
      "food  :: 1481\n",
      "chines  :: 1482\n",
      "1950  :: 1483\n",
      "rescu  :: 1484\n",
      "dirti  :: 1485\n",
      "lock  :: 1486\n",
      "angri  :: 1487\n",
      "joy  :: 1488\n",
      "steven  :: 1489\n",
      "price  :: 1490\n",
      "cage  :: 1491\n",
      "bland  :: 1492\n",
      "anymor  :: 1493\n",
      "rang  :: 1494\n",
      "wooden  :: 1495\n",
      "jason  :: 1496\n",
      "n  :: 1497\n",
      "rush  :: 1498\n",
      "news  :: 1499\n",
      "board  :: 1500\n",
      "12  :: 1501\n",
      "martial  :: 1502\n",
      "worri  :: 1503\n",
      "twenti  :: 1504\n",
      "led  :: 1505\n",
      "transform  :: 1506\n",
      "hunter  :: 1507\n",
      "cgi  :: 1508\n",
      "symbol  :: 1509\n",
      "sentiment  :: 1510\n",
      "johnni  :: 1511\n",
      "x  :: 1512\n",
      "onto  :: 1513\n",
      "piti  :: 1514\n",
      "invent  :: 1515\n",
      "explan  :: 1516\n",
      "process  :: 1517\n",
      "attitud  :: 1518\n",
      "owner  :: 1519\n",
      "awar  :: 1520\n",
      "aim  :: 1521\n",
      "favor  :: 1522\n",
      "energi  :: 1523\n",
      "floor  :: 1524\n",
      "necessari  :: 1525\n",
      "target  :: 1526\n",
      "opposit  :: 1527\n",
      "religi  :: 1528\n",
      "chick  :: 1529\n",
      "window  :: 1530\n",
      "insight  :: 1531\n",
      "blind  :: 1532\n",
      "movement  :: 1533\n",
      "possess  :: 1534\n",
      "deepli  :: 1535\n",
      "comparison  :: 1536\n",
      "research  :: 1537\n",
      "mountain  :: 1538\n",
      "grand  :: 1539\n",
      "comed  :: 1540\n",
      "rain  :: 1541\n",
      "whatsoev  :: 1542\n",
      "shadow  :: 1543\n",
      "bank  :: 1544\n",
      "mid  :: 1545\n",
      "began  :: 1546\n",
      "princ  :: 1547\n",
      "parodi  :: 1548\n",
      "credibl  :: 1549\n",
      "weapon  :: 1550\n",
      "taylor  :: 1551\n",
      "friendship  :: 1552\n",
      "pre  :: 1553\n",
      "teach  :: 1554\n",
      "dougla  :: 1555\n",
      "flesh  :: 1556\n",
      "bloodi  :: 1557\n",
      "hint  :: 1558\n",
      "protect  :: 1559\n",
      "terror  :: 1560\n",
      "marvel  :: 1561\n",
      "anybodi  :: 1562\n",
      "load  :: 1563\n",
      "watchabl  :: 1564\n",
      "leader  :: 1565\n",
      "drunk  :: 1566\n",
      "accord  :: 1567\n",
      "superman  :: 1568\n",
      "brown  :: 1569\n",
      "freddi  :: 1570\n",
      "appropri  :: 1571\n",
      "tim  :: 1572\n",
      "jeff  :: 1573\n",
      "hitler  :: 1574\n",
      "seat  :: 1575\n",
      "keaton  :: 1576\n",
      "unknown  :: 1577\n",
      "knock  :: 1578\n",
      "villag  :: 1579\n",
      "charg  :: 1580\n",
      "england  :: 1581\n",
      "unnecessari  :: 1582\n",
      "enemi  :: 1583\n",
      "empti  :: 1584\n",
      "media  :: 1585\n",
      "utter  :: 1586\n",
      "perspect  :: 1587\n",
      "wave  :: 1588\n",
      "strength  :: 1589\n",
      "buck  :: 1590\n",
      "dare  :: 1591\n",
      "craft  :: 1592\n",
      "contrast  :: 1593\n",
      "nativ  :: 1594\n",
      "correct  :: 1595\n",
      "kiss  :: 1596\n",
      "ford  :: 1597\n",
      "magnific  :: 1598\n",
      "soap  :: 1599\n",
      "chill  :: 1600\n",
      "speed  :: 1601\n",
      "anywher  :: 1602\n",
      "distract  :: 1603\n",
      "knowledg  :: 1604\n",
      "nazi  :: 1605\n",
      "ice  :: 1606\n",
      "fred  :: 1607\n",
      "mission  :: 1608\n",
      "1980  :: 1609\n",
      "breath  :: 1610\n",
      "moon  :: 1611\n",
      "crowd  :: 1612\n",
      "jr  :: 1613\n",
      "joan  :: 1614\n",
      "soft  :: 1615\n",
      "000  :: 1616\n",
      "frighten  :: 1617\n",
      "kate  :: 1618\n",
      "dick  :: 1619\n",
      "dan  :: 1620\n",
      "hundr  :: 1621\n",
      "nick  :: 1622\n",
      "somebodi  :: 1623\n",
      "dozen  :: 1624\n",
      "simon  :: 1625\n",
      "radio  :: 1626\n",
      "thousand  :: 1627\n",
      "shakespear  :: 1628\n",
      "loss  :: 1629\n",
      "andrew  :: 1630\n",
      "academi  :: 1631\n",
      "vehicl  :: 1632\n",
      "sum  :: 1633\n",
      "account  :: 1634\n",
      "quot  :: 1635\n",
      "root  :: 1636\n",
      "convent  :: 1637\n",
      "leg  :: 1638\n",
      "1970  :: 1639\n",
      "behavior  :: 1640\n",
      "regular  :: 1641\n",
      "gold  :: 1642\n",
      "pretenti  :: 1643\n",
      "demand  :: 1644\n",
      "compet  :: 1645\n",
      "worker  :: 1646\n",
      "japan  :: 1647\n",
      "notabl  :: 1648\n",
      "interpret  :: 1649\n",
      "lynch  :: 1650\n",
      "stretch  :: 1651\n",
      "explos  :: 1652\n",
      "candi  :: 1653\n",
      "privat  :: 1654\n",
      "debut  :: 1655\n",
      "constant  :: 1656\n",
      "tarzan  :: 1657\n",
      "prais  :: 1658\n",
      "spi  :: 1659\n",
      "translat  :: 1660\n",
      "sea  :: 1661\n",
      "revolv  :: 1662\n",
      "quiet  :: 1663\n",
      "failur  :: 1664\n",
      "franc  :: 1665\n",
      "ass  :: 1666\n",
      "threaten  :: 1667\n",
      "sat  :: 1668\n",
      "technolog  :: 1669\n",
      "jesu  :: 1670\n",
      "punch  :: 1671\n",
      "met  :: 1672\n",
      "kevin  :: 1673\n",
      "toy  :: 1674\n",
      "higher  :: 1675\n",
      "aid  :: 1676\n",
      "mike  :: 1677\n",
      "vh  :: 1678\n",
      "abandon  :: 1679\n",
      "interact  :: 1680\n",
      "bet  :: 1681\n",
      "separ  :: 1682\n",
      "command  :: 1683\n",
      "confront  :: 1684\n",
      "servic  :: 1685\n",
      "gotten  :: 1686\n",
      "site  :: 1687\n",
      "techniqu  :: 1688\n",
      "stunt  :: 1689\n",
      "recal  :: 1690\n",
      "belong  :: 1691\n",
      "cabl  :: 1692\n",
      "freak  :: 1693\n",
      "foot  :: 1694\n",
      "bug  :: 1695\n",
      "fu  :: 1696\n",
      "jimmi  :: 1697\n",
      "african  :: 1698\n",
      "capabl  :: 1699\n",
      "bright  :: 1700\n",
      "fat  :: 1701\n",
      "clark  :: 1702\n",
      "succeed  :: 1703\n",
      "presid  :: 1704\n",
      "boat  :: 1705\n",
      "stock  :: 1706\n",
      "gene  :: 1707\n",
      "spanish  :: 1708\n",
      "structur  :: 1709\n",
      "kidnap  :: 1710\n",
      "paper  :: 1711\n",
      "belief  :: 1712\n",
      "whilst  :: 1713\n",
      "factor  :: 1714\n",
      "bob  :: 1715\n",
      "realis  :: 1716\n",
      "tree  :: 1717\n",
      "complic  :: 1718\n",
      "attend  :: 1719\n",
      "witti  :: 1720\n",
      "educ  :: 1721\n",
      "realism  :: 1722\n",
      "broken  :: 1723\n",
      "santa  :: 1724\n",
      "assist  :: 1725\n",
      "finest  :: 1726\n",
      "smoke  :: 1727\n",
      "determin  :: 1728\n",
      "up  :: 1729\n",
      "v  :: 1730\n",
      "depart  :: 1731\n",
      "observ  :: 1732\n",
      "oper  :: 1733\n",
      "rubbish  :: 1734\n",
      "hat  :: 1735\n",
      "domin  :: 1736\n",
      "lewi  :: 1737\n",
      "routin  :: 1738\n",
      "fame  :: 1739\n",
      "hook  :: 1740\n",
      "kinda  :: 1741\n",
      "advanc  :: 1742\n",
      "lone  :: 1743\n",
      "foreign  :: 1744\n",
      "safe  :: 1745\n",
      "morgan  :: 1746\n",
      "rank  :: 1747\n",
      "numer  :: 1748\n",
      "shallow  :: 1749\n",
      "shape  :: 1750\n",
      "washington  :: 1751\n",
      "rose  :: 1752\n",
      "civil  :: 1753\n",
      "vs  :: 1754\n",
      "werewolf  :: 1755\n",
      "gari  :: 1756\n",
      "morn  :: 1757\n",
      "ordinari  :: 1758\n",
      "winner  :: 1759\n",
      "kong  :: 1760\n",
      "accomplish  :: 1761\n",
      "virtual  :: 1762\n",
      "whenev  :: 1763\n",
      "grab  :: 1764\n",
      "peac  :: 1765\n",
      "offens  :: 1766\n",
      "luck  :: 1767\n",
      "h  :: 1768\n",
      "complain  :: 1769\n",
      "bigger  :: 1770\n",
      "welcom  :: 1771\n",
      "patient  :: 1772\n",
      "activ  :: 1773\n",
      "unfunni  :: 1774\n",
      "contriv  :: 1775\n",
      "trek  :: 1776\n",
      "pretend  :: 1777\n",
      "con  :: 1778\n",
      "dimension  :: 1779\n",
      "dri  :: 1780\n",
      "flash  :: 1781\n",
      "cain  :: 1782\n",
      "wake  :: 1783\n",
      "code  :: 1784\n",
      "lesbian  :: 1785\n",
      "eric  :: 1786\n",
      "guard  :: 1787\n",
      "dancer  :: 1788\n",
      "corrupt  :: 1789\n",
      "albert  :: 1790\n",
      "statu  :: 1791\n",
      "manipul  :: 1792\n",
      "gain  :: 1793\n",
      "sourc  :: 1794\n",
      "signific  :: 1795\n",
      "context  :: 1796\n",
      "awkward  :: 1797\n",
      "speech  :: 1798\n",
      "13  :: 1799\n",
      "sean  :: 1800\n",
      "psycho  :: 1801\n",
      "anthoni  :: 1802\n",
      "clip  :: 1803\n",
      "corni  :: 1804\n",
      "priest  :: 1805\n",
      "curiou  :: 1806\n",
      "advic  :: 1807\n",
      "theatric  :: 1808\n",
      "w  :: 1809\n",
      "reli  :: 1810\n",
      "religion  :: 1811\n",
      "flow  :: 1812\n",
      "addict  :: 1813\n",
      "asian  :: 1814\n",
      "skin  :: 1815\n",
      "howard  :: 1816\n",
      "specif  :: 1817\n",
      "secur  :: 1818\n",
      "jennif  :: 1819\n",
      "core  :: 1820\n",
      "organ  :: 1821\n",
      "comfort  :: 1822\n",
      "golden  :: 1823\n",
      "luke  :: 1824\n",
      "promot  :: 1825\n",
      "lucki  :: 1826\n",
      "cheat  :: 1827\n",
      "cash  :: 1828\n",
      "dislik  :: 1829\n",
      "associ  :: 1830\n",
      "lower  :: 1831\n",
      "wing  :: 1832\n",
      "degre  :: 1833\n",
      "contribut  :: 1834\n",
      "spell  :: 1835\n",
      "frequent  :: 1836\n",
      "balanc  :: 1837\n",
      "frankli  :: 1838\n",
      "devic  :: 1839\n",
      "regret  :: 1840\n",
      "lake  :: 1841\n",
      "forgiv  :: 1842\n",
      "print  :: 1843\n",
      "sake  :: 1844\n",
      "thoma  :: 1845\n",
      "betti  :: 1846\n",
      "mass  :: 1847\n",
      "crack  :: 1848\n",
      "unexpect  :: 1849\n",
      "gordon  :: 1850\n",
      "categori  :: 1851\n",
      "invit  :: 1852\n",
      "grown  :: 1853\n",
      "depend  :: 1854\n",
      "construct  :: 1855\n",
      "amateur  :: 1856\n",
      "unfold  :: 1857\n",
      "matur  :: 1858\n",
      "honor  :: 1859\n",
      "walter  :: 1860\n",
      "intellectu  :: 1861\n",
      "grew  :: 1862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anna  :: 1863\n",
      "condit  :: 1864\n",
      "sudden  :: 1865\n",
      "mirror  :: 1866\n",
      "sole  :: 1867\n",
      "veteran  :: 1868\n",
      "spectacular  :: 1869\n",
      "demonstr  :: 1870\n",
      "meanwhil  :: 1871\n",
      "overli  :: 1872\n",
      "card  :: 1873\n",
      "gift  :: 1874\n",
      "freedom  :: 1875\n",
      "liner  :: 1876\n",
      "robin  :: 1877\n",
      "experienc  :: 1878\n",
      "grip  :: 1879\n",
      "crappi  :: 1880\n",
      "brilliantli  :: 1881\n",
      "colour  :: 1882\n",
      "subtitl  :: 1883\n",
      "section  :: 1884\n",
      "circumst  :: 1885\n",
      "theori  :: 1886\n",
      "drew  :: 1887\n",
      "sheriff  :: 1888\n",
      "unabl  :: 1889\n",
      "oliv  :: 1890\n",
      "pile  :: 1891\n",
      "matt  :: 1892\n",
      "laughter  :: 1893\n",
      "altern  :: 1894\n",
      "sheer  :: 1895\n",
      "parker  :: 1896\n",
      "path  :: 1897\n",
      "cook  :: 1898\n",
      "lawyer  :: 1899\n",
      "accident  :: 1900\n",
      "treatment  :: 1901\n",
      "hall  :: 1902\n",
      "defin  :: 1903\n",
      "wander  :: 1904\n",
      "sinatra  :: 1905\n",
      "relief  :: 1906\n",
      "captiv  :: 1907\n",
      "dragon  :: 1908\n",
      "hank  :: 1909\n",
      "halloween  :: 1910\n",
      "gratuit  :: 1911\n",
      "moor  :: 1912\n",
      "cowboy  :: 1913\n",
      "k  :: 1914\n",
      "jacki  :: 1915\n",
      "wayn  :: 1916\n",
      "barbara  :: 1917\n",
      "broadway  :: 1918\n",
      "unintent  :: 1919\n",
      "kung  :: 1920\n",
      "wound  :: 1921\n",
      "surreal  :: 1922\n",
      "canadian  :: 1923\n",
      "statement  :: 1924\n",
      "winter  :: 1925\n",
      "spoof  :: 1926\n",
      "fish  :: 1927\n",
      "cheer  :: 1928\n",
      "gonna  :: 1929\n",
      "treasur  :: 1930\n",
      "fare  :: 1931\n",
      "compos  :: 1932\n",
      "sensit  :: 1933\n",
      "victor  :: 1934\n",
      "woodi  :: 1935\n",
      "unrealist  :: 1936\n",
      "emerg  :: 1937\n",
      "driven  :: 1938\n",
      "ran  :: 1939\n",
      "sympathet  :: 1940\n",
      "neighbor  :: 1941\n",
      "glass  :: 1942\n",
      "topic  :: 1943\n",
      "expos  :: 1944\n",
      "authent  :: 1945\n",
      "menac  :: 1946\n",
      "overlook  :: 1947\n",
      "gross  :: 1948\n",
      "chief  :: 1949\n",
      "michel  :: 1950\n",
      "handsom  :: 1951\n",
      "ancient  :: 1952\n",
      "feet  :: 1953\n",
      "comedian  :: 1954\n",
      "cinderella  :: 1955\n",
      "network  :: 1956\n",
      "built  :: 1957\n",
      "contemporari  :: 1958\n",
      "pleasant  :: 1959\n",
      "russel  :: 1960\n",
      "stranger  :: 1961\n",
      "nevertheless  :: 1962\n",
      "endless  :: 1963\n",
      "blockbust  :: 1964\n",
      "letter  :: 1965\n",
      "earn  :: 1966\n",
      "miser  :: 1967\n",
      "consider  :: 1968\n",
      "underr  :: 1969\n",
      "gori  :: 1970\n",
      "brook  :: 1971\n",
      "switch  :: 1972\n",
      "solv  :: 1973\n",
      "convict  :: 1974\n",
      "joseph  :: 1975\n",
      "virgin  :: 1976\n",
      "victoria  :: 1977\n",
      "edward  :: 1978\n",
      "bullet  :: 1979\n",
      "scenario  :: 1980\n",
      "0  :: 1981\n",
      "scale  :: 1982\n",
      "alex  :: 1983\n",
      "cynic  :: 1984\n",
      "chosen  :: 1985\n",
      "curs  :: 1986\n",
      "sword  :: 1987\n",
      "gut  :: 1988\n",
      "outrag  :: 1989\n",
      "com  :: 1990\n",
      "wrap  :: 1991\n",
      "uk  :: 1992\n",
      "substanc  :: 1993\n",
      "proper  :: 1994\n",
      "driver  :: 1995\n",
      "monkey  :: 1996\n",
      "juli  :: 1997\n",
      "screenwrit  :: 1998\n",
      "court  :: 1999\n",
      "remov  :: 2000\n",
      "bird  :: 2001\n",
      "indic  :: 2002\n",
      "par  :: 2003\n",
      "consequ  :: 2004\n",
      "naiv  :: 2005\n",
      "nanci  :: 2006\n",
      "roy  :: 2007\n",
      "loser  :: 2008\n",
      "grave  :: 2009\n",
      "inevit  :: 2010\n",
      "advertis  :: 2011\n",
      "rental  :: 2012\n",
      "germani  :: 2013\n",
      "le  :: 2014\n",
      "fatal  :: 2015\n",
      "bridg  :: 2016\n",
      "brave  :: 2017\n",
      "slap  :: 2018\n",
      "invis  :: 2019\n",
      "provok  :: 2020\n",
      "footbal  :: 2021\n",
      "anger  :: 2022\n",
      "loui  :: 2023\n",
      "ador  :: 2024\n",
      "chan  :: 2025\n",
      "anderson  :: 2026\n",
      "alcohol  :: 2027\n",
      "willi  :: 2028\n",
      "stumbl  :: 2029\n",
      "ryan  :: 2030\n",
      "professor  :: 2031\n",
      "patrick  :: 2032\n",
      "assassin  :: 2033\n",
      "1930  :: 2034\n",
      "bat  :: 2035\n",
      "sharp  :: 2036\n",
      "australian  :: 2037\n",
      "deni  :: 2038\n",
      "ape  :: 2039\n",
      "lousi  :: 2040\n",
      "saturday  :: 2041\n",
      "cell  :: 2042\n",
      "trilog  :: 2043\n",
      "refresh  :: 2044\n",
      "strongli  :: 2045\n",
      "eight  :: 2046\n",
      "liber  :: 2047\n",
      "amateurish  :: 2048\n",
      "heck  :: 2049\n",
      "sin  :: 2050\n",
      "resid  :: 2051\n",
      "justifi  :: 2052\n",
      "san  :: 2053\n",
      "vagu  :: 2054\n",
      "creator  :: 2055\n",
      "reput  :: 2056\n",
      "terrifi  :: 2057\n",
      "defeat  :: 2058\n",
      "sympathi  :: 2059\n",
      "mini  :: 2060\n",
      "indi  :: 2061\n",
      "prevent  :: 2062\n",
      "expert  :: 2063\n",
      "task  :: 2064\n",
      "tediou  :: 2065\n",
      "endur  :: 2066\n",
      "tabl  :: 2067\n",
      "offend  :: 2068\n",
      "basebal  :: 2069\n",
      "imit  :: 2070\n",
      "employ  :: 2071\n",
      "rival  :: 2072\n",
      "che  :: 2073\n",
      "trial  :: 2074\n",
      "dig  :: 2075\n",
      "europ  :: 2076\n",
      "weekend  :: 2077\n",
      "max  :: 2078\n",
      "fairi  :: 2079\n",
      "pitch  :: 2080\n",
      "complaint  :: 2081\n",
      "beach  :: 2082\n",
      "purchas  :: 2083\n",
      "murphi  :: 2084\n",
      "format  :: 2085\n",
      "risk  :: 2086\n",
      "bite  :: 2087\n",
      "nois  :: 2088\n",
      "titan  :: 2089\n",
      "powel  :: 2090\n",
      "hype  :: 2091\n",
      "harsh  :: 2092\n",
      "reminisc  :: 2093\n",
      "tini  :: 2094\n",
      "glimps  :: 2095\n",
      "north  :: 2096\n",
      "fals  :: 2097\n",
      "14  :: 2098\n",
      "asleep  :: 2099\n",
      "till  :: 2100\n",
      "prime  :: 2101\n",
      "strip  :: 2102\n",
      "destruct  :: 2103\n",
      "descript  :: 2104\n",
      "texa  :: 2105\n",
      "africa  :: 2106\n",
      "revel  :: 2107\n",
      "uninterest  :: 2108\n",
      "inner  :: 2109\n",
      "excess  :: 2110\n",
      "spin  :: 2111\n",
      "surfac  :: 2112\n",
      "arrest  :: 2113\n",
      "sitcom  :: 2114\n",
      "semi  :: 2115\n",
      "massiv  :: 2116\n",
      "makeup  :: 2117\n",
      "dinosaur  :: 2118\n",
      "hitchcock  :: 2119\n",
      "controversi  :: 2120\n",
      "twin  :: 2121\n",
      "maintain  :: 2122\n",
      "argu  :: 2123\n",
      "kim  :: 2124\n",
      "ludicr  :: 2125\n",
      "melodrama  :: 2126\n",
      "insist  :: 2127\n",
      "reject  :: 2128\n",
      "ideal  :: 2129\n",
      "expens  :: 2130\n",
      "stare  :: 2131\n",
      "subplot  :: 2132\n",
      "press  :: 2133\n",
      "host  :: 2134\n",
      "columbo  :: 2135\n",
      "supernatur  :: 2136\n",
      "nail  :: 2137\n",
      "atroci  :: 2138\n",
      "erot  :: 2139\n",
      "forest  :: 2140\n",
      "ga  :: 2141\n",
      "ala  :: 2142\n",
      "identifi  :: 2143\n",
      "cant  :: 2144\n",
      "notch  :: 2145\n",
      "dude  :: 2146\n",
      "presum  :: 2147\n",
      "character  :: 2148\n",
      "crude  :: 2149\n",
      "method  :: 2150\n",
      "plagu  :: 2151\n",
      "closer  :: 2152\n",
      "guest  :: 2153\n",
      "forgett  :: 2154\n",
      "princess  :: 2155\n",
      "landscap  :: 2156\n",
      "beast  :: 2157\n",
      "border  :: 2158\n",
      "ear  :: 2159\n",
      "foster  :: 2160\n",
      "lion  :: 2161\n",
      "birth  :: 2162\n",
      "urban  :: 2163\n",
      "bound  :: 2164\n",
      "previous  :: 2165\n",
      "pacino  :: 2166\n",
      "accus  :: 2167\n",
      "damag  :: 2168\n",
      "storytel  :: 2169\n",
      "aunt  :: 2170\n",
      "jungl  :: 2171\n",
      "nude  :: 2172\n",
      "guid  :: 2173\n",
      "jess  :: 2174\n",
      "emma  :: 2175\n",
      "thirti  :: 2176\n",
      "propaganda  :: 2177\n",
      "chose  :: 2178\n",
      "doll  :: 2179\n",
      "pet  :: 2180\n",
      "whoever  :: 2181\n",
      "mate  :: 2182\n",
      "25  :: 2183\n",
      "warrior  :: 2184\n",
      "mainstream  :: 2185\n",
      "exact  :: 2186\n",
      "size  :: 2187\n",
      "upset  :: 2188\n",
      "gritti  :: 2189\n",
      "cooper  :: 2190\n",
      "latest  :: 2191\n",
      "friday  :: 2192\n",
      "merit  :: 2193\n",
      "poster  :: 2194\n",
      "deadli  :: 2195\n",
      "1990  :: 2196\n",
      "citizen  :: 2197\n",
      "warner  :: 2198\n",
      "buff  :: 2199\n",
      "contact  :: 2200\n",
      "rough  :: 2201\n",
      "wilson  :: 2202\n",
      "popul  :: 2203\n",
      "corps  :: 2204\n",
      "blend  :: 2205\n",
      "sun  :: 2206\n",
      "settl  :: 2207\n",
      "ton  :: 2208\n",
      "contest  :: 2209\n",
      "select  :: 2210\n",
      "overcom  :: 2211\n",
      "pitt  :: 2212\n",
      "metal  :: 2213\n",
      "mgm  :: 2214\n",
      "widow  :: 2215\n",
      "alic  :: 2216\n",
      "rat  :: 2217\n",
      "bu  :: 2218\n",
      "environ  :: 2219\n",
      "guilti  :: 2220\n",
      "particip  :: 2221\n",
      "ted  :: 2222\n",
      "lift  :: 2223\n",
      "revolut  :: 2224\n",
      "link  :: 2225\n",
      "accompani  :: 2226\n",
      "afternoon  :: 2227\n",
      "1960  :: 2228\n",
      "exagger  :: 2229\n",
      "prostitut  :: 2230\n",
      "corpor  :: 2231\n",
      "corner  :: 2232\n",
      "moron  :: 2233\n",
      "matrix  :: 2234\n",
      "johnson  :: 2235\n",
      "clair  :: 2236\n",
      "sincer  :: 2237\n",
      "leagu  :: 2238\n",
      "multipl  :: 2239\n",
      "hood  :: 2240\n",
      "friendli  :: 2241\n",
      "holm  :: 2242\n",
      "instal  :: 2243\n",
      "doom  :: 2244\n",
      "sunday  :: 2245\n",
      "lugosi  :: 2246\n",
      "defend  :: 2247\n",
      "grim  :: 2248\n",
      "examin  :: 2249\n",
      "hip  :: 2250\n",
      "blah  :: 2251\n",
      "junk  :: 2252\n",
      "campi  :: 2253\n",
      "string  :: 2254\n",
      "aka  :: 2255\n",
      "advis  :: 2256\n",
      "irish  :: 2257\n",
      "shake  :: 2258\n",
      "shut  :: 2259\n",
      "rachel  :: 2260\n",
      "icon  :: 2261\n",
      "tight  :: 2262\n",
      "varieti  :: 2263\n",
      "confid  :: 2264\n",
      "pro  :: 2265\n",
      "directli  :: 2266\n",
      "medic  :: 2267\n",
      "goal  :: 2268\n",
      "jaw  :: 2269\n",
      "attach  :: 2270\n",
      "denni  :: 2271\n",
      "mexican  :: 2272\n",
      "sullivan  :: 2273\n",
      "sarah  :: 2274\n",
      "dean  :: 2275\n",
      "prior  :: 2276\n",
      "duke  :: 2277\n",
      "courag  :: 2278\n",
      "terrorist  :: 2279\n",
      "bourn  :: 2280\n",
      "breast  :: 2281\n",
      "sentenc  :: 2282\n",
      "vietnam  :: 2283\n",
      "truck  :: 2284\n",
      "legendari  :: 2285\n",
      "entri  :: 2286\n",
      "donald  :: 2287\n",
      "nose  :: 2288\n",
      "hong  :: 2289\n",
      "split  :: 2290\n",
      "proceed  :: 2291\n",
      "un  :: 2292\n",
      "behav  :: 2293\n",
      "yell  :: 2294\n",
      "gather  :: 2295\n",
      "everywher  :: 2296\n",
      "lifetim  :: 2297\n",
      "crush  :: 2298\n",
      "unconvinc  :: 2299\n",
      "confess  :: 2300\n",
      "buri  :: 2301\n",
      "jerk  :: 2302\n",
      "borrow  :: 2303\n",
      "forth  :: 2304\n",
      "stolen  :: 2305\n",
      "concentr  :: 2306\n",
      "swim  :: 2307\n",
      "julia  :: 2308\n",
      "turkey  :: 2309\n",
      "deliveri  :: 2310\n",
      "pan  :: 2311\n",
      "california  :: 2312\n",
      "lip  :: 2313\n",
      "spite  :: 2314\n",
      "proud  :: 2315\n",
      "reward  :: 2316\n",
      "freeman  :: 2317\n",
      "hoffman  :: 2318\n",
      "downright  :: 2319\n",
      "offici  :: 2320\n",
      "quest  :: 2321\n",
      "china  :: 2322\n",
      "flight  :: 2323\n",
      "sink  :: 2324\n",
      "fabul  :: 2325\n",
      "worthwhil  :: 2326\n",
      "notori  :: 2327\n",
      "jon  :: 2328\n",
      "jail  :: 2329\n",
      "sir  :: 2330\n",
      "lazi  :: 2331\n",
      "inept  :: 2332\n",
      "fade  :: 2333\n",
      "betray  :: 2334\n",
      "encourag  :: 2335\n",
      "teeth  :: 2336\n",
      "shower  :: 2337\n",
      "relev  :: 2338\n",
      "susan  :: 2339\n",
      "branagh  :: 2340\n",
      "bell  :: 2341\n",
      "bag  :: 2342\n",
      "lisa  :: 2343\n",
      "cousin  :: 2344\n",
      "imageri  :: 2345\n",
      "survivor  :: 2346\n",
      "storm  :: 2347\n",
      "retard  :: 2348\n",
      "summari  :: 2349\n",
      "hugh  :: 2350\n",
      "trade  :: 2351\n",
      "finger  :: 2352\n",
      "alright  :: 2353\n",
      "stab  :: 2354\n",
      "bride  :: 2355\n",
      "shark  :: 2356\n",
      "quirki  :: 2357\n",
      "toler  :: 2358\n",
      "facial  :: 2359\n",
      "mexico  :: 2360\n",
      "tremend  :: 2361\n",
      "hyster  :: 2362\n",
      "blown  :: 2363\n",
      "pose  :: 2364\n",
      "bitter  :: 2365\n",
      "von  :: 2366\n",
      "ha  :: 2367\n",
      "address  :: 2368\n",
      "afterward  :: 2369\n",
      "larri  :: 2370\n",
      "ned  :: 2371\n",
      "ron  :: 2372\n",
      "scheme  :: 2373\n",
      "cruel  :: 2374\n",
      "bone  :: 2375\n",
      "christ  :: 2376\n",
      "screw  :: 2377\n",
      "snake  :: 2378\n",
      "swear  :: 2379\n",
      "distinct  :: 2380\n",
      "pursu  :: 2381\n",
      "tour  :: 2382\n",
      "beg  :: 2383\n",
      "traci  :: 2384\n",
      "feed  :: 2385\n",
      "thumb  :: 2386\n",
      "chair  :: 2387\n",
      "photo  :: 2388\n",
      "raw  :: 2389\n",
      "obscur  :: 2390\n",
      "occas  :: 2391\n",
      "stomach  :: 2392\n",
      "mechan  :: 2393\n",
      "chain  :: 2394\n",
      "hardi  :: 2395\n",
      "render  :: 2396\n",
      "southern  :: 2397\n",
      "argument  :: 2398\n",
      "resist  :: 2399\n",
      "necessarili  :: 2400\n",
      "sidney  :: 2401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heavili  :: 2402\n",
      "cabin  :: 2403\n",
      "holiday  :: 2404\n",
      "gruesom  :: 2405\n",
      "racist  :: 2406\n",
      "india  :: 2407\n",
      "understood  :: 2408\n",
      "satan  :: 2409\n",
      "philip  :: 2410\n",
      "indulg  :: 2411\n",
      "belov  :: 2412\n",
      "stalk  :: 2413\n",
      "forgot  :: 2414\n",
      "midnight  :: 2415\n",
      "outfit  :: 2416\n",
      "pregnant  :: 2417\n",
      "integr  :: 2418\n",
      "tongu  :: 2419\n",
      "fourth  :: 2420\n",
      "lay  :: 2421\n",
      "obnoxi  :: 2422\n",
      "garden  :: 2423\n",
      "deeper  :: 2424\n",
      "ticket  :: 2425\n",
      "carol  :: 2426\n",
      "magazin  :: 2427\n",
      "17  :: 2428\n",
      "restor  :: 2429\n",
      "inhabit  :: 2430\n",
      "slapstick  :: 2431\n",
      "incid  :: 2432\n",
      "shoe  :: 2433\n",
      "brad  :: 2434\n",
      "devot  :: 2435\n",
      "lincoln  :: 2436\n",
      "underground  :: 2437\n",
      "sandler  :: 2438\n",
      "divorc  :: 2439\n",
      "elizabeth  :: 2440\n",
      "disbelief  :: 2441\n",
      "anticip  :: 2442\n",
      "maria  :: 2443\n",
      "guarante  :: 2444\n",
      "benefit  :: 2445\n",
      "lili  :: 2446\n",
      "amazingli  :: 2447\n",
      "creation  :: 2448\n",
      "explod  :: 2449\n",
      "slave  :: 2450\n",
      "capit  :: 2451\n",
      "greater  :: 2452\n",
      "mildli  :: 2453\n",
      "bbc  :: 2454\n",
      "cring  :: 2455\n",
      "princip  :: 2456\n",
      "lesli  :: 2457\n",
      "funnier  :: 2458\n",
      "introduct  :: 2459\n",
      "halfway  :: 2460\n",
      "extraordinari  :: 2461\n",
      "punish  :: 2462\n",
      "overwhelm  :: 2463\n",
      "advantag  :: 2464\n",
      "tap  :: 2465\n",
      "enhanc  :: 2466\n",
      "text  :: 2467\n",
      "wreck  :: 2468\n",
      "transfer  :: 2469\n",
      "extent  :: 2470\n",
      "lo  :: 2471\n",
      "east  :: 2472\n",
      "preview  :: 2473\n",
      "horrif  :: 2474\n",
      "lane  :: 2475\n",
      "deliber  :: 2476\n",
      "plant  :: 2477\n",
      "dynam  :: 2478\n",
      "error  :: 2479\n",
      "jessica  :: 2480\n",
      "vincent  :: 2481\n",
      "miller  :: 2482\n",
      "sophist  :: 2483\n",
      "basi  :: 2484\n",
      "ensu  :: 2485\n",
      "2000  :: 2486\n",
      "homosexu  :: 2487\n",
      "appli  :: 2488\n",
      "vacat  :: 2489\n",
      "miscast  :: 2490\n",
      "mansion  :: 2491\n",
      "reed  :: 2492\n",
      "spoken  :: 2493\n",
      "extend  :: 2494\n",
      "elev  :: 2495\n",
      "sleazi  :: 2496\n",
      "uncomfort  :: 2497\n",
      "measur  :: 2498\n",
      "bollywood  :: 2499\n",
      "steel  :: 2500\n",
      "via  :: 2501\n",
      "beer  :: 2502\n",
      "savag  :: 2503\n",
      "stanley  :: 2504\n",
      "melt  :: 2505\n",
      "blair  :: 2506\n",
      "daili  :: 2507\n",
      "breathtak  :: 2508\n",
      "dentist  :: 2509\n",
      "alter  :: 2510\n",
      "cathol  :: 2511\n",
      "mous  :: 2512\n",
      "goofi  :: 2513\n",
      "overact  :: 2514\n",
      "assign  :: 2515\n",
      "hippi  :: 2516\n",
      "fix  :: 2517\n",
      "conceiv  :: 2518\n",
      "oppos  :: 2519\n",
      "inspector  :: 2520\n",
      "succe  :: 2521\n",
      "everyday  :: 2522\n",
      "burt  :: 2523\n",
      "subsequ  :: 2524\n",
      "properli  :: 2525\n",
      "nowaday  :: 2526\n",
      "carpent  :: 2527\n",
      "sacrific  :: 2528\n",
      "laura  :: 2529\n",
      "neck  :: 2530\n",
      "massacr  :: 2531\n",
      "block  :: 2532\n",
      "circl  :: 2533\n",
      "fallen  :: 2534\n",
      "mob  :: 2535\n",
      "access  :: 2536\n",
      "grey  :: 2537\n",
      "pool  :: 2538\n",
      "christi  :: 2539\n",
      "concert  :: 2540\n",
      "portrait  :: 2541\n",
      "lesser  :: 2542\n",
      "fay  :: 2543\n",
      "seagal  :: 2544\n",
      "competit  :: 2545\n",
      "react  :: 2546\n",
      "jake  :: 2547\n",
      "chees  :: 2548\n",
      "sinist  :: 2549\n",
      "isol  :: 2550\n",
      "usa  :: 2551\n",
      "jewish  :: 2552\n",
      "relax  :: 2553\n",
      "chop  :: 2554\n",
      "nine  :: 2555\n",
      "nonetheless  :: 2556\n",
      "appal  :: 2557\n",
      "ironi  :: 2558\n",
      "lyric  :: 2559\n",
      "creep  :: 2560\n",
      "spiritu  :: 2561\n",
      "2006  :: 2562\n",
      "suitabl  :: 2563\n",
      "stink  :: 2564\n",
      "immens  :: 2565\n",
      "luci  :: 2566\n",
      "rage  :: 2567\n",
      "shirt  :: 2568\n",
      "user  :: 2569\n",
      "franchis  :: 2570\n",
      "showcas  :: 2571\n",
      "sold  :: 2572\n",
      "navi  :: 2573\n",
      "adopt  :: 2574\n",
      "nut  :: 2575\n",
      "reduc  :: 2576\n",
      "spring  :: 2577\n",
      "needless  :: 2578\n",
      "retir  :: 2579\n",
      "digit  :: 2580\n",
      "asham  :: 2581\n",
      "bulli  :: 2582\n",
      "nurs  :: 2583\n",
      "per  :: 2584\n",
      "uninspir  :: 2585\n",
      "jay  :: 2586\n",
      "stanwyck  :: 2587\n",
      "bath  :: 2588\n",
      "zone  :: 2589\n",
      "laid  :: 2590\n",
      "upper  :: 2591\n",
      "broadcast  :: 2592\n",
      "oddli  :: 2593\n",
      "sutherland  :: 2594\n",
      "illustr  :: 2595\n",
      "2001  :: 2596\n",
      "1940  :: 2597\n",
      "amongst  :: 2598\n",
      "aspir  :: 2599\n",
      "fulfil  :: 2600\n",
      "stylish  :: 2601\n",
      "throat  :: 2602\n",
      "brando  :: 2603\n",
      "baker  :: 2604\n",
      "disguis  :: 2605\n",
      "em  :: 2606\n",
      "pound  :: 2607\n",
      "pride  :: 2608\n",
      "endear  :: 2609\n",
      "18  :: 2610\n",
      "neighborhood  :: 2611\n",
      "wwii  :: 2612\n",
      "impli  :: 2613\n",
      "thief  :: 2614\n",
      "wanna  :: 2615\n",
      "nobl  :: 2616\n",
      "shift  :: 2617\n",
      "shoulder  :: 2618\n",
      "albeit  :: 2619\n",
      "dawn  :: 2620\n",
      "prop  :: 2621\n",
      "distribut  :: 2622\n",
      "16  :: 2623\n",
      "coher  :: 2624\n",
      "cinematograph  :: 2625\n",
      "rochest  :: 2626\n",
      "bett  :: 2627\n",
      "dinner  :: 2628\n",
      "bo  :: 2629\n",
      "diseas  :: 2630\n",
      "tens  :: 2631\n",
      "snow  :: 2632\n",
      "forti  :: 2633\n",
      "surf  :: 2634\n",
      "rebel  :: 2635\n",
      "wash  :: 2636\n",
      "contract  :: 2637\n",
      "function  :: 2638\n",
      "silenc  :: 2639\n",
      "poignant  :: 2640\n",
      "shout  :: 2641\n",
      "matthau  :: 2642\n",
      "knife  :: 2643\n",
      "duti  :: 2644\n",
      "proof  :: 2645\n",
      "silver  :: 2646\n",
      "mindless  :: 2647\n",
      "elvira  :: 2648\n",
      "height  :: 2649\n",
      "internet  :: 2650\n",
      "instinct  :: 2651\n",
      "henc  :: 2652\n",
      "chuck  :: 2653\n",
      "cannib  :: 2654\n",
      "reunion  :: 2655\n",
      "heat  :: 2656\n",
      "eeri  :: 2657\n",
      "horrend  :: 2658\n",
      "derek  :: 2659\n",
      "cancel  :: 2660\n",
      "widmark  :: 2661\n",
      "repetit  :: 2662\n",
      "etern  :: 2663\n",
      "torn  :: 2664\n",
      "spielberg  :: 2665\n",
      "neat  :: 2666\n",
      "incoher  :: 2667\n",
      "glori  :: 2668\n",
      "innov  :: 2669\n",
      "absorb  :: 2670\n",
      "musician  :: 2671\n",
      "alik  :: 2672\n",
      "mill  :: 2673\n",
      "greatli  :: 2674\n",
      "elvi  :: 2675\n",
      "premier  :: 2676\n",
      "pie  :: 2677\n",
      "horrifi  :: 2678\n",
      "lovabl  :: 2679\n",
      "bang  :: 2680\n",
      "nelson  :: 2681\n",
      "precis  :: 2682\n",
      "burton  :: 2683\n",
      "infam  :: 2684\n",
      "homag  :: 2685\n",
      "fbi  :: 2686\n",
      "britain  :: 2687\n",
      "diamond  :: 2688\n",
      "blank  :: 2689\n",
      "itali  :: 2690\n",
      "crisi  :: 2691\n",
      "racism  :: 2692\n",
      "announc  :: 2693\n",
      "redempt  :: 2694\n",
      "trite  :: 2695\n",
      "wealthi  :: 2696\n",
      "parallel  :: 2697\n",
      "streisand  :: 2698\n",
      "resolut  :: 2699\n",
      "dedic  :: 2700\n",
      "happili  :: 2701\n",
      "helen  :: 2702\n",
      "flop  :: 2703\n",
      "pat  :: 2704\n",
      "wilder  :: 2705\n",
      "chaplin  :: 2706\n",
      "ensembl  :: 2707\n",
      "hammer  :: 2708\n",
      "triumph  :: 2709\n",
      "factori  :: 2710\n",
      "st  :: 2711\n",
      "disagre  :: 2712\n",
      "conclud  :: 2713\n",
      "broke  :: 2714\n",
      "carter  :: 2715\n",
      "plastic  :: 2716\n",
      "mar  :: 2717\n",
      "oil  :: 2718\n",
      "cube  :: 2719\n",
      "row  :: 2720\n",
      "own  :: 2721\n",
      "climb  :: 2722\n",
      "fighter  :: 2723\n",
      "bush  :: 2724\n",
      "chuckl  :: 2725\n",
      "vega  :: 2726\n",
      "march  :: 2727\n",
      "rocket  :: 2728\n",
      "weight  :: 2729\n",
      "boot  :: 2730\n",
      "kurt  :: 2731\n",
      "lust  :: 2732\n",
      "enorm  :: 2733\n",
      "dane  :: 2734\n",
      "wherea  :: 2735\n",
      "spare  :: 2736\n",
      "dump  :: 2737\n",
      "meaning  :: 2738\n",
      "unforgett  :: 2739\n",
      "mst3k  :: 2740\n",
      "luca  :: 2741\n",
      "thug  :: 2742\n",
      "sensibl  :: 2743\n",
      "karloff  :: 2744\n",
      "adequ  :: 2745\n",
      "fifti  :: 2746\n",
      "stress  :: 2747\n",
      "bobbi  :: 2748\n",
      "engin  :: 2749\n",
      "brand  :: 2750\n",
      "difficulti  :: 2751\n",
      "butt  :: 2752\n",
      "arnold  :: 2753\n",
      "caricatur  :: 2754\n",
      "rap  :: 2755\n",
      "dear  :: 2756\n",
      "threat  :: 2757\n",
      "flynn  :: 2758\n",
      "ralph  :: 2759\n",
      "secretari  :: 2760\n",
      "ego  :: 2761\n",
      "homeless  :: 2762\n",
      "elabor  :: 2763\n",
      "fest  :: 2764\n",
      "arrog  :: 2765\n",
      "barri  :: 2766\n",
      "hamlet  :: 2767\n",
      "swing  :: 2768\n",
      "journalist  :: 2769\n",
      "polish  :: 2770\n",
      "unbear  :: 2771\n",
      "float  :: 2772\n",
      "fanci  :: 2773\n",
      "grate  :: 2774\n",
      "simpson  :: 2775\n",
      "arrang  :: 2776\n",
      "conspiraci  :: 2777\n",
      "spike  :: 2778\n",
      "induc  :: 2779\n",
      "puppet  :: 2780\n",
      "resort  :: 2781\n",
      "tool  :: 2782\n",
      "phillip  :: 2783\n",
      "choreograph  :: 2784\n",
      "guilt  :: 2785\n",
      "pig  :: 2786\n",
      "muppet  :: 2787\n",
      "tribut  :: 2788\n",
      "basement  :: 2789\n",
      "boll  :: 2790\n",
      "exercis  :: 2791\n",
      "cruis  :: 2792\n",
      "puzzl  :: 2793\n",
      "medium  :: 2794\n",
      "document  :: 2795\n",
      "tower  :: 2796\n",
      "scarecrow  :: 2797\n",
      "stan  :: 2798\n",
      "editor  :: 2799\n",
      "ham  :: 2800\n",
      "fianc  :: 2801\n",
      "korean  :: 2802\n",
      "layer  :: 2803\n",
      "babe  :: 2804\n",
      "toilet  :: 2805\n",
      "item  :: 2806\n",
      "slip  :: 2807\n",
      "ward  :: 2808\n",
      "24  :: 2809\n",
      "file  :: 2810\n",
      "portion  :: 2811\n",
      "philosoph  :: 2812\n",
      "inexplic  :: 2813\n",
      "assur  :: 2814\n",
      "slaughter  :: 2815\n",
      "doc  :: 2816\n",
      "persona  :: 2817\n",
      "orient  :: 2818\n",
      "catherin  :: 2819\n",
      "librari  :: 2820\n",
      "denzel  :: 2821\n",
      "minim  :: 2822\n",
      "glover  :: 2823\n",
      "larger  :: 2824\n",
      "transit  :: 2825\n",
      "territori  :: 2826\n",
      "superfici  :: 2827\n",
      "spark  :: 2828\n",
      "jeremi  :: 2829\n",
      "pg  :: 2830\n",
      "ban  :: 2831\n",
      "curti  :: 2832\n",
      "owe  :: 2833\n",
      "jet  :: 2834\n",
      "wolf  :: 2835\n",
      "financi  :: 2836\n",
      "walken  :: 2837\n",
      "boredom  :: 2838\n",
      "sneak  :: 2839\n",
      "shi  :: 2840\n",
      "dorothi  :: 2841\n",
      "metaphor  :: 2842\n",
      "profound  :: 2843\n",
      "ambigu  :: 2844\n",
      "backdrop  :: 2845\n",
      "hudson  :: 2846\n",
      "multi  :: 2847\n",
      "cusack  :: 2848\n",
      "whale  :: 2849\n",
      "eleph  :: 2850\n",
      "hack  :: 2851\n",
      "gadget  :: 2852\n",
      "union  :: 2853\n",
      "ultra  :: 2854\n",
      "stiff  :: 2855\n",
      "elsewher  :: 2856\n",
      "viru  :: 2857\n",
      "2005  :: 2858\n",
      "implaus  :: 2859\n",
      "birthday  :: 2860\n",
      "notion  :: 2861\n",
      "rave  :: 2862\n",
      "distanc  :: 2863\n",
      "deriv  :: 2864\n",
      "1st  :: 2865\n",
      "reader  :: 2866\n",
      "afford  :: 2867\n",
      "eva  :: 2868\n",
      "superhero  :: 2869\n",
      "urg  :: 2870\n",
      "slight  :: 2871\n",
      "bibl  :: 2872\n",
      "canada  :: 2873\n",
      "hawk  :: 2874\n",
      "poison  :: 2875\n",
      "newspap  :: 2876\n",
      "lloyd  :: 2877\n",
      "disc  :: 2878\n",
      "pad  :: 2879\n",
      "squar  :: 2880\n",
      "eastwood  :: 2881\n",
      "health  :: 2882\n",
      "heston  :: 2883\n",
      "montag  :: 2884\n",
      "spread  :: 2885\n",
      "cure  :: 2886\n",
      "drown  :: 2887\n",
      "sadist  :: 2888\n",
      "skit  :: 2889\n",
      "huh  :: 2890\n",
      "charisma  :: 2891\n",
      "restaur  :: 2892\n",
      "essenc  :: 2893\n",
      "button  :: 2894\n",
      "godfath  :: 2895\n",
      "dealt  :: 2896\n",
      "maniac  :: 2897\n",
      "lab  :: 2898\n",
      "companion  :: 2899\n",
      "fetch  :: 2900\n",
      "peak  :: 2901\n",
      "invest  :: 2902\n",
      "scoobi  :: 2903\n",
      "gradual  :: 2904\n",
      "estat  :: 2905\n",
      "muslim  :: 2906\n",
      "tea  :: 2907\n",
      "gothic  :: 2908\n",
      "alli  :: 2909\n",
      "servant  :: 2910\n",
      "countless  :: 2911\n",
      "cup  :: 2912\n",
      "miik  :: 2913\n",
      "subtleti  :: 2914\n",
      "kane  :: 2915\n",
      "ritter  :: 2916\n",
      "heroic  :: 2917\n",
      "electr  :: 2918\n",
      "briefli  :: 2919\n",
      "charismat  :: 2920\n",
      "elect  :: 2921\n",
      "iii  :: 2922\n",
      "salli  :: 2923\n",
      "admittedli  :: 2924\n",
      "neil  :: 2925\n",
      "reel  :: 2926\n",
      "wannab  :: 2927\n",
      "toss  :: 2928\n",
      "tender  :: 2929\n",
      "ingredi  :: 2930\n",
      "bud  :: 2931\n",
      "nuanc  :: 2932\n",
      "cole  :: 2933\n",
      "grandmoth  :: 2934\n",
      "resourc  :: 2935\n",
      "gate  :: 2936\n",
      "shall  :: 2937\n",
      "mild  :: 2938\n",
      "kubrick  :: 2939\n",
      "pauli  :: 2940\n",
      "mafia  :: 2941\n",
      "stronger  :: 2942\n",
      "dawson  :: 2943\n",
      "stood  :: 2944\n",
      "pit  :: 2945\n",
      "carrey  :: 2946\n",
      "punk  :: 2947\n",
      "poverti  :: 2948\n",
      "label  :: 2949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reev  :: 2950\n",
      "ian  :: 2951\n",
      "easier  :: 2952\n",
      "updat  :: 2953\n",
      "burst  :: 2954\n",
      "assault  :: 2955\n",
      "smash  :: 2956\n",
      "fond  :: 2957\n",
      "smooth  :: 2958\n",
      "useless  :: 2959\n",
      "astair  :: 2960\n",
      "bakshi  :: 2961\n",
      "outcom  :: 2962\n",
      "cardboard  :: 2963\n",
      "tag  :: 2964\n",
      "terri  :: 2965\n",
      "cox  :: 2966\n",
      "divers  :: 2967\n",
      "exchang  :: 2968\n",
      "sketch  :: 2969\n",
      "vulner  :: 2970\n",
      "melodramat  :: 2971\n",
      "increasingli  :: 2972\n",
      "vari  :: 2973\n",
      "coincid  :: 2974\n",
      "fist  :: 2975\n",
      "rex  :: 2976\n",
      "samurai  :: 2977\n",
      "resolv  :: 2978\n",
      "qualifi  :: 2979\n",
      "2002  :: 2980\n",
      "templ  :: 2981\n",
      "scratch  :: 2982\n",
      "suspend  :: 2983\n",
      "blast  :: 2984\n",
      "tame  :: 2985\n",
      "insert  :: 2986\n",
      "reynold  :: 2987\n",
      "brillianc  :: 2988\n",
      "luckili  :: 2989\n",
      "be  :: 2990\n",
      "conveni  :: 2991\n",
      "farm  :: 2992\n",
      "strictli  :: 2993\n",
      "hamilton  :: 2994\n",
      "coach  :: 2995\n",
      "pin  :: 2996\n",
      "nuclear  :: 2997\n",
      "seventi  :: 2998\n",
      "ambiti  :: 2999\n",
      "walker  :: 3000\n",
      "meat  :: 3001\n",
      "jami  :: 3002\n",
      "matthew  :: 3003\n",
      "gotta  :: 3004\n",
      "soprano  :: 3005\n",
      "fisher  :: 3006\n",
      "discoveri  :: 3007\n",
      "revers  :: 3008\n",
      "convolut  :: 3009\n",
      "spooki  :: 3010\n",
      "instantli  :: 3011\n",
      "timeless  :: 3012\n",
      "empir  :: 3013\n",
      "closet  :: 3014\n",
      "cave  :: 3015\n",
      "eccentr  :: 3016\n",
      "kudo  :: 3017\n",
      "recreat  :: 3018\n",
      "ninja  :: 3019\n",
      "butcher  :: 3020\n",
      "clock  :: 3021\n",
      "worthless  :: 3022\n",
      "monk  :: 3023\n",
      "struck  :: 3024\n",
      "brosnan  :: 3025\n",
      "joey  :: 3026\n",
      "grasp  :: 3027\n",
      "seller  :: 3028\n",
      "mitchel  :: 3029\n",
      "bleak  :: 3030\n",
      "wipe  :: 3031\n",
      "pal  :: 3032\n",
      "clown  :: 3033\n",
      "communist  :: 3034\n",
      "eighti  :: 3035\n",
      "cliff  :: 3036\n",
      "norman  :: 3037\n",
      "sloppi  :: 3038\n",
      "sidekick  :: 3039\n",
      "importantli  :: 3040\n",
      "selfish  :: 3041\n",
      "partli  :: 3042\n",
      "inconsist  :: 3043\n",
      "declar  :: 3044\n",
      "fifteen  :: 3045\n",
      "gray  :: 3046\n",
      "miracl  :: 3047\n",
      "evok  :: 3048\n",
      "farc  :: 3049\n",
      "flawless  :: 3050\n",
      "superbl  :: 3051\n",
      "piano  :: 3052\n",
      "ho  :: 3053\n",
      "seed  :: 3054\n",
      "stoog  :: 3055\n",
      "chew  :: 3056\n",
      "websit  :: 3057\n",
      "aforement  :: 3058\n",
      "45  :: 3059\n",
      "lifestyl  :: 3060\n",
      "cheek  :: 3061\n",
      "debat  :: 3062\n",
      "australia  :: 3063\n",
      "destin  :: 3064\n",
      "enthusiast  :: 3065\n",
      "psychiatrist  :: 3066\n",
      "pressur  :: 3067\n",
      "soviet  :: 3068\n",
      "bash  :: 3069\n",
      "slice  :: 3070\n",
      "wrestl  :: 3071\n",
      "drivel  :: 3072\n",
      "incompet  :: 3073\n",
      "abc  :: 3074\n",
      "splatter  :: 3075\n",
      "akshay  :: 3076\n",
      "dire  :: 3077\n",
      "kitchen  :: 3078\n",
      "dash  :: 3079\n",
      "emili  :: 3080\n",
      "wick  :: 3081\n",
      "directori  :: 3082\n",
      "regardless  :: 3083\n",
      "anni  :: 3084\n",
      "mann  :: 3085\n",
      "chapter  :: 3086\n",
      "lou  :: 3087\n",
      "glow  :: 3088\n",
      "cia  :: 3089\n",
      "doo  :: 3090\n",
      "distant  :: 3091\n",
      "recov  :: 3092\n",
      "curios  :: 3093\n",
      "prize  :: 3094\n",
      "cameron  :: 3095\n",
      "boil  :: 3096\n",
      "ken  :: 3097\n",
      "jar  :: 3098\n",
      "flower  :: 3099\n",
      "increas  :: 3100\n",
      "suppli  :: 3101\n",
      "pleasantli  :: 3102\n",
      "helicopt  :: 3103\n",
      "duo  :: 3104\n",
      "judi  :: 3105\n",
      "artifici  :: 3106\n",
      "beaten  :: 3107\n",
      "seduc  :: 3108\n",
      "cagney  :: 3109\n",
      "blob  :: 3110\n",
      "dave  :: 3111\n",
      "drunken  :: 3112\n",
      "glenn  :: 3113\n",
      "ranger  :: 3114\n",
      "laurel  :: 3115\n",
      "ellen  :: 3116\n",
      "craig  :: 3117\n",
      "favour  :: 3118\n",
      "combat  :: 3119\n",
      "panic  :: 3120\n",
      "web  :: 3121\n",
      "psychot  :: 3122\n",
      "splendid  :: 3123\n",
      "perri  :: 3124\n",
      "eleg  :: 3125\n",
      "hop  :: 3126\n",
      "francisco  :: 3127\n",
      "goldberg  :: 3128\n",
      "craven  :: 3129\n",
      "turner  :: 3130\n",
      "gentl  :: 3131\n",
      "flip  :: 3132\n",
      "graduat  :: 3133\n",
      "wizard  :: 3134\n",
      "gandhi  :: 3135\n",
      "min  :: 3136\n",
      "plausibl  :: 3137\n",
      "philosophi  :: 3138\n",
      "falk  :: 3139\n",
      "shortli  :: 3140\n",
      "fx  :: 3141\n",
      "rid  :: 3142\n",
      "20th  :: 3143\n",
      "greek  :: 3144\n",
      "modesti  :: 3145\n",
      "alexand  :: 3146\n",
      "ruth  :: 3147\n",
      "hatr  :: 3148\n",
      "slightest  :: 3149\n",
      "fund  :: 3150\n",
      "we  :: 3151\n",
      "felix  :: 3152\n",
      "jealou  :: 3153\n",
      "tall  :: 3154\n",
      "manhattan  :: 3155\n",
      "ocean  :: 3156\n",
      "harm  :: 3157\n",
      "legal  :: 3158\n",
      "lend  :: 3159\n",
      "preciou  :: 3160\n",
      "holi  :: 3161\n",
      "knight  :: 3162\n",
      "dracula  :: 3163\n",
      "futurist  :: 3164\n",
      "unpleas  :: 3165\n",
      "mock  :: 3166\n",
      "tank  :: 3167\n",
      "nod  :: 3168\n",
      "childish  :: 3169\n",
      "forbidden  :: 3170\n",
      "scientif  :: 3171\n",
      "digniti  :: 3172\n",
      "thread  :: 3173\n",
      "giallo  :: 3174\n",
      "ami  :: 3175\n",
      "explicit  :: 3176\n",
      "bless  :: 3177\n",
      "reviv  :: 3178\n",
      "overdon  :: 3179\n",
      "eve  :: 3180\n",
      "verhoeven  :: 3181\n",
      "repeatedli  :: 3182\n",
      "yesterday  :: 3183\n",
      "2004  :: 3184\n",
      "mel  :: 3185\n",
      "pirat  :: 3186\n",
      "elderli  :: 3187\n",
      "thick  :: 3188\n",
      "awe  :: 3189\n",
      "fever  :: 3190\n",
      "broad  :: 3191\n",
      "torment  :: 3192\n",
      "margaret  :: 3193\n",
      "awaken  :: 3194\n",
      "99  :: 3195\n",
      "nerv  :: 3196\n",
      "unwatch  :: 3197\n",
      "eas  :: 3198\n",
      "publish  :: 3199\n",
      "rivet  :: 3200\n",
      "stiller  :: 3201\n",
      "timothi  :: 3202\n",
      "roman  :: 3203\n",
      "uniform  :: 3204\n",
      "lean  :: 3205\n",
      "bin  :: 3206\n",
      "absenc  :: 3207\n",
      "romero  :: 3208\n",
      "acclaim  :: 3209\n",
      "kay  :: 3210\n",
      "launch  :: 3211\n",
      "politician  :: 3212\n",
      "automat  :: 3213\n",
      "ah  :: 3214\n",
      "ambit  :: 3215\n",
      "custom  :: 3216\n",
      "griffith  :: 3217\n",
      "royal  :: 3218\n",
      "darker  :: 3219\n",
      "pulp  :: 3220\n",
      "crook  :: 3221\n",
      "antic  :: 3222\n",
      "sunshin  :: 3223\n",
      "wallac  :: 3224\n",
      "homicid  :: 3225\n",
      "tomato  :: 3226\n",
      "termin  :: 3227\n",
      "pierc  :: 3228\n",
      "warren  :: 3229\n",
      "transport  :: 3230\n",
      "phrase  :: 3231\n",
      "bathroom  :: 3232\n",
      "purpl  :: 3233\n",
      "foul  :: 3234\n",
      "gabriel  :: 3235\n",
      "stinker  :: 3236\n",
      "horrid  :: 3237\n",
      "eyr  :: 3238\n",
      "ought  :: 3239\n",
      "packag  :: 3240\n",
      "li  :: 3241\n",
      "evolv  :: 3242\n",
      "awak  :: 3243\n",
      "album  :: 3244\n",
      "rambo  :: 3245\n",
      "donna  :: 3246\n",
      "revolutionari  :: 3247\n",
      "hollow  :: 3248\n",
      "saint  :: 3249\n",
      "marin  :: 3250\n",
      "kenneth  :: 3251\n",
      "juvenil  :: 3252\n",
      "contrari  :: 3253\n",
      "q  :: 3254\n",
      "viciou  :: 3255\n",
      "brazil  :: 3256\n",
      "2003  :: 3257\n",
      "choreographi  :: 3258\n",
      "coloni  :: 3259\n",
      "sixti  :: 3260\n",
      "karen  :: 3261\n",
      "pray  :: 3262\n",
      "prom  :: 3263\n",
      "option  :: 3264\n",
      "stole  :: 3265\n",
      "kapoor  :: 3266\n",
      "conserv  :: 3267\n",
      "ireland  :: 3268\n",
      "mildr  :: 3269\n",
      "defi  :: 3270\n",
      "blade  :: 3271\n",
      "beatti  :: 3272\n",
      "candid  :: 3273\n",
      "overr  :: 3274\n",
      "dose  :: 3275\n",
      "mummi  :: 3276\n",
      "ramon  :: 3277\n",
      "twelv  :: 3278\n",
      "nerd  :: 3279\n",
      "boast  :: 3280\n",
      "astonish  :: 3281\n",
      "protest  :: 3282\n",
      "natali  :: 3283\n",
      "flame  :: 3284\n",
      "funer  :: 3285\n",
      "kirk  :: 3286\n",
      "detract  :: 3287\n",
      "collabor  :: 3288\n",
      "fulci  :: 3289\n",
      "jazz  :: 3290\n",
      "confirm  :: 3291\n",
      "trio  :: 3292\n",
      "altman  :: 3293\n",
      "global  :: 3294\n",
      "nicholson  :: 3295\n",
      "blake  :: 3296\n",
      "bull  :: 3297\n",
      "yellow  :: 3298\n",
      "mystic  :: 3299\n",
      "tommi  :: 3300\n",
      "leap  :: 3301\n",
      "shade  :: 3302\n",
      "whip  :: 3303\n",
      "racial  :: 3304\n",
      "spit  :: 3305\n",
      "bottl  :: 3306\n",
      "audio  :: 3307\n",
      "destini  :: 3308\n",
      "delici  :: 3309\n",
      "enterpris  :: 3310\n",
      "vivid  :: 3311\n",
      "todd  :: 3312\n",
      "merci  :: 3313\n",
      "enchant  :: 3314\n",
      "adolesc  :: 3315\n",
      "threw  :: 3316\n",
      "harder  :: 3317\n",
      "fonda  :: 3318\n",
      "staff  :: 3319\n",
      "neo  :: 3320\n",
      "popcorn  :: 3321\n",
      "visibl  :: 3322\n",
      "inherit  :: 3323\n",
      "meaningless  :: 3324\n",
      "swedish  :: 3325\n",
      "pseudo  :: 3326\n",
      "bedroom  :: 3327\n",
      "reunit  :: 3328\n",
      "altogeth  :: 3329\n",
      "leonard  :: 3330\n",
      "befriend  :: 3331\n",
      "crocodil  :: 3332\n",
      "roommat  :: 3333\n",
      "lawrenc  :: 3334\n",
      "suspici  :: 3335\n",
      "moodi  :: 3336\n",
      "madonna  :: 3337\n",
      "reserv  :: 3338\n",
      "ruthless  :: 3339\n",
      "wire  :: 3340\n",
      "decor  :: 3341\n",
      "edi  :: 3342\n",
      "synopsi  :: 3343\n",
      "atlanti  :: 3344\n",
      "fanat  :: 3345\n",
      "await  :: 3346\n",
      "respond  :: 3347\n",
      "jew  :: 3348\n",
      "exhibit  :: 3349\n",
      "uneven  :: 3350\n",
      "bust  :: 3351\n",
      "tip  :: 3352\n",
      "voight  :: 3353\n",
      "lemmon  :: 3354\n",
      "kennedi  :: 3355\n",
      "clint  :: 3356\n",
      "centr  :: 3357\n",
      "chao  :: 3358\n",
      "rural  :: 3359\n",
      "bargain  :: 3360\n",
      "dimens  :: 3361\n",
      "unsettl  :: 3362\n",
      "incident  :: 3363\n",
      "palma  :: 3364\n",
      "voyag  :: 3365\n",
      "abysm  :: 3366\n",
      "bold  :: 3367\n",
      "clumsi  :: 3368\n",
      "holli  :: 3369\n",
      "carl  :: 3370\n",
      "bradi  :: 3371\n",
      "2007  :: 3372\n",
      "garner  :: 3373\n",
      "ventur  :: 3374\n",
      "audit  :: 3375\n",
      "troop  :: 3376\n",
      "ant  :: 3377\n",
      "daddi  :: 3378\n",
      "immigr  :: 3379\n",
      "cd  :: 3380\n",
      "neglect  :: 3381\n",
      "echo  :: 3382\n",
      "2nd  :: 3383\n",
      "wealth  :: 3384\n",
      "cuba  :: 3385\n",
      "characterist  :: 3386\n",
      "acknowledg  :: 3387\n",
      "timon  :: 3388\n",
      "mall  :: 3389\n",
      "humili  :: 3390\n",
      "lit  :: 3391\n",
      "hart  :: 3392\n",
      "cari  :: 3393\n",
      "trail  :: 3394\n",
      "tiger  :: 3395\n",
      "nearbi  :: 3396\n",
      "versu  :: 3397\n",
      "poetic  :: 3398\n",
      "elimin  :: 3399\n",
      "imperson  :: 3400\n",
      "marshal  :: 3401\n",
      "repuls  :: 3402\n",
      "jeffrey  :: 3403\n",
      "domest  :: 3404\n",
      "celluloid  :: 3405\n",
      "mickey  :: 3406\n",
      "homer  :: 3407\n",
      "saga  :: 3408\n",
      "infect  :: 3409\n",
      "paus  :: 3410\n",
      "prejudic  :: 3411\n",
      "mistaken  :: 3412\n",
      "collaps  :: 3413\n",
      "solo  :: 3414\n",
      "pun  :: 3415\n",
      "cake  :: 3416\n",
      "inan  :: 3417\n",
      "ginger  :: 3418\n",
      "hbo  :: 3419\n",
      "assembl  :: 3420\n",
      "leon  :: 3421\n",
      "harvey  :: 3422\n",
      "apolog  :: 3423\n",
      "milk  :: 3424\n",
      "sore  :: 3425\n",
      "interrupt  :: 3426\n",
      "undoubtedli  :: 3427\n",
      "olivi  :: 3428\n",
      "equip  :: 3429\n",
      "coat  :: 3430\n",
      "pant  :: 3431\n",
      "promin  :: 3432\n",
      "chest  :: 3433\n",
      "inappropri  :: 3434\n",
      "tribe  :: 3435\n",
      "1996  :: 3436\n",
      "coffe  :: 3437\n",
      "gear  :: 3438\n",
      "polanski  :: 3439\n",
      "retain  :: 3440\n",
      "exot  :: 3441\n",
      "primari  :: 3442\n",
      "furthermor  :: 3443\n",
      "trace  :: 3444\n",
      "instant  :: 3445\n",
      "airplan  :: 3446\n",
      "devast  :: 3447\n",
      "brooklyn  :: 3448\n",
      "highest  :: 3449\n",
      "institut  :: 3450\n",
      "jenni  :: 3451\n",
      "colleagu  :: 3452\n",
      "aveng  :: 3453\n",
      "pen  :: 3454\n",
      "pot  :: 3455\n",
      "humbl  :: 3456\n",
      "colonel  :: 3457\n",
      "embrac  :: 3458\n",
      "maggi  :: 3459\n",
      "vulgar  :: 3460\n",
      "florida  :: 3461\n",
      "consum  :: 3462\n",
      "solut  :: 3463\n",
      "gender  :: 3464\n",
      "dian  :: 3465\n",
      "poke  :: 3466\n",
      "rick  :: 3467\n",
      "dutch  :: 3468\n",
      "1999  :: 3469\n",
      "wive  :: 3470\n",
      "cope  :: 3471\n",
      "strain  :: 3472\n",
      "smaller  :: 3473\n",
      "outer  :: 3474\n",
      "ya  :: 3475\n",
      "bowl  :: 3476\n",
      "3rd  :: 3477\n",
      "principl  :: 3478\n",
      "disabl  :: 3479\n",
      "linda  :: 3480\n",
      "godzilla  :: 3481\n",
      "seduct  :: 3482\n",
      "illog  :: 3483\n",
      "sale  :: 3484\n",
      "descend  :: 3485\n",
      "lol  :: 3486\n",
      "scope  :: 3487\n",
      "cue  :: 3488\n",
      "dive  :: 3489\n",
      "predecessor  :: 3490\n",
      "devoid  :: 3491\n",
      "rabbit  :: 3492\n",
      "yard  :: 3493\n",
      "vast  :: 3494\n",
      "bubbl  :: 3495\n",
      "secondli  :: 3496\n",
      "blatant  :: 3497\n",
      "beneath  :: 3498\n",
      "hal  :: 3499\n",
      "inferior  :: 3500\n",
      "gloriou  :: 3501\n",
      "mixtur  :: 3502\n",
      "gundam  :: 3503\n",
      "dud  :: 3504\n",
      "primarili  :: 3505\n",
      "glamor  :: 3506\n",
      "z  :: 3507\n",
      "shelf  :: 3508\n",
      "myer  :: 3509\n",
      "shirley  :: 3510\n",
      "pearl  :: 3511\n",
      "disjoint  :: 3512\n",
      "countrysid  :: 3513\n",
      "alfr  :: 3514\n",
      "hideou  :: 3515\n",
      "arab  :: 3516\n",
      "casual  :: 3517\n",
      "grinch  :: 3518\n",
      "breed  :: 3519\n",
      "domino  :: 3520\n",
      "garbo  :: 3521\n",
      "talki  :: 3522\n",
      "museum  :: 3523\n",
      "trademark  :: 3524\n",
      "aggress  :: 3525\n",
      "streep  :: 3526\n",
      "simplist  :: 3527\n",
      "invas  :: 3528\n",
      "et  :: 3529\n",
      "alert  :: 3530\n",
      "senseless  :: 3531\n",
      "april  :: 3532\n",
      "hardcor  :: 3533\n",
      "illeg  :: 3534\n",
      "hopeless  :: 3535\n",
      "obtain  :: 3536\n",
      "slide  :: 3537\n",
      "loyal  :: 3538\n",
      "stellar  :: 3539\n",
      "uwe  :: 3540\n",
      "stack  :: 3541\n",
      "rendit  :: 3542\n",
      "applaud  :: 3543\n",
      "defens  :: 3544\n",
      "robinson  :: 3545\n",
      "mail  :: 3546\n",
      "oz  :: 3547\n",
      "unhappi  :: 3548\n",
      "experiment  :: 3549\n",
      "disgrac  :: 3550\n",
      "mayor  :: 3551\n",
      "robberi  :: 3552\n",
      "sh  :: 3553\n",
      "stir  :: 3554\n",
      "vanish  :: 3555\n",
      "boom  :: 3556\n",
      "khan  :: 3557\n",
      "maci  :: 3558\n",
      "acid  :: 3559\n",
      "blew  :: 3560\n",
      "dicken  :: 3561\n",
      "tenant  :: 3562\n",
      "recruit  :: 3563\n",
      "berlin  :: 3564\n",
      "scroog  :: 3565\n",
      "spider  :: 3566\n",
      "craze  :: 3567\n",
      "emphasi  :: 3568\n",
      "amanda  :: 3569\n",
      "rifl  :: 3570\n",
      "grandfath  :: 3571\n",
      "span  :: 3572\n",
      "dismiss  :: 3573\n",
      "hartley  :: 3574\n",
      "soccer  :: 3575\n",
      "psychic  :: 3576\n",
      "topless  :: 3577\n",
      "tempt  :: 3578\n",
      "wont  :: 3579\n",
      "declin  :: 3580\n",
      "counter  :: 3581\n",
      "fri  :: 3582\n",
      "diana  :: 3583\n",
      "incomprehens  :: 3584\n",
      "trashi  :: 3585\n",
      "bitch  :: 3586\n",
      "ethnic  :: 3587\n",
      "resurrect  :: 3588\n",
      "wet  :: 3589\n",
      "niro  :: 3590\n",
      "justin  :: 3591\n",
      "parad  :: 3592\n",
      "lumet  :: 3593\n",
      "ration  :: 3594\n",
      "sympath  :: 3595\n",
      "shed  :: 3596\n",
      "woo  :: 3597\n",
      "sibl  :: 3598\n",
      "shaw  :: 3599\n",
      "faster  :: 3600\n",
      "porno  :: 3601\n",
      "intim  :: 3602\n",
      "revolt  :: 3603\n",
      "goer  :: 3604\n",
      "riot  :: 3605\n",
      "farmer  :: 3606\n",
      "mario  :: 3607\n",
      "00  :: 3608\n",
      "dealer  :: 3609\n",
      "lena  :: 3610\n",
      "partial  :: 3611\n",
      "jonathan  :: 3612\n",
      "slick  :: 3613\n",
      "andr  :: 3614\n",
      "hopper  :: 3615\n",
      "steam  :: 3616\n",
      "choru  :: 3617\n",
      "ensur  :: 3618\n",
      "gap  :: 3619\n",
      "hesit  :: 3620\n",
      "enlighten  :: 3621\n",
      "commend  :: 3622\n",
      "rider  :: 3623\n",
      "ballet  :: 3624\n",
      "patriot  :: 3625\n",
      "biographi  :: 3626\n",
      "nephew  :: 3627\n",
      "wheel  :: 3628\n",
      "unreal  :: 3629\n",
      "wendi  :: 3630\n",
      "eager  :: 3631\n",
      "weakest  :: 3632\n",
      "region  :: 3633\n",
      "feminist  :: 3634\n",
      "honesti  :: 3635\n",
      "immort  :: 3636\n",
      "worm  :: 3637\n",
      "nostalg  :: 3638\n",
      "franco  :: 3639\n",
      "snap  :: 3640\n",
      "prequel  :: 3641\n",
      "mutant  :: 3642\n",
      "owen  :: 3643\n",
      "similarli  :: 3644\n",
      "confin  :: 3645\n",
      "leo  :: 3646\n",
      "skull  :: 3647\n",
      "util  :: 3648\n",
      "sandra  :: 3649\n",
      "hung  :: 3650\n",
      "morri  :: 3651\n",
      "charlott  :: 3652\n",
      "kingdom  :: 3653\n",
      "blunt  :: 3654\n",
      "psychopath  :: 3655\n",
      "vice  :: 3656\n",
      "safeti  :: 3657\n",
      "macarthur  :: 3658\n",
      "repress  :: 3659\n",
      "properti  :: 3660\n",
      "victori  :: 3661\n",
      "wore  :: 3662\n",
      "composit  :: 3663\n",
      "sappi  :: 3664\n",
      "montana  :: 3665\n",
      "nervou  :: 3666\n",
      "heartbreak  :: 3667\n",
      "emperor  :: 3668\n",
      "1972  :: 3669\n",
      "recycl  :: 3670\n",
      "cg  :: 3671\n",
      "acquir  :: 3672\n",
      "bow  :: 3673\n",
      "farrel  :: 3674\n",
      "bumbl  :: 3675\n",
      "snl  :: 3676\n",
      "bergman  :: 3677\n",
      "speci  :: 3678\n",
      "dust  :: 3679\n",
      "thru  :: 3680\n",
      "tail  :: 3681\n",
      "whoopi  :: 3682\n",
      "repli  :: 3683\n",
      "pattern  :: 3684\n",
      "rocki  :: 3685\n",
      "rope  :: 3686\n",
      "rambl  :: 3687\n",
      "drain  :: 3688\n",
      "del  :: 3689\n",
      "campbel  :: 3690\n",
      "compens  :: 3691\n",
      "despair  :: 3692\n",
      "drum  :: 3693\n",
      "exit  :: 3694\n",
      "deed  :: 3695\n",
      "compass  :: 3696\n",
      "strand  :: 3697\n",
      "miseri  :: 3698\n",
      "tad  :: 3699\n",
      "latin  :: 3700\n",
      "bonu  :: 3701\n",
      "dalton  :: 3702\n",
      "kyle  :: 3703\n",
      "valuabl  :: 3704\n",
      "hyde  :: 3705\n",
      "da  :: 3706\n",
      "orson  :: 3707\n",
      "radic  :: 3708\n",
      "wacki  :: 3709\n",
      "slug  :: 3710\n",
      "carradin  :: 3711\n",
      "airport  :: 3712\n",
      "martian  :: 3713\n",
      "35  :: 3714\n",
      "roth  :: 3715\n",
      "percept  :: 3716\n",
      "chess  :: 3717\n",
      "olli  :: 3718\n",
      "pour  :: 3719\n",
      "mistress  :: 3720\n",
      "downhil  :: 3721\n",
      "gimmick  :: 3722\n",
      "contempl  :: 3723\n",
      "romp  :: 3724\n",
      "gal  :: 3725\n",
      "oppress  :: 3726\n",
      "rotten  :: 3727\n",
      "bleed  :: 3728\n",
      "tonight  :: 3729\n",
      "rapist  :: 3730\n",
      "champion  :: 3731\n",
      "1983  :: 3732\n",
      "stilt  :: 3733\n",
      "unpredict  :: 3734\n",
      "shelley  :: 3735\n",
      "tackl  :: 3736\n",
      "banal  :: 3737\n",
      "attorney  :: 3738\n",
      "preach  :: 3739\n",
      "belt  :: 3740\n",
      "pursuit  :: 3741\n",
      "programm  :: 3742\n",
      "pervert  :: 3743\n",
      "arc  :: 3744\n",
      "pervers  :: 3745\n",
      "tooth  :: 3746\n",
      "arguabl  :: 3747\n",
      "dazzl  :: 3748\n",
      "edgar  :: 3749\n",
      "melodi  :: 3750\n",
      "taught  :: 3751\n",
      "heal  :: 3752\n",
      "paltrow  :: 3753\n",
      "mislead  :: 3754\n",
      "slash  :: 3755\n",
      "rubi  :: 3756\n",
      "bela  :: 3757\n",
      "poem  :: 3758\n",
      "orang  :: 3759\n",
      "virginia  :: 3760\n",
      "vengeanc  :: 3761\n",
      "mesmer  :: 3762\n",
      "dixon  :: 3763\n",
      "sensat  :: 3764\n",
      "employe  :: 3765\n",
      "graham  :: 3766\n",
      "chicken  :: 3767\n",
      "duval  :: 3768\n",
      "closest  :: 3769\n",
      "franki  :: 3770\n",
      "cleverli  :: 3771\n",
      "marti  :: 3772\n",
      "gambl  :: 3773\n",
      "passeng  :: 3774\n",
      "tiresom  :: 3775\n",
      "plight  :: 3776\n",
      "uplift  :: 3777\n",
      "maid  :: 3778\n",
      "vocal  :: 3779\n",
      "raymond  :: 3780\n",
      "conneri  :: 3781\n",
      "outing  :: 3782\n",
      "abraham  :: 3783\n",
      "bay  :: 3784\n",
      "mute  :: 3785\n",
      "calm  :: 3786\n",
      "tube  :: 3787\n",
      "extens  :: 3788\n",
      "climact  :: 3789\n",
      "numb  :: 3790\n",
      "quarter  :: 3791\n",
      "habit  :: 3792\n",
      "secretli  :: 3793\n",
      "profan  :: 3794\n",
      "monologu  :: 3795\n",
      "inject  :: 3796\n",
      "gerard  :: 3797\n",
      "amitabh  :: 3798\n",
      "whine  :: 3799\n",
      "yawn  :: 3800\n",
      "clone  :: 3801\n",
      "iran  :: 3802\n",
      "scottish  :: 3803\n",
      "suffic  :: 3804\n",
      "lundgren  :: 3805\n",
      "sirk  :: 3806\n",
      "giggl  :: 3807\n",
      "convincingli  :: 3808\n",
      "swallow  :: 3809\n",
      "pokemon  :: 3810\n",
      "paranoia  :: 3811\n",
      "1968  :: 3812\n",
      "engross  :: 3813\n",
      "volum  :: 3814\n",
      "crystal  :: 3815\n",
      "plod  :: 3816\n",
      "expand  :: 3817\n",
      "backward  :: 3818\n",
      "chicago  :: 3819\n",
      "ethan  :: 3820\n",
      "septemb  :: 3821\n",
      "spock  :: 3822\n",
      "nichola  :: 3823\n",
      "fed  :: 3824\n",
      "surpass  :: 3825\n",
      "grotesqu  :: 3826\n",
      "abort  :: 3827\n",
      "austen  :: 3828\n",
      "dispos  :: 3829\n",
      "richardson  :: 3830\n",
      "profess  :: 3831\n",
      "taxi  :: 3832\n",
      "junior  :: 3833\n",
      "franci  :: 3834\n",
      "poetri  :: 3835\n",
      "meander  :: 3836\n",
      "linger  :: 3837\n",
      "frankenstein  :: 3838\n",
      "earl  :: 3839\n",
      "trend  :: 3840\n",
      "lowest  :: 3841\n",
      "underst  :: 3842\n",
      "bend  :: 3843\n",
      "im  :: 3844\n",
      "myth  :: 3845\n",
      "literatur  :: 3846\n",
      "der  :: 3847\n",
      "spoke  :: 3848\n",
      "tourist  :: 3849\n",
      "dysfunct  :: 3850\n",
      "compliment  :: 3851\n",
      "catchi  :: 3852\n",
      "lure  :: 3853\n",
      "hum  :: 3854\n",
      "household  :: 3855\n",
      "rant  :: 3856\n",
      "greedi  :: 3857\n",
      "rubber  :: 3858\n",
      "sue  :: 3859\n",
      "descent  :: 3860\n",
      "instrument  :: 3861\n",
      "stallon  :: 3862\n",
      "muddl  :: 3863\n",
      "nostalgia  :: 3864\n",
      "waitress  :: 3865\n",
      "simplic  :: 3866\n",
      "econom  :: 3867\n",
      "cannon  :: 3868\n",
      "eugen  :: 3869\n",
      "mundan  :: 3870\n",
      "eaten  :: 3871\n",
      "map  :: 3872\n",
      "alongsid  :: 3873\n",
      "bacal  :: 3874\n",
      "equival  :: 3875\n",
      "lang  :: 3876\n",
      "sissi  :: 3877\n",
      "dement  :: 3878\n",
      "coast  :: 3879\n",
      "deaf  :: 3880\n",
      "mortal  :: 3881\n",
      "carel  :: 3882\n",
      "recognis  :: 3883\n",
      "dictat  :: 3884\n",
      "louis  :: 3885\n",
      "furi  :: 3886\n",
      "phantom  :: 3887\n",
      "duck  :: 3888\n",
      "occupi  :: 3889\n",
      "flee  :: 3890\n",
      "recognit  :: 3891\n",
      "hello  :: 3892\n",
      "damon  :: 3893\n",
      "crucial  :: 3894\n",
      "firstli  :: 3895\n",
      "mankind  :: 3896\n",
      "insur  :: 3897\n",
      "cent  :: 3898\n",
      "randi  :: 3899\n",
      "stale  :: 3900\n",
      "irrelev  :: 3901\n",
      "molli  :: 3902\n",
      "june  :: 3903\n",
      "phoni  :: 3904\n",
      "omen  :: 3905\n",
      "labor  :: 3906\n",
      "1973  :: 3907\n",
      "distinguish  :: 3908\n",
      "cyborg  :: 3909\n",
      "twilight  :: 3910\n",
      "grayson  :: 3911\n",
      "newli  :: 3912\n",
      "freez  :: 3913\n",
      "antwon  :: 3914\n",
      "bike  :: 3915\n",
      "lengthi  :: 3916\n",
      "blackmail  :: 3917\n",
      "wisdom  :: 3918\n",
      "daisi  :: 3919\n",
      "onlin  :: 3920\n",
      "drake  :: 3921\n",
      "buffalo  :: 3922\n",
      "rooney  :: 3923\n",
      "dreari  :: 3924\n",
      "rude  :: 3925\n",
      "heel  :: 3926\n",
      "biko  :: 3927\n",
      "bump  :: 3928\n",
      "reign  :: 3929\n",
      "likewis  :: 3930\n",
      "loyalti  :: 3931\n",
      "damm  :: 3932\n",
      "ashley  :: 3933\n",
      "baddi  :: 3934\n",
      "chronicl  :: 3935\n",
      "worn  :: 3936\n",
      "basketbal  :: 3937\n",
      "butler  :: 3938\n",
      "tunnel  :: 3939\n",
      "vein  :: 3940\n",
      "startl  :: 3941\n",
      "provoc  :: 3942\n",
      "exposur  :: 3943\n",
      "sailor  :: 3944\n",
      "proce  :: 3945\n",
      "unorigin  :: 3946\n",
      "attribut  :: 3947\n",
      "inher  :: 3948\n",
      "keith  :: 3949\n",
      "prey  :: 3950\n",
      "analysi  :: 3951\n",
      "pink  :: 3952\n",
      "nineti  :: 3953\n",
      "interior  :: 3954\n",
      "incorpor  :: 3955\n",
      "approv  :: 3956\n",
      "boxer  :: 3957\n",
      "barrymor  :: 3958\n",
      "ridden  :: 3959\n",
      "emphas  :: 3960\n",
      "unrel  :: 3961\n",
      "meg  :: 3962\n",
      "drift  :: 3963\n",
      "carla  :: 3964\n",
      "improvis  :: 3965\n",
      "fleet  :: 3966\n",
      "degrad  :: 3967\n",
      "bunni  :: 3968\n",
      "mighti  :: 3969\n",
      "simmon  :: 3970\n",
      "belushi  :: 3971\n",
      "hypnot  :: 3972\n",
      "mormon  :: 3973\n",
      "millionair  :: 3974\n",
      "othello  :: 3975\n",
      "julian  :: 3976\n",
      "walsh  :: 3977\n",
      "elm  :: 3978\n",
      "meyer  :: 3979\n",
      "underli  :: 3980\n",
      "robbin  :: 3981\n",
      "er  :: 3982\n",
      "condemn  :: 3983\n",
      "substitut  :: 3984\n",
      "stalker  :: 3985\n",
      "nicol  :: 3986\n",
      "indiffer  :: 3987\n",
      "undeni  :: 3988\n",
      "barrel  :: 3989\n",
      "predat  :: 3990\n",
      "priceless  :: 3991\n",
      "mtv  :: 3992\n",
      "hay  :: 3993\n",
      "disord  :: 3994\n",
      "dolph  :: 3995\n",
      "novak  :: 3996\n",
      "alison  :: 3997\n",
      "agenda  :: 3998\n",
      "edgi  :: 3999\n",
      "alarm  :: 4000\n",
      "warmth  :: 4001\n",
      "exquisit  :: 4002\n",
      "firm  :: 4003\n",
      "errol  :: 4004\n",
      "roof  :: 4005\n",
      "lampoon  :: 4006\n",
      "enthusiasm  :: 4007\n",
      "shove  :: 4008\n",
      "3d  :: 4009\n",
      "greed  :: 4010\n",
      "nyc  :: 4011\n",
      "unawar  :: 4012\n",
      "palac  :: 4013\n",
      "marion  :: 4014\n",
      "vital  :: 4015\n",
      "reid  :: 4016\n",
      "watson  :: 4017\n",
      "rukh  :: 4018\n",
      "iraq  :: 4019\n",
      "zizek  :: 4020\n",
      "13th  :: 4021\n",
      "beatl  :: 4022\n",
      "distort  :: 4023\n",
      "randomli  :: 4024\n",
      "coup  :: 4025\n",
      "testament  :: 4026\n",
      "drip  :: 4027\n",
      "gestur  :: 4028\n",
      "pamela  :: 4029\n",
      "cassidi  :: 4030\n",
      "petti  :: 4031\n",
      "glanc  :: 4032\n",
      "showdown  :: 4033\n",
      "sergeant  :: 4034\n",
      "profit  :: 4035\n",
      "nun  :: 4036\n",
      "orlean  :: 4037\n",
      "simultan  :: 4038\n",
      "1933  :: 4039\n",
      "crown  :: 4040\n",
      "session  :: 4041\n",
      "thompson  :: 4042\n",
      "championship  :: 4043\n",
      "ponder  :: 4044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum  :: 4045\n",
      "angela  :: 4046\n",
      "peck  :: 4047\n",
      "israel  :: 4048\n",
      "spain  :: 4049\n",
      "peril  :: 4050\n",
      "campaign  :: 4051\n",
      "what  :: 4052\n",
      "eastern  :: 4053\n",
      "unleash  :: 4054\n",
      "valentin  :: 4055\n",
      "preserv  :: 4056\n",
      "regist  :: 4057\n",
      "mon  :: 4058\n",
      "valley  :: 4059\n",
      "represent  :: 4060\n",
      "scotland  :: 4061\n",
      "calib  :: 4062\n",
      "stroke  :: 4063\n",
      "din  :: 4064\n",
      "perpetu  :: 4065\n",
      "fido  :: 4066\n",
      "crawl  :: 4067\n",
      "wig  :: 4068\n",
      "restrain  :: 4069\n",
      "rout  :: 4070\n",
      "gentleman  :: 4071\n",
      "sabrina  :: 4072\n",
      "contradict  :: 4073\n",
      "han  :: 4074\n",
      "shootout  :: 4075\n",
      "bro  :: 4076\n",
      "buster  :: 4077\n",
      "quinn  :: 4078\n",
      "unimagin  :: 4079\n",
      "brenda  :: 4080\n",
      "cooki  :: 4081\n",
      "crow  :: 4082\n",
      "realm  :: 4083\n",
      "kurosawa  :: 4084\n",
      "miyazaki  :: 4085\n",
      "exposit  :: 4086\n",
      "travesti  :: 4087\n",
      "empathi  :: 4088\n",
      "reson  :: 4089\n",
      "stake  :: 4090\n",
      "climat  :: 4091\n",
      "1984  :: 4092\n",
      "jan  :: 4093\n",
      "cream  :: 4094\n",
      "ross  :: 4095\n",
      "fuller  :: 4096\n",
      "femm  :: 4097\n",
      "abomin  :: 4098\n",
      "geek  :: 4099\n",
      "josh  :: 4100\n",
      "businessman  :: 4101\n",
      "mclaglen  :: 4102\n",
      "distress  :: 4103\n",
      "cloud  :: 4104\n",
      "passabl  :: 4105\n",
      "soderbergh  :: 4106\n",
      "delic  :: 4107\n",
      "wax  :: 4108\n",
      "compromis  :: 4109\n",
      "sammi  :: 4110\n",
      "absent  :: 4111\n",
      "traumat  :: 4112\n",
      "monoton  :: 4113\n",
      "warrant  :: 4114\n",
      "unsatisfi  :: 4115\n",
      "ustinov  :: 4116\n",
      "greg  :: 4117\n",
      "crawford  :: 4118\n",
      "shoddi  :: 4119\n",
      "pole  :: 4120\n",
      "demis  :: 4121\n",
      "censor  :: 4122\n",
      "painter  :: 4123\n",
      "spacey  :: 4124\n",
      "tacki  :: 4125\n",
      "stargat  :: 4126\n",
      "1997  :: 4127\n",
      "dana  :: 4128\n",
      "pretens  :: 4129\n",
      "shaki  :: 4130\n",
      "meryl  :: 4131\n",
      "sucker  :: 4132\n",
      "baldwin  :: 4133\n",
      "unseen  :: 4134\n",
      "derang  :: 4135\n",
      "darren  :: 4136\n",
      "1987  :: 4137\n",
      "perceiv  :: 4138\n",
      "polici  :: 4139\n",
      "tarantino  :: 4140\n",
      "valid  :: 4141\n",
      "click  :: 4142\n",
      "austin  :: 4143\n",
      "verbal  :: 4144\n",
      "antonioni  :: 4145\n",
      "nathan  :: 4146\n",
      "kumar  :: 4147\n",
      "reluct  :: 4148\n",
      "jewel  :: 4149\n",
      "seal  :: 4150\n",
      "sid  :: 4151\n",
      "furiou  :: 4152\n",
      "correctli  :: 4153\n",
      "fog  :: 4154\n",
      "deniro  :: 4155\n",
      "dee  :: 4156\n",
      "deceas  :: 4157\n",
      "fenc  :: 4158\n",
      "judgment  :: 4159\n",
      "uncov  :: 4160\n",
      "clash  :: 4161\n",
      "accuraci  :: 4162\n",
      "anchor  :: 4163\n",
      "unravel  :: 4164\n",
      "expedit  :: 4165\n",
      "tech  :: 4166\n",
      "wholli  :: 4167\n",
      "1993  :: 4168\n",
      "primit  :: 4169\n",
      "norm  :: 4170\n",
      "exclus  :: 4171\n",
      "seldom  :: 4172\n",
      "crippl  :: 4173\n",
      "fabric  :: 4174\n",
      "alec  :: 4175\n",
      "tax  :: 4176\n",
      "debt  :: 4177\n",
      "behold  :: 4178\n",
      "wretch  :: 4179\n",
      "logan  :: 4180\n",
      "bake  :: 4181\n",
      "dreck  :: 4182\n",
      "pocket  :: 4183\n",
      "joel  :: 4184\n",
      "sheet  :: 4185\n",
      "darn  :: 4186\n",
      "wang  :: 4187\n",
      "nicola  :: 4188\n",
      "enforc  :: 4189\n",
      "malon  :: 4190\n",
      "vanc  :: 4191\n",
      "hallucin  :: 4192\n",
      "trait  :: 4193\n",
      "1971  :: 4194\n",
      "temper  :: 4195\n",
      "mode  :: 4196\n",
      "roller  :: 4197\n",
      "patienc  :: 4198\n",
      "ritual  :: 4199\n",
      "1995  :: 4200\n",
      "conduct  :: 4201\n",
      "fart  :: 4202\n",
      "unfair  :: 4203\n",
      "fought  :: 4204\n",
      "slam  :: 4205\n",
      "shanghai  :: 4206\n",
      "sustain  :: 4207\n",
      "murray  :: 4208\n",
      "sunni  :: 4209\n",
      "3000  :: 4210\n",
      "sand  :: 4211\n",
      "2008  :: 4212\n",
      "clerk  :: 4213\n",
      "sweep  :: 4214\n",
      "exhaust  :: 4215\n",
      "conscious  :: 4216\n",
      "helpless  :: 4217\n",
      "pete  :: 4218\n",
      "stuart  :: 4219\n",
      "technicolor  :: 4220\n",
      "robber  :: 4221\n",
      "isabel  :: 4222\n",
      "soup  :: 4223\n",
      "preposter  :: 4224\n",
      "schedul  :: 4225\n",
      "divid  :: 4226\n",
      "penni  :: 4227\n",
      "shell  :: 4228\n",
      "critiqu  :: 4229\n",
      "squad  :: 4230\n",
      "guitar  :: 4231\n",
      "grief  :: 4232\n",
      "bias  :: 4233\n",
      "clau  :: 4234\n",
      "outlin  :: 4235\n",
      "stark  :: 4236\n",
      "legaci  :: 4237\n",
      "rita  :: 4238\n",
      "runner  :: 4239\n",
      "bridget  :: 4240\n",
      "preston  :: 4241\n",
      "scriptwrit  :: 4242\n",
      "tactic  :: 4243\n",
      "canyon  :: 4244\n",
      "fundament  :: 4245\n",
      "despis  :: 4246\n",
      "phil  :: 4247\n",
      "unexpectedli  :: 4248\n",
      "boyl  :: 4249\n",
      "alicia  :: 4250\n",
      "flair  :: 4251\n",
      "alley  :: 4252\n",
      "lacklust  :: 4253\n",
      "marc  :: 4254\n",
      "kansa  :: 4255\n",
      "drove  :: 4256\n",
      "jodi  :: 4257\n",
      "culmin  :: 4258\n",
      "connor  :: 4259\n",
      "rehash  :: 4260\n",
      "consciou  :: 4261\n",
      "gregori  :: 4262\n",
      "sugar  :: 4263\n",
      "restrict  :: 4264\n",
      "palanc  :: 4265\n",
      "downey  :: 4266\n",
      "inabl  :: 4267\n",
      "agenc  :: 4268\n",
      "cigarett  :: 4269\n",
      "sniper  :: 4270\n",
      "implic  :: 4271\n",
      "bloom  :: 4272\n",
      "liberti  :: 4273\n",
      "sentinel  :: 4274\n",
      "rear  :: 4275\n",
      "russia  :: 4276\n",
      "vomit  :: 4277\n",
      "invad  :: 4278\n",
      "jacket  :: 4279\n",
      "propos  :: 4280\n",
      "delv  :: 4281\n",
      "passag  :: 4282\n",
      "newman  :: 4283\n",
      "cap  :: 4284\n",
      "sharon  :: 4285\n",
      "rampag  :: 4286\n",
      "improb  :: 4287\n",
      "rod  :: 4288\n",
      "chainsaw  :: 4289\n",
      "horn  :: 4290\n",
      "asylum  :: 4291\n",
      "feat  :: 4292\n",
      "delet  :: 4293\n",
      "22  :: 4294\n",
      "pale  :: 4295\n",
      "wrench  :: 4296\n",
      "awhil  :: 4297\n",
      "aesthet  :: 4298\n",
      "lush  :: 4299\n",
      "tendenc  :: 4300\n",
      "yeti  :: 4301\n",
      "1936  :: 4302\n",
      "ladder  :: 4303\n",
      "mccoy  :: 4304\n",
      "vet  :: 4305\n",
      "kolchak  :: 4306\n",
      "behaviour  :: 4307\n",
      "bacon  :: 4308\n",
      "tripe  :: 4309\n",
      "karl  :: 4310\n",
      "foxx  :: 4311\n",
      "rehears  :: 4312\n",
      "arrow  :: 4313\n",
      "1978  :: 4314\n",
      "paradis  :: 4315\n",
      "wildli  :: 4316\n",
      "scoop  :: 4317\n",
      "fright  :: 4318\n",
      "tasteless  :: 4319\n",
      "hungri  :: 4320\n",
      "minu  :: 4321\n",
      "weav  :: 4322\n",
      "thunderbird  :: 4323\n",
      "rhythm  :: 4324\n",
      "sung  :: 4325\n",
      "stream  :: 4326\n",
      "amazon  :: 4327\n",
      "suffici  :: 4328\n",
      "hackney  :: 4329\n",
      "prank  :: 4330\n",
      "19th  :: 4331\n",
      "paramount  :: 4332\n",
      "elit  :: 4333\n",
      "coaster  :: 4334\n",
      "visitor  :: 4335\n",
      "tomorrow  :: 4336\n",
      "aristocrat  :: 4337\n",
      "1988  :: 4338\n",
      "wagner  :: 4339\n",
      "hulk  :: 4340\n",
      "spice  :: 4341\n",
      "loneli  :: 4342\n",
      "el  :: 4343\n",
      "underneath  :: 4344\n",
      "filler  :: 4345\n",
      "1920  :: 4346\n",
      "lurk  :: 4347\n",
      "rumor  :: 4348\n",
      "conscienc  :: 4349\n",
      "shortcom  :: 4350\n",
      "basing  :: 4351\n",
      "globe  :: 4352\n",
      "financ  :: 4353\n",
      "newcom  :: 4354\n",
      "suspicion  :: 4355\n",
      "choppi  :: 4356\n",
      "teas  :: 4357\n",
      "worship  :: 4358\n",
      "leigh  :: 4359\n",
      "ram  :: 4360\n",
      "impos  :: 4361\n",
      "immers  :: 4362\n",
      "naughti  :: 4363\n",
      "couch  :: 4364\n",
      "paxton  :: 4365\n",
      "atroc  :: 4366\n",
      "tierney  :: 4367\n",
      "wwe  :: 4368\n",
      "en  :: 4369\n",
      "counterpart  :: 4370\n",
      "brit  :: 4371\n",
      "heist  :: 4372\n",
      "iv  :: 4373\n",
      "straightforward  :: 4374\n",
      "inmat  :: 4375\n",
      "dirt  :: 4376\n",
      "cancer  :: 4377\n",
      "beverli  :: 4378\n",
      "rub  :: 4379\n",
      "curli  :: 4380\n",
      "ingeni  :: 4381\n",
      "springer  :: 4382\n",
      "entranc  :: 4383\n",
      "grudg  :: 4384\n",
      "recogniz  :: 4385\n",
      "75  :: 4386\n",
      "quietli  :: 4387\n",
      "1939  :: 4388\n",
      "chavez  :: 4389\n",
      "penn  :: 4390\n",
      "abrupt  :: 4391\n",
      "chamberlain  :: 4392\n",
      "1989  :: 4393\n",
      "bread  :: 4394\n",
      "secondari  :: 4395\n",
      "lectur  :: 4396\n",
      "literari  :: 4397\n",
      "smell  :: 4398\n",
      "posey  :: 4399\n",
      "minist  :: 4400\n",
      "hopkin  :: 4401\n",
      "standout  :: 4402\n",
      "bernard  :: 4403\n",
      "net  :: 4404\n",
      "ratso  :: 4405\n",
      "1986  :: 4406\n",
      "geni  :: 4407\n",
      "variat  :: 4408\n",
      "esther  :: 4409\n",
      "morbid  :: 4410\n",
      "sublim  :: 4411\n",
      "misguid  :: 4412\n",
      "enthral  :: 4413\n",
      "skeptic  :: 4414\n",
      "laurenc  :: 4415\n",
      "heartfelt  :: 4416\n",
      "injuri  :: 4417\n",
      "missil  :: 4418\n",
      "duel  :: 4419\n",
      "yearn  :: 4420\n",
      "lindsay  :: 4421\n",
      "clan  :: 4422\n",
      "watcher  :: 4423\n",
      "convert  :: 4424\n",
      "cattl  :: 4425\n",
      "entitl  :: 4426\n",
      "nemesi  :: 4427\n",
      "attenborough  :: 4428\n",
      "ace  :: 4429\n",
      "sassi  :: 4430\n",
      "transcend  :: 4431\n",
      "nolan  :: 4432\n",
      "policeman  :: 4433\n",
      "moreov  :: 4434\n",
      "quaid  :: 4435\n",
      "buzz  :: 4436\n",
      "egg  :: 4437\n",
      "facil  :: 4438\n",
      "moder  :: 4439\n",
      "grin  :: 4440\n",
      "enabl  :: 4441\n",
      "uncut  :: 4442\n",
      "unexplain  :: 4443\n",
      "artsi  :: 4444\n",
      "1979  :: 4445\n",
      "graini  :: 4446\n",
      "youngest  :: 4447\n",
      "cruelti  :: 4448\n",
      "dont  :: 4449\n",
      "spiral  :: 4450\n",
      "carlito  :: 4451\n",
      "hopelessli  :: 4452\n",
      "steadi  :: 4453\n",
      "brood  :: 4454\n",
      "mytholog  :: 4455\n",
      "kidman  :: 4456\n",
      "bean  :: 4457\n",
      "hk  :: 4458\n",
      "tyler  :: 4459\n",
      "setup  :: 4460\n",
      "diari  :: 4461\n",
      "poe  :: 4462\n",
      "bye  :: 4463\n",
      "vader  :: 4464\n",
      "obstacl  :: 4465\n",
      "reliabl  :: 4466\n",
      "rosemari  :: 4467\n",
      "characteris  :: 4468\n",
      "puppi  :: 4469\n",
      "kitti  :: 4470\n",
      "out  :: 4471\n",
      "spontan  :: 4472\n",
      "decept  :: 4473\n",
      "disastr  :: 4474\n",
      "exterior  :: 4475\n",
      "athlet  :: 4476\n",
      "heap  :: 4477\n",
      "patricia  :: 4478\n",
      "underworld  :: 4479\n",
      "christin  :: 4480\n",
      "martha  :: 4481\n",
      "effici  :: 4482\n",
      "sweat  :: 4483\n",
      "hammi  :: 4484\n",
      "weather  :: 4485\n",
      "fuel  :: 4486\n",
      "1969  :: 4487\n",
      "narrow  :: 4488\n",
      "bewar  :: 4489\n",
      "oblig  :: 4490\n",
      "preming  :: 4491\n",
      "baffl  :: 4492\n",
      "gillian  :: 4493\n",
      "gina  :: 4494\n",
      "kline  :: 4495\n",
      "hain  :: 4496\n",
      "despic  :: 4497\n",
      "niec  :: 4498\n",
      "bronson  :: 4499\n",
      "clueless  :: 4500\n",
      "bounc  :: 4501\n",
      "brendan  :: 4502\n",
      "acquaint  :: 4503\n",
      "housewif  :: 4504\n",
      "astound  :: 4505\n",
      "sleepwalk  :: 4506\n",
      "mayhem  :: 4507\n",
      "shatter  :: 4508\n",
      "rome  :: 4509\n",
      "loi  :: 4510\n",
      "fontain  :: 4511\n",
      "analyz  :: 4512\n",
      "hepburn  :: 4513\n",
      "loath  :: 4514\n",
      "dilemma  :: 4515\n",
      "19  :: 4516\n",
      "circu  :: 4517\n",
      "scar  :: 4518\n",
      "trigger  :: 4519\n",
      "lester  :: 4520\n",
      "goof  :: 4521\n",
      "insipid  :: 4522\n",
      "mermaid  :: 4523\n",
      "angst  :: 4524\n",
      "biker  :: 4525\n",
      "candl  :: 4526\n",
      "dandi  :: 4527\n",
      "enlist  :: 4528\n",
      "tick  :: 4529\n",
      "sooner  :: 4530\n",
      "taboo  :: 4531\n",
      "injur  :: 4532\n",
      "harmless  :: 4533\n",
      "viewpoint  :: 4534\n",
      "renaiss  :: 4535\n",
      "suprem  :: 4536\n",
      "preachi  :: 4537\n",
      "outlaw  :: 4538\n",
      "headach  :: 4539\n",
      "virtu  :: 4540\n",
      "uh  :: 4541\n",
      "73  :: 4542\n",
      "contempt  :: 4543\n",
      "glorifi  :: 4544\n",
      "gere  :: 4545\n",
      "foolish  :: 4546\n",
      "phenomenon  :: 4547\n",
      "macho  :: 4548\n",
      "tripl  :: 4549\n",
      "immatur  :: 4550\n",
      "stimul  :: 4551\n",
      "corbett  :: 4552\n",
      "camcord  :: 4553\n",
      "intric  :: 4554\n",
      "idol  :: 4555\n",
      "amor  :: 4556\n",
      "whore  :: 4557\n",
      "overlong  :: 4558\n",
      "filth  :: 4559\n",
      "spade  :: 4560\n",
      "bent  :: 4561\n",
      "dismal  :: 4562\n",
      "dish  :: 4563\n",
      "boston  :: 4564\n",
      "surgeri  :: 4565\n",
      "scorses  :: 4566\n",
      "claustrophob  :: 4567\n",
      "steer  :: 4568\n",
      "sox  :: 4569\n",
      "hostag  :: 4570\n",
      "cassavet  :: 4571\n",
      "zoom  :: 4572\n",
      "ariel  :: 4573\n",
      "stair  :: 4574\n",
      "slimi  :: 4575\n",
      "ebert  :: 4576\n",
      "hooker  :: 4577\n",
      "fluff  :: 4578\n",
      "redund  :: 4579\n",
      "hokey  :: 4580\n",
      "guin  :: 4581\n",
      "oldest  :: 4582\n",
      "salt  :: 4583\n",
      "messi  :: 4584\n",
      "cush  :: 4585\n",
      "proport  :: 4586\n",
      "assert  :: 4587\n",
      "mutual  :: 4588\n",
      "spree  :: 4589\n",
      "shred  :: 4590\n",
      "zane  :: 4591\n",
      "1981  :: 4592\n",
      "1976  :: 4593\n",
      "spinal  :: 4594\n",
      "fascist  :: 4595\n",
      "trivia  :: 4596\n",
      "joker  :: 4597\n",
      "gabl  :: 4598\n",
      "dwarf  :: 4599\n",
      "obligatori  :: 4600\n",
      "schlock  :: 4601\n",
      "transplant  :: 4602\n",
      "naschi  :: 4603\n",
      "keen  :: 4604\n",
      "mount  :: 4605\n",
      "faint  :: 4606\n",
      "margin  :: 4607\n",
      "perman  :: 4608\n",
      "alvin  :: 4609\n",
      "astronaut  :: 4610\n",
      "muscl  :: 4611\n",
      "strongest  :: 4612\n",
      "conquer  :: 4613\n",
      "nolt  :: 4614\n",
      "gasp  :: 4615\n",
      "antagonist  :: 4616\n",
      "harold  :: 4617\n",
      "widescreen  :: 4618\n",
      "rhyme  :: 4619\n",
      "remad  :: 4620\n",
      "cow  :: 4621\n",
      "shield  :: 4622\n",
      "flirt  :: 4623\n",
      "frantic  :: 4624\n",
      "cohen  :: 4625\n",
      "radiat  :: 4626\n",
      "corman  :: 4627\n",
      "flag  :: 4628\n",
      "down  :: 4629\n",
      "flashi  :: 4630\n",
      "preced  :: 4631\n",
      "beard  :: 4632\n",
      "neurot  :: 4633\n",
      "95  :: 4634\n",
      "aborigin  :: 4635\n",
      "www  :: 4636\n",
      "instruct  :: 4637\n",
      "boob  :: 4638\n",
      "persuad  :: 4639\n",
      "strive  :: 4640\n",
      "mobil  :: 4641\n",
      "scandal  :: 4642\n",
      "resum  :: 4643\n",
      "barn  :: 4644\n",
      "hara  :: 4645\n",
      "raj  :: 4646\n",
      "bitten  :: 4647\n",
      "wield  :: 4648\n",
      "bachelor  :: 4649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info  :: 4650\n",
      "danish  :: 4651\n",
      "28  :: 4652\n",
      "inflict  :: 4653\n",
      "vaniti  :: 4654\n",
      "off  :: 4655\n",
      "divin  :: 4656\n",
      "triangl  :: 4657\n",
      "interestingli  :: 4658\n",
      "carey  :: 4659\n",
      "sensual  :: 4660\n",
      "ritchi  :: 4661\n",
      "departur  :: 4662\n",
      "claud  :: 4663\n",
      "repris  :: 4664\n",
      "archiv  :: 4665\n",
      "discern  :: 4666\n",
      "fishburn  :: 4667\n",
      "flock  :: 4668\n",
      "1945  :: 4669\n",
      "brush  :: 4670\n",
      "someday  :: 4671\n",
      "mol  :: 4672\n",
      "deer  :: 4673\n",
      "cb  :: 4674\n",
      "biblic  :: 4675\n",
      "heartwarm  :: 4676\n",
      "cycl  :: 4677\n",
      "mobster  :: 4678\n",
      "undermin  :: 4679\n",
      "europa  :: 4680\n",
      "submit  :: 4681\n",
      "proclaim  :: 4682\n",
      "clad  :: 4683\n",
      "loretta  :: 4684\n",
      "carlo  :: 4685\n",
      "pixar  :: 4686\n",
      "frontier  :: 4687\n",
      "banter  :: 4688\n",
      "artwork  :: 4689\n",
      "anton  :: 4690\n",
      "wendigo  :: 4691\n",
      "hug  :: 4692\n",
      "cher  :: 4693\n",
      "dim  :: 4694\n",
      "jade  :: 4695\n",
      "recit  :: 4696\n",
      "miracul  :: 4697\n",
      "harrison  :: 4698\n",
      "parson  :: 4699\n",
      "casino  :: 4700\n",
      "neill  :: 4701\n",
      "cliffhang  :: 4702\n",
      "timberlak  :: 4703\n",
      "pacif  :: 4704\n",
      "rot  :: 4705\n",
      "bate  :: 4706\n",
      "colin  :: 4707\n",
      "helm  :: 4708\n",
      "traffic  :: 4709\n",
      "kathryn  :: 4710\n",
      "melissa  :: 4711\n",
      "vibrant  :: 4712\n",
      "dame  :: 4713\n",
      "prophet  :: 4714\n",
      "hilar  :: 4715\n",
      "axe  :: 4716\n",
      "ish  :: 4717\n",
      "hapless  :: 4718\n",
      "luka  :: 4719\n",
      "pickford  :: 4720\n",
      "fragil  :: 4721\n",
      "earnest  :: 4722\n",
      "senior  :: 4723\n",
      "dylan  :: 4724\n",
      "lui  :: 4725\n",
      "orphan  :: 4726\n",
      "feast  :: 4727\n",
      "bondag  :: 4728\n",
      "misfortun  :: 4729\n",
      "http  :: 4730\n",
      "akin  :: 4731\n",
      "static  :: 4732\n",
      "illus  :: 4733\n",
      "foil  :: 4734\n",
      "legitim  :: 4735\n",
      "marlon  :: 4736\n",
      "redneck  :: 4737\n",
      "electron  :: 4738\n",
      "nope  :: 4739\n",
      "blatantli  :: 4740\n",
      "shepherd  :: 4741\n",
      "mason  :: 4742\n",
      "aris  :: 4743\n",
      "isra  :: 4744\n",
      "toronto  :: 4745\n",
      "northern  :: 4746\n",
      "holocaust  :: 4747\n",
      "flavor  :: 4748\n",
      "sicken  :: 4749\n",
      "jordan  :: 4750\n",
      "jo  :: 4751\n",
      "token  :: 4752\n",
      "pc  :: 4753\n",
      "mathieu  :: 4754\n",
      "milo  :: 4755\n",
      "winchest  :: 4756\n",
      "lucil  :: 4757\n",
      "vile  :: 4758\n",
      "razor  :: 4759\n",
      "trier  :: 4760\n",
      "bikini  :: 4761\n",
      "rooki  :: 4762\n",
      "seedi  :: 4763\n",
      "choke  :: 4764\n",
      "alexandr  :: 4765\n",
      "eli  :: 4766\n",
      "antholog  :: 4767\n",
      "breakfast  :: 4768\n",
      "venom  :: 4769\n",
      "estrang  :: 4770\n",
      "uma  :: 4771\n",
      "cerebr  :: 4772\n",
      "articl  :: 4773\n",
      "vanessa  :: 4774\n",
      "wardrob  :: 4775\n",
      "tack  :: 4776\n",
      "gilbert  :: 4777\n",
      "huston  :: 4778\n",
      "ceremoni  :: 4779\n",
      "boyer  :: 4780\n",
      "magician  :: 4781\n",
      "styliz  :: 4782\n",
      "swept  :: 4783\n",
      "dudley  :: 4784\n",
      "peer  :: 4785\n",
      "wrestler  :: 4786\n",
      "knightley  :: 4787\n",
      "gunga  :: 4788\n",
      "disregard  :: 4789\n",
      "cartoonish  :: 4790\n",
      "shorter  :: 4791\n",
      "nightclub  :: 4792\n",
      "glare  :: 4793\n",
      "turd  :: 4794\n",
      "howl  :: 4795\n",
      "clinic  :: 4796\n",
      "frog  :: 4797\n",
      "ideolog  :: 4798\n",
      "outdat  :: 4799\n",
      "charlton  :: 4800\n",
      "abund  :: 4801\n",
      "affleck  :: 4802\n",
      "psych  :: 4803\n",
      "highway  :: 4804\n",
      "retriev  :: 4805\n",
      "comprehend  :: 4806\n",
      "linear  :: 4807\n",
      "audrey  :: 4808\n",
      "fifth  :: 4809\n",
      "oppon  :: 4810\n",
      "feminin  :: 4811\n",
      "deem  :: 4812\n",
      "leather  :: 4813\n",
      "smack  :: 4814\n",
      "greet  :: 4815\n",
      "moe  :: 4816\n",
      "evolut  :: 4817\n",
      "cuban  :: 4818\n",
      "corn  :: 4819\n",
      "lifeless  :: 4820\n",
      "mitch  :: 4821\n",
      "lavish  :: 4822\n",
      "snatch  :: 4823\n",
      "durat  :: 4824\n",
      "sleaz  :: 4825\n",
      "bastard  :: 4826\n",
      "bogu  :: 4827\n",
      "lighter  :: 4828\n",
      "boo  :: 4829\n",
      "uniformli  :: 4830\n",
      "compris  :: 4831\n",
      "btw  :: 4832\n",
      "goldsworthi  :: 4833\n",
      "breakdown  :: 4834\n",
      "1994  :: 4835\n",
      "chip  :: 4836\n",
      "salman  :: 4837\n",
      "4th  :: 4838\n",
      "1991  :: 4839\n",
      "spawn  :: 4840\n",
      "summar  :: 4841\n",
      "collector  :: 4842\n",
      "einstein  :: 4843\n",
      "newer  :: 4844\n",
      "phenomen  :: 4845\n",
      "client  :: 4846\n",
      "conrad  :: 4847\n",
      "energet  :: 4848\n",
      "tara  :: 4849\n",
      "plate  :: 4850\n",
      "spine  :: 4851\n",
      "senat  :: 4852\n",
      "whack  :: 4853\n",
      "toe  :: 4854\n",
      "deliver  :: 4855\n",
      "potter  :: 4856\n",
      "monument  :: 4857\n",
      "cemeteri  :: 4858\n",
      "braveheart  :: 4859\n",
      "wtf  :: 4860\n",
      "occup  :: 4861\n",
      "inaccuraci  :: 4862\n",
      "jedi  :: 4863\n",
      "armstrong  :: 4864\n",
      "ie  :: 4865\n",
      "gilliam  :: 4866\n",
      "embark  :: 4867\n",
      "constitut  :: 4868\n",
      "sorrow  :: 4869\n",
      "appl  :: 4870\n",
      "luxuri  :: 4871\n",
      "bori  :: 4872\n",
      "neatli  :: 4873\n",
      "healthi  :: 4874\n",
      "jare  :: 4875\n",
      "capot  :: 4876\n",
      "undead  :: 4877\n",
      "liu  :: 4878\n",
      "1977  :: 4879\n",
      "jam  :: 4880\n",
      "outright  :: 4881\n",
      "replay  :: 4882\n",
      "clara  :: 4883\n",
      "pronounc  :: 4884\n",
      "firmli  :: 4885\n",
      "lex  :: 4886\n",
      "fluid  :: 4887\n",
      "alleg  :: 4888\n",
      "ol  :: 4889\n",
      "signal  :: 4890\n",
      "nina  :: 4891\n",
      "spectacl  :: 4892\n",
      "creek  :: 4893\n",
      "cecil  :: 4894\n",
      "judd  :: 4895\n",
      "1974  :: 4896\n",
      "mcqueen  :: 4897\n",
      "belli  :: 4898\n",
      "bulk  :: 4899\n",
      "evelyn  :: 4900\n",
      "jule  :: 4901\n",
      "historian  :: 4902\n",
      "kazan  :: 4903\n",
      "eleven  :: 4904\n",
      "kent  :: 4905\n",
      "undertak  :: 4906\n",
      "trauma  :: 4907\n",
      "randolph  :: 4908\n",
      "blur  :: 4909\n",
      "relentless  :: 4910\n",
      "comb  :: 4911\n",
      "basket  :: 4912\n",
      "miami  :: 4913\n",
      "goldblum  :: 4914\n",
      "sacrif  :: 4915\n",
      "knee  :: 4916\n",
      "pepper  :: 4917\n",
      "vignett  :: 4918\n",
      "inaccur  :: 4919\n",
      "truman  :: 4920\n",
      "ash  :: 4921\n",
      "lanc  :: 4922\n",
      "id  :: 4923\n",
      "kiddi  :: 4924\n",
      "meal  :: 4925\n",
      "conan  :: 4926\n",
      "decapit  :: 4927\n",
      "bait  :: 4928\n",
      "unattract  :: 4929\n",
      "genet  :: 4930\n",
      "aussi  :: 4931\n",
      "porter  :: 4932\n",
      "spray  :: 4933\n",
      "curtain  :: 4934\n",
      "poker  :: 4935\n",
      "mum  :: 4936\n",
      "pioneer  :: 4937\n",
      "inclus  :: 4938\n",
      "subtli  :: 4939\n",
      "lauren  :: 4940\n",
      "abound  :: 4941\n",
      "paula  :: 4942\n",
      "groan  :: 4943\n",
      "carmen  :: 4944\n",
      "1985  :: 4945\n",
      "miniseri  :: 4946\n",
      "rosario  :: 4947\n",
      "propheci  :: 4948\n",
      "unsuspect  :: 4949\n",
      "sidewalk  :: 4950\n",
      "comprehens  :: 4951\n",
      "galaxi  :: 4952\n",
      "bsg  :: 4953\n",
      "congratul  :: 4954\n",
      "fruit  :: 4955\n",
      "tokyo  :: 4956\n",
      "walt  :: 4957\n",
      "palm  :: 4958\n",
      "cape  :: 4959\n",
      "roar  :: 4960\n",
      "antonio  :: 4961\n",
      "vain  :: 4962\n",
      "forgiven  :: 4963\n",
      "ingrid  :: 4964\n",
      "turtl  :: 4965\n",
      "macabr  :: 4966\n",
      "epitom  :: 4967\n",
      "motorcycl  :: 4968\n",
      "masterson  :: 4969\n",
      "vastli  :: 4970\n",
      "omin  :: 4971\n",
      "bach  :: 4972\n",
      "drone  :: 4973\n",
      "dubiou  :: 4974\n",
      "playboy  :: 4975\n",
      "cypher  :: 4976\n",
      "spill  :: 4977\n",
      "hackman  :: 4978\n",
      "orchestr  :: 4979\n",
      "asset  :: 4980\n",
      "modest  :: 4981\n",
      "casper  :: 4982\n",
      "incorrect  :: 4983\n",
      "victorian  :: 4984\n",
      "evan  :: 4985\n",
      "scariest  :: 4986\n",
      "hostil  :: 4987\n",
      "21st  :: 4988\n",
      "bravo  :: 4989\n",
      "sophi  :: 4990\n",
      "scarfac  :: 4991\n",
      "jill  :: 4992\n",
      "rapidli  :: 4993\n",
      "frontal  :: 4994\n",
      "weaker  :: 4995\n",
      "mice  :: 4996\n",
      "growth  :: 4997\n",
      "monti  :: 4998\n",
      "substanti  :: 4999\n"
     ]
    }
   ],
   "source": [
    "#word_dict\n",
    "    \n",
    "listofTuples = sorted(word_dict.items() , key=lambda x: x[1])\n",
    " \n",
    "# Iterate over the sorted sequence\n",
    "for elem in listofTuples :\n",
    "    print(elem[0] , \" ::\" , elem[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What are the five most frequently appearing (tokenized) words in the training set? Does it makes sense that these words appear frequently in the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** movi, film, one, like, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO: Use this space to determine the five most frequently appearing words in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movi\n",
      "film\n",
      "one\n",
      "like\n",
      "time\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for wd in word_dict:\n",
    "    print(wd)\n",
    "    i+=1\n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `word_dict`\n",
    "\n",
    "Later on when we construct an endpoint which processes a submitted review we will need to make use of the `word_dict` which we have created. As such, we will save it to a file now for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/pytorch' # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"rb\" ) as f:\n",
    "    word_dict = pickle.load( f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the reviews\n",
    "\n",
    "Now that we have our word dictionary which allows us to transform the words appearing in the reviews into integers, it is time to make use of it and convert our reviews to their integer sequence representation, making sure to pad or truncate to a fixed length, which in our case is `500`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(word_dict, sentence, pad=500):\n",
    "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
    "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check to make sure that things are working as intended, check to see what one of the reviews in the training set looks like after having been processeed. Does this look reasonable? What is the length of a review in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 [ 68  75  84 ... 129  74  34]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 135,    2,  996,  279, 1309,    1,   11, 3228, 3025,    1,   95,\n",
       "          4, 1411,    2,   47,   44,   87,  139,  529,    1, 1394,  499,\n",
       "        267,   40,  312,    4, 1876,   26, 1540, 1523, 3228, 3025, 4117,\n",
       "          1,   27,   38,    2,  105,  683,  328,    6,  431,  122,  390,\n",
       "        517,   37,  149,   21,    1,  111,    4,   53,    2,   47,  114,\n",
       "          6,  219,  517,  372, 2600,    3,  664,   11, 1380,  279,  215,\n",
       "        181,  660,    7,  105,   17,  343,  125,  116,    1,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this cell to examine one of the processed reviews to make sure everything is working as intended.\n",
    "print(len(train_X[1]),train_X_len)\n",
    "train_X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** In the cells above we use the `preprocess_data` and `convert_and_pad_data` methods to process both the training and testing set. Why or why not might this be a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "the current implementation of `preprocess_data` method requires 2 labeled sets, it doesn't allow to preprocess and dump train, val, test sets at the same time. Also, preprocessing of a new unlabled test set would raise an error.\n",
    "`convert_and_pad_data` doesn't cause any problems since we assume that both sets are in the same domain (therefore the words come from one dictionary), and if the test set has any words not present in train set, these words will get the key `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Upload the data to S3\n",
    "\n",
    "As in the XGBoost notebook, we will need to upload the training dataset to S3 in order for our training code to access it. For now we will save it locally and we will upload to S3 later on.\n",
    "\n",
    "### Save the processed training dataset locally\n",
    "\n",
    "It is important to note the format of the data that we are saving as we will need to know it when we write the training code. In our case, each row of the dataset has the form `label`, `length`, `review[500]` where `review[500]` is a sequence of `500` integers representing the words in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
    "        .to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the training data\n",
    "\n",
    "\n",
    "Next, we need to upload the training data to the SageMaker default S3 bucket so that we can provide access to it while training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/sentiment_rnn'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The cell above uploads the entire contents of our data directory. This includes the `word_dict.pkl` file. This is fortunate as we will need this later on when we create an endpoint that accepts an arbitrary review. For now, we will just take note of the fact that it resides in the data directory (and so also in the S3 training bucket) and that we will need to make sure it gets saved in the model directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build and Train the PyTorch Model\n",
    "\n",
    "In the XGBoost notebook we discussed what a model is in the SageMaker framework. In particular, a model comprises three objects\n",
    "\n",
    " - Model Artifacts,\n",
    " - Training Code, and\n",
    " - Inference Code,\n",
    " \n",
    "each of which interact with one another. In the XGBoost example we used training and inference code that was provided by Amazon. Here we will still be using containers provided by Amazon with the added benefit of being able to include our own custom code.\n",
    "\n",
    "We will start by implementing our own neural network in PyTorch along with a training script. For the purposes of this project we have provided the necessary model object in the `model.py` file, inside of the `train` folder. You can see the provided implementation by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mLSTMClassifier\u001b[39;49;00m(nn.Module):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    This is the simple RNN model we will be using to perform Sentiment Analysis.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, embedding_dim, hidden_dim, vocab_size):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Initialize the model by settingg up the various layers.\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(LSTMClassifier, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\r\n",
      "\r\n",
      "        \u001b[36mself\u001b[39;49;00m.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=\u001b[34m0\u001b[39;49;00m)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.lstm = nn.LSTM(embedding_dim, hidden_dim)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.dense = nn.Linear(in_features=hidden_dim, out_features=\u001b[34m1\u001b[39;49;00m)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.sig = nn.Sigmoid()\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.word_dict = \u001b[36mNone\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Perform a forward pass of our model on some input.\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        x = x.t()\r\n",
      "        lengths = x[\u001b[34m0\u001b[39;49;00m,:]\r\n",
      "        reviews = x[\u001b[34m1\u001b[39;49;00m:,:]\r\n",
      "        embeds = \u001b[36mself\u001b[39;49;00m.embedding(reviews)\r\n",
      "        lstm_out, _ = \u001b[36mself\u001b[39;49;00m.lstm(embeds)\r\n",
      "        out = \u001b[36mself\u001b[39;49;00m.dense(lstm_out)\r\n",
      "        out = out[lengths - \u001b[34m1\u001b[39;49;00m, \u001b[36mrange\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(lengths))]\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.sig(out.squeeze())\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important takeaway from the implementation provided is that there are three parameters that we may wish to tweak to improve the performance of our model. These are the embedding dimension, the hidden dimension and the size of the vocabulary. We will likely want to make these parameters configurable in the training script so that if we wish to modify them we do not need to modify the script itself. We will see how to do this later on. To start we will write some of the training code in the notebook so that we can more easily diagnose any issues that arise.\n",
    "\n",
    "First we will load a small portion of the training data set to use as a sample. It would be very time consuming to try and train the model completely in the notebook as we do not have access to a gpu and the compute instance that we are using is not particularly powerful. However, we can work on a small bit of the data to get a feel for how our training script is behaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Read in only the first 250 rows\n",
    "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None, nrows=250)\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
    "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "# Build the dataloader\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Writing the training method\n",
    "\n",
    "Next we need to write the training code itself. This should be very similar to training methods that you have written before to train PyTorch models. We will leave any difficult aspects such as model saving / loading and parameter loading until a little later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            #x, y = place_and_unwrap(batch, device)\n",
    "            with torch.set_grad_enabled(True):\n",
    "             \n",
    "                out = model(batch_X)\n",
    "                    \n",
    "                loss = loss_fn(out, batch_y)\n",
    "\n",
    "            #if is_training:\n",
    "            optimizer.zero_grad()\n",
    "                  \n",
    "            loss.backward()\n",
    "               \n",
    "            optimizer.step()\n",
    "\n",
    "            #phase.batch_loss = loss.item()\n",
    "            #\n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposing we have the training method above, we will test that it is working by writing a bit of code in the notebook that executes our training method on the small sample training set that we loaded earlier. The reason for doing this in the notebook is so that we have an opportunity to fix any errors that arise early when they are easier to diagnose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, BCELoss: 0.6940591692924499\n",
      "Epoch: 2, BCELoss: 0.6854180932044983\n",
      "Epoch: 3, BCELoss: 0.6777827024459839\n",
      "Epoch: 4, BCELoss: 0.6689720630645752\n",
      "Epoch: 5, BCELoss: 0.6574710845947266\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from train.model import LSTMClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(32, 100, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "train(model, train_sample_dl, 5, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct a PyTorch model using SageMaker we must provide SageMaker with a training script. We may optionally include a directory which will be copied to the container and from which our training code will be run. When the training container is executed it will check the uploaded directory (if there is one) for a `requirements.txt` file and install any required Python libraries, after which the training script will be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Training the model\n",
    "\n",
    "When a PyTorch model is constructed in SageMaker, an entry point must be specified. This is the Python file which will be executed when the model is trained. Inside of the `train` directory is a file called `train.py` which has been provided and which contains most of the necessary code to train our model. The only thing that is missing is the implementation of the `train()` method which you wrote earlier in this notebook.\n",
    "\n",
    "**TODO**: Copy the `train()` method written above and paste it into the `train/train.py` file where required.\n",
    "\n",
    "The way that SageMaker passes hyperparameters to the training script is by way of arguments. These arguments can then be parsed and used in the training script. To see how this is done take a look at the provided `train/train.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"train\",\n",
    "                    role=role,\n",
    "                    framework_version='0.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type= 'ml.m4.xlarge',#'ml.p2.xlarge',#\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10,\n",
    "                        'hidden_dim': 200,\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 09:01:53 Starting - Starting the training job...\n",
      "2020-04-09 09:01:55 Starting - Launching requested ML instances......\n",
      "2020-04-09 09:03:03 Starting - Preparing the instances for training......\n",
      "2020-04-09 09:04:03 Downloading - Downloading input data...\n",
      "2020-04-09 09:04:53 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-09 09:04:54,222 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-09 09:04:54,225 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-09 09:04:54,238 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-09 09:04:55,679 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-09 09:04:56,042 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-09 09:04:56,043 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-09 09:04:56,043 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-09 09:04:56,043 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/ff/18/c0b937e2f84095ae230196899e56d1d7d76c8e8424fb235ed7e5bb6d68af/numpy-1.18.2-cp35-cp35m-manylinux1_x86_64.whl (20.0MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/b5/7bb03a696f2c9b7af792a8f51b82974e51c268f15e925fc834876a4efa0b/beautifulsoup4-4.9.0-py3-none-any.whl (109kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/62/bbd2be0e7943ec8504b517e62bab011b4946e1258842bc159e5dfde15b96/html5lib-1.0.1-py2.py3-none-any.whl (117kB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (1.11.0)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2 (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/05/cf/ea245e52f55823f19992447b008bcbb7f78efc5960d77f6c34b5b45b36dd/soupsieve-2.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train\n",
      "  Running setup.py bdist_wheel for nltk: started\n",
      "  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9cl0cspt/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.0 html5lib-1.0.1 nltk-3.4.5 numpy-1.18.2 pandas-0.24.2 pytz-2019.3 soupsieve-2.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-04-09 09:05:08,590 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-09 09:05:08,604 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-04-09-09-01-53-305\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"log_level\": 20,\n",
      "    \"module_name\": \"train\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"resource_config\": {\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 200,\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"num_gpus\": 0,\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-008894397420/sagemaker-pytorch-2020-04-09-09-01-53-305/source/sourcedir.tar.gz\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"num_cpus\": 4,\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"current_host\": \"algo-1\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10,\"hidden_dim\":200}\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10,\"hidden_dim\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-04-09-09-01-53-305\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-008894397420/sagemaker-pytorch-2020-04-09-09-01-53-305/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\",\"--hidden_dim\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=200\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-008894397420/sagemaker-pytorch-2020-04-09-09-01-53-305/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 10 --hidden_dim 200\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 32, hidden_dim 200, vocab_size 5000.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 1, BCELoss: 0.6706423662146743\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.6050693052155631\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.5347774478853965\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.4780822834190057\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.4453286224482011\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.3910784173984917\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.3530127625076138\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.3982901567099046\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.32424689677296853\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.2972212537210815\u001b[0m\n",
      "\u001b[34m2020-04-09 10:46:45,241 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-09 10:46:54 Uploading - Uploading generated training model\n",
      "2020-04-09 10:46:54 Completed - Training job completed\n",
      "Training seconds: 6171\n",
      "Billable seconds: 6171\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Testing the model\n",
    "\n",
    "As mentioned at the top of this notebook, we will be testing this model by first deploying it and then sending the testing data to the deployed endpoint. We will do this so that we can make sure that the deployed model is working correctly.\n",
    "\n",
    "## Step 6: Deploy the model for testing\n",
    "\n",
    "Now that we have trained our model, we would like to test it to see how it performs. Currently our model takes input of the form `review_length, review[500]` where `review[500]` is a sequence of `500` integers which describe the words present in the review, encoded using `word_dict`. Fortunately for us, SageMaker provides built-in inference code for models with simple inputs such as this.\n",
    "\n",
    "There is one thing that we need to provide, however, and that is a function which loads the saved model. This function must be called `model_fn()` and takes as its only parameter a path to the directory where the model artifacts are stored. This function must also be present in the python file which we specified as the entry point. In our case the model loading function has been provided and so no changes need to be made.\n",
    "\n",
    "**NOTE**: When the built-in inference code is run it must import the `model_fn()` method from the `train.py` file. This is why the training code is wrapped in a main guard ( ie, `if __name__ == '__main__':` )\n",
    "\n",
    "Since we don't need to change anything in the code that was uploaded during training, we can simply deploy the current model as-is.\n",
    "\n",
    "**NOTE:** When deploying a model you are asking SageMaker to launch an compute instance that will wait for data to be sent to it. As a result, this compute instance will continue to run until *you* shut it down. This is important to know since the cost of a deployed endpoint depends on how long it has been running for.\n",
    "\n",
    "In other words **If you are no longer using a deployed endpoint, shut it down!**\n",
    "\n",
    "**TODO:** Deploy the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# TODO: Deploy the trained model\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Use the model for testing\n",
    "\n",
    "Once deployed, we can read in the test data and send it off to our deployed model to get some results. Once we collect all of the results we can determine how accurate our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.concat([pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into chunks and send each chunk seperately, accumulating the results.\n",
    "\n",
    "def predict(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = np.array([])\n",
    "    for array in split_array:\n",
    "        predictions = np.append(predictions, predictor.predict(array))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(test_X.values)\n",
    "predictions = [round(num) for num in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85328"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does this model compare to the XGBoost model you created earlier? Why might these two models perform differently on this dataset? Which do *you* think is better for sentiment analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The result of XGBoost was almost the same: 0.8536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) More testing\n",
    "\n",
    "We now have a trained model which has been deployed and which we can send processed reviews to and which returns the predicted sentiment. However, ultimately we would like to be able to send our model an unprocessed review. That is, we would like to send the review itself as a string. For example, suppose we wish to send the following review to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = 'The simplest pleasures in life are the best, and this film is one of them. Combining a rather basic storyline of love and adventure this movie transcends the usual weekend fair with wit and unmitigated charm.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question we now need to answer is, how do we send this review to our model?\n",
    "\n",
    "Recall in the first section of this notebook we did a bunch of data processing to the IMDb dataset. In particular, we did two specific things to the provided reviews.\n",
    " - Removed any html tags and stemmed the input\n",
    " - Encoded the review as a sequence of integers using `word_dict`\n",
    " \n",
    "In order process the review we will need to repeat these two steps.\n",
    "\n",
    "**TODO**: Using the `review_to_words` and `convert_and_pad` methods from section one, convert `test_review` into a numpy array `test_data` suitable to send to our model. Remember that our model expects input of the form `review_length, review[500]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_review_to_words = review_to_words(test_review)\n",
    "test_data = [np.array(convert_and_pad(word_dict, test_data_review_to_words)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.60721785, dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have processed the review, we can send the resulting array to our model to predict the sentiment of the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the return value of our model is close to `1`, we can be certain that the review we submitted is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the endpoint\n",
    "\n",
    "Of course, just like in the XGBoost notebook, once we've deployed an endpoint it continues to run until we tell it to shut down. Since we are done using our endpoint for now, we can delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 (again) - Deploy the model for the web app\n",
    "\n",
    "Now that we know that our model is working, it's time to create some custom inference code so that we can send the model a review which has not been processed and have it determine the sentiment of the review.\n",
    "\n",
    "As we saw above, by default the estimator which we created, when deployed, will use the entry script and directory which we provided when creating the model. However, since we now wish to accept a string as input and our model expects a processed review, we need to write some custom inference code.\n",
    "\n",
    "We will store the code that we write in the `serve` directory. Provided in this directory is the `model.py` file that we used to construct our model, a `utils.py` file which contains the `review_to_words` and `convert_and_pad` pre-processing functions which we used during the initial data processing, and `predict.py`, the file which will contain our custom inference code. Note also that `requirements.txt` is present which will tell SageMaker what Python libraries are required by our custom inference code.\n",
    "\n",
    "When deploying a PyTorch model in SageMaker, you are expected to provide four functions which the SageMaker inference container will use.\n",
    " - `model_fn`: This function is the same function that we used in the training script and it tells SageMaker how to load our model.\n",
    " - `input_fn`: This function receives the raw serialized input that has been sent to the model's endpoint and its job is to de-serialize and make the input available for the inference code.\n",
    " - `output_fn`: This function takes the output of the inference code and its job is to serialize this output and return it to the caller of the model's endpoint.\n",
    " - `predict_fn`: The heart of the inference script, this is where the actual prediction is done and is the function which you will need to complete.\n",
    "\n",
    "For the simple website that we are constructing during this project, the `input_fn` and `output_fn` methods are relatively straightforward. We only require being able to accept a string as input and we expect to return a single value as output. You might imagine though that in a more complex application the input or output may be image data or some other binary data which would require some effort to serialize.\n",
    "\n",
    "### (TODO) Writing inference code\n",
    "\n",
    "Before writing our custom inference code, we will begin by taking a look at the code which has been provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_containers\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.optim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.utils.data\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LSTMClassifier\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m review_to_words, convert_and_pad\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# First, load the parameters used to create the model.\u001b[39;49;00m\r\n",
      "    model_info = {}\r\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model_info = torch.load(f)\r\n",
      "\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: {}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\r\n",
      "\r\n",
      "    \u001b[37m# Determine the device and construct the model.\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    model = LSTMClassifier(model_info[\u001b[33m'\u001b[39;49;00m\u001b[33membedding_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mvocab_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[37m# Load the store model parameters.\u001b[39;49;00m\r\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model.load_state_dict(torch.load(f))\r\n",
      "\r\n",
      "    \u001b[37m# Load the saved word_dict.\u001b[39;49;00m\r\n",
      "    word_dict_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mword_dict.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(word_dict_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model.word_dict = pickle.load(f)\r\n",
      "\r\n",
      "    model.to(device).eval()\r\n",
      "\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(serialized_input_data, content_type):\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mDeserializing the input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mtext/plain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "        data = serialized_input_data.decode(\u001b[33m'\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m data\r\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in content_type: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + content_type)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction_output, accept):\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mSerializing the generated output.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mstr\u001b[39;49;00m(prediction_output)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mInferring sentiment of input data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34mif\u001b[39;49;00m model.word_dict \u001b[35mis\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mModel has not been loaded properly, no word_dict.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# TODO: Process input_data so that it is ready to be sent to our model.\u001b[39;49;00m\r\n",
      "    \u001b[37m#       You should produce two variables:\u001b[39;49;00m\r\n",
      "    \u001b[37m#         data_X   - A sequence of length 500 which represents the converted review\u001b[39;49;00m\r\n",
      "    \u001b[37m#         data_len - The length of the review\u001b[39;49;00m\r\n",
      "\r\n",
      "    data_X,data_len = convert_and_pad(model.word_dict, review_to_words(input_data), pad=\u001b[34m500\u001b[39;49;00m)\r\n",
      "    \r\n",
      "\r\n",
      "    \u001b[37m# Using data_X and data_len we construct an appropriate input tensor. Remember\u001b[39;49;00m\r\n",
      "    \u001b[37m# that our model expects input data of the form 'len, review[500]'.\u001b[39;49;00m\r\n",
      "    data_pack = np.hstack((data_len, data_X))\r\n",
      "    data_pack = data_pack.reshape(\u001b[34m1\u001b[39;49;00m, -\u001b[34m1\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    data = torch.from_numpy(data_pack)\r\n",
      "    data = data.to(device)\r\n",
      "\r\n",
      "    \u001b[37m# Make sure to put the model into evaluation mode\u001b[39;49;00m\r\n",
      "    model.eval()\r\n",
      "\r\n",
      "    \u001b[37m# TODO: Compute the result of applying the model to the input data. The variable `result` should\u001b[39;49;00m\r\n",
      "    \u001b[37m#       be a numpy array which contains a single integer which is either 1 or 0\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[33m\"\"\"result = round(model.predict(data))\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    return int(result)\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\r\n",
      "        output = model.forward(data)\r\n",
      "\r\n",
      "    result = np.round(output.numpy())\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mint\u001b[39;49;00m(result)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize serve/predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the `model_fn` method is the same as the one provided in the training code and the `input_fn` and `output_fn` methods are very simple and your task will be to complete the `predict_fn` method. Make sure that you save the completed file as `predict.py` in the `serve` directory.\n",
    "\n",
    "**TODO**: Complete the `predict_fn()` method in the `serve/predict.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the model\n",
    "\n",
    "Now that the custom inference code has been written, we will create and deploy our model. To begin with, we need to construct a new PyTorchModel object which points to the model artifacts created during training and also points to the inference code that we wish to use. Then we can call the deploy method to launch the deployment container.\n",
    "\n",
    "**NOTE**: The default behaviour for a deployed PyTorch model is to assume that any input passed to the predictor is a `numpy` array. In our case we want to send a string so we need to construct a simple wrapper around the `RealTimePredictor` class to accomodate simple strings. In a more complicated situation you may want to provide a serialization object, for example if you wanted to sent image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import RealTimePredictor\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "class StringPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')\n",
    "\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='0.4.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='serve',\n",
    "                     predictor_cls=StringPredictor)\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "\n",
    "Now that we have deployed our model with the custom inference code, we should test to see if everything is working. Here we test our model by loading the first `250` positive and negative reviews and send them to the endpoint, then collect the results. The reason for only sending some of the data is that the amount of time it takes for our model to process the input and then perform inference is quite long and so testing the entire data set would be prohibitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def test_reviews(data_dir='../data/aclImdb', stop=250):\n",
    "    \n",
    "    results = []\n",
    "    ground = []\n",
    "    \n",
    "    # We make sure to test both positive and negative reviews    \n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        \n",
    "        path = os.path.join(data_dir, 'test', sentiment, '*.txt')\n",
    "        files = glob.glob(path)\n",
    "        \n",
    "        files_read = 0\n",
    "        \n",
    "        print('Starting ', sentiment, ' files')\n",
    "        \n",
    "        # Iterate through the files and send them to the predictor\n",
    "        for f in files:\n",
    "            with open(f) as review:\n",
    "                # First, we store the ground truth (was the review positive or negative)\n",
    "                if sentiment == 'pos':\n",
    "                    ground.append(1)\n",
    "                else:\n",
    "                    ground.append(0)\n",
    "                # Read in the review and convert to 'utf-8' for transmission via HTTP\n",
    "                review_input = review.read().encode('utf-8')\n",
    "                # Send the review to the predictor and store the results\n",
    "                results.append(int(predictor.predict(review_input)))\n",
    "                \n",
    "            # Sending reviews to our endpoint one at a time takes a while so we\n",
    "            # only send a small number of reviews\n",
    "            files_read += 1\n",
    "            if files_read == stop:\n",
    "                break\n",
    "            \n",
    "    return ground, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  pos  files\n",
      "Starting  neg  files\n"
     ]
    }
   ],
   "source": [
    "ground, results = test_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ground, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an additional test, we can try sending the `test_review` that we looked at earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(test_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know our endpoint is working as expected, we can set up the web page that will interact with it. If you don't have time to finish the project now, make sure to skip down to the end of this notebook and shut down your endpoint. You can deploy it again when you come back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 (again): Use the model for the web app\n",
    "\n",
    "> **TODO:** This entire section and the next contain tasks for you to complete, mostly using the AWS console.\n",
    "\n",
    "So far we have been accessing our model endpoint by constructing a predictor object which uses the endpoint and then just using the predictor object to perform inference. What if we wanted to create a web app which accessed our model? The way things are set up currently makes that not possible since in order to access a SageMaker endpoint the app would first have to authenticate with AWS using an IAM role which included access to SageMaker endpoints. However, there is an easier way! We just need to use some additional AWS services.\n",
    "\n",
    "<img src=\"Web App Diagram.svg\">\n",
    "\n",
    "The diagram above gives an overview of how the various services will work together. On the far right is the model which we trained above and which is deployed using SageMaker. On the far left is our web app that collects a user's movie review, sends it off and expects a positive or negative sentiment in return.\n",
    "\n",
    "In the middle is where some of the magic happens. We will construct a Lambda function, which you can think of as a straightforward Python function that can be executed whenever a specified event occurs. We will give this function permission to send and recieve data from a SageMaker endpoint.\n",
    "\n",
    "Lastly, the method we will use to execute the Lambda function is a new endpoint that we will create using API Gateway. This endpoint will be a url that listens for data to be sent to it. Once it gets some data it will pass that data on to the Lambda function and then return whatever the Lambda function returns. Essentially it will act as an interface that lets our web app communicate with the Lambda function.\n",
    "\n",
    "### Setting up a Lambda function\n",
    "\n",
    "The first thing we are going to do is set up a Lambda function. This Lambda function will be executed whenever our public API has data sent to it. When it is executed it will receive the data, perform any sort of processing that is required, send the data (the review) to the SageMaker endpoint we've created and then return the result.\n",
    "\n",
    "#### Part A: Create an IAM Role for the Lambda function\n",
    "\n",
    "Since we want the Lambda function to call a SageMaker endpoint, we need to make sure that it has permission to do so. To do this, we will construct a role that we can later give the Lambda function.\n",
    "\n",
    "Using the AWS Console, navigate to the **IAM** page and click on **Roles**. Then, click on **Create role**. Make sure that the **AWS service** is the type of trusted entity selected and choose **Lambda** as the service that will use this role, then click **Next: Permissions**.\n",
    "\n",
    "In the search box type `sagemaker` and select the check box next to the **AmazonSageMakerFullAccess** policy. Then, click on **Next: Review**.\n",
    "\n",
    "Lastly, give this role a name. Make sure you use a name that you will remember later on, for example `LambdaSageMakerRole`. Then, click on **Create role**.\n",
    "\n",
    "#### Part B: Create a Lambda function\n",
    "\n",
    "Now it is time to actually create the Lambda function.\n",
    "\n",
    "Using the AWS Console, navigate to the AWS Lambda page and click on **Create a function**. When you get to the next page, make sure that **Author from scratch** is selected. Now, name your Lambda function, using a name that you will remember later on, for example `sentiment_analysis_func`. Make sure that the **Python 3.6** runtime is selected and then choose the role that you created in the previous part. Then, click on **Create Function**.\n",
    "\n",
    "On the next page you will see some information about the Lambda function you've just created. If you scroll down you should see an editor in which you can write the code that will be executed when your Lambda function is triggered. In our example, we will use the code below. \n",
    "\n",
    "```python\n",
    "# We need to use the low-level library to interact with SageMaker since the SageMaker API\n",
    "# is not available natively through Lambda.\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    # The SageMaker runtime is what allows us to invoke the endpoint that we've created.\n",
    "    runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "    # Now we use the SageMaker runtime to invoke our endpoint, sending the review we were given\n",
    "    response = runtime.invoke_endpoint(EndpointName = '**ENDPOINT NAME HERE**',    # The name of the endpoint we created\n",
    "                                       ContentType = 'text/plain',                 # The data format that is expected\n",
    "                                       Body = event['body'])                       # The actual review\n",
    "\n",
    "    # The response is an HTTP response whose body contains the result of our inference\n",
    "    result = response['Body'].read().decode('utf-8')\n",
    "\n",
    "    return {\n",
    "        'statusCode' : 200,\n",
    "        'headers' : { 'Content-Type' : 'text/plain', 'Access-Control-Allow-Origin' : '*' },\n",
    "        'body' : result\n",
    "    }\n",
    "```\n",
    "\n",
    "Once you have copy and pasted the code above into the Lambda code editor, replace the `**ENDPOINT NAME HERE**` portion with the name of the endpoint that we deployed earlier. You can determine the name of the endpoint using the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-pytorch-2020-04-09-11-07-27-503'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have added the endpoint name to the Lambda function, click on **Save**. Your Lambda function is now up and running. Next we need to create a way for our web app to execute the Lambda function.\n",
    "\n",
    "### Setting up API Gateway\n",
    "\n",
    "Now that our Lambda function is set up, it is time to create a new API using API Gateway that will trigger the Lambda function we have just created.\n",
    "\n",
    "Using AWS Console, navigate to **Amazon API Gateway** and then click on **Get started**.\n",
    "\n",
    "On the next page, make sure that **New API** is selected and give the new api a name, for example, `sentiment_analysis_api`. Then, click on **Create API**.\n",
    "\n",
    "Now we have created an API, however it doesn't currently do anything. What we want it to do is to trigger the Lambda function that we created earlier.\n",
    "\n",
    "Select the **Actions** dropdown menu and click **Create Method**. A new blank method will be created, select its dropdown menu and select **POST**, then click on the check mark beside it.\n",
    "\n",
    "For the integration point, make sure that **Lambda Function** is selected and click on the **Use Lambda Proxy integration**. This option makes sure that the data that is sent to the API is then sent directly to the Lambda function with no processing. It also means that the return value must be a proper response object as it will also not be processed by API Gateway.\n",
    "\n",
    "Type the name of the Lambda function you created earlier into the **Lambda Function** text entry box and then click on **Save**. Click on **OK** in the pop-up box that then appears, giving permission to API Gateway to invoke the Lambda function you created.\n",
    "\n",
    "The last step in creating the API Gateway is to select the **Actions** dropdown and click on **Deploy API**. You will need to create a new Deployment stage and name it anything you like, for example `prod`.\n",
    "\n",
    "You have now successfully set up a public API to access your SageMaker model. Make sure to copy or write down the URL provided to invoke your newly created public API as this will be needed in the next step. This URL can be found at the top of the page, highlighted in blue next to the text **Invoke URL**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Deploying our web app\n",
    "\n",
    "Now that we have a publicly available API, we can start using it in a web app. For our purposes, we have provided a simple static html file which can make use of the public api you created earlier.\n",
    "\n",
    "In the `website` folder there should be a file called `index.html`. Download the file to your computer and open that file up in a text editor of your choice. There should be a line which contains **\\*\\*REPLACE WITH PUBLIC API URL\\*\\***. Replace this string with the url that you wrote down in the last step and then save the file.\n",
    "\n",
    "Now, if you open `index.html` on your local computer, your browser will behave as a local web server and you can use the provided site to interact with your SageMaker model.\n",
    "\n",
    "If you'd like to go further, you can host this html file anywhere you'd like, for example using github or hosting a static site on Amazon's S3. Once you have done this you can share the link with anyone you'd like and have them play with it too!\n",
    "\n",
    "> **Important Note** In order for the web app to communicate with the SageMaker endpoint, the endpoint has to actually be deployed and running. This means that you are paying for it. Make sure that the endpoint is running when you want to use the web app but that you shut it down when you don't need it, otherwise you will end up with a surprisingly large AWS bill.\n",
    "\n",
    "**TODO:** Make sure that you include the edited `index.html` file in your project submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your web app is working, trying playing around with it and see how well it works.\n",
    "\n",
    "**Question**: Give an example of a review that you entered into your web app. What was the predicted sentiment of your example review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \"It's a great action movie! Definitely recommended\"\n",
    "- \"our review was POSITIVE!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the endpoint\n",
    "\n",
    "Remember to always shut down your endpoint if you are no longer using it. You are charged for the length of time that the endpoint is running so if you forget and leave it on you could end up with an unexpectedly large bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
